{"_default": {"1": {"bradisbell": {"issues": [{"url": "https://api.github.com/repos/nodejs/http-parser/issues/405", "title": "Support for `SOURCE` method", "body": "A Feature Request:  As it is difficult to add support for custom methods, and the chatter on the various issue reports for it over the years indicates that \"just use HTTP/2\" is the final solution, could a `SOURCE` method be added as a possible HTTP method?\r\n\r\nThis method has been in-use by streaming media servers for a little over 15 years, and is still the dominant technology used for live HTTP progressive streaming source clients.  Most source clients cannot be configured to use `PUT` or another method, so servers supporting this type of streaming media must support `SOURCE`.\r\n\r\nThe [current workaround](https://stackoverflow.com/a/24298059/362536) involves some really nasty duck punching, which has to be updated regularly since it fiddles with Node.js internals on the JavaScript side.  Proper support for `SOURCE` would be greatly appreciated.  Thank you!", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/405/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "ZaMaZaN4iK": {"issues": [{"url": "https://api.github.com/repos/nodejs/http-parser/issues/404", "title": "Conan package for http-parser", "body": "Hello,\r\nDo you know about [Conan](https://github.com/conan-io/conan)?\r\n[Conan](http://docs.conan.io/en/latest/) is modern dependency manager for C++. And will be great if your library will be available via package manager for other developers.\r\n\r\n[Here](https://github.com/bincrafters/conan-templates) you can find example, how you can create package for the library. \r\n\r\nIf you have any questions, just ask :-)", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/404/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "samoconnor": {"issues": [{"url": "https://api.github.com/repos/nodejs/http-parser/issues/403", "title": "Test \"CONNECT_WITH_BODY_REQUEST\" maybe worng", "body": "See: https://github.com/nodejs/http-parser/pull/235#issuecomment-356903686\r\n\r\nThe `CONNECT_WITH_BODY_REQUEST` test case input has `Content-Length: 10` and a body `\"blarfcicle\"`, but the test expects [`.body= \"\"`](https://github.com/nodejs/http-parser/blob/master/test.c#L1102) !\r\n\r\n[The RFC says](https://tools.ietf.org/html/rfc7230#section-3.3):\r\n> _The presence of a message body in a request is signaled by a\r\n    Content-Length or Transfer-Encoding header field.  Request message\r\n   framing is independent of method semantics, even if the method does\r\n   not define any use for a message body._\r\n\r\ni.e. A request that says `Content-Length: 10` has a 10-byte body irrespective of the method being `CONNECT`.\r\n\r\nThe `CONNECT` scemantics are defined here: [RFC 7231, 4.3.6](https://tools.ietf.org/html/rfc7231#section-4.3.6). It talks about the client ignoring *responses( with Content-Length in, however, that is not relevant to this test *request* test case.\r\n\r\n>    _A server MUST NOT send any Transfer-Encoding or Content-Length header\r\n   fields in a 2xx (Successful) response to CONNECT.  A client MUST\r\n   ignore any Content-Length or Transfer-Encoding header fields received\r\n   in a successful response to CONNECT._\r\n\r\n[RFC 7231, 4.3.6](https://tools.ietf.org/html/rfc7231#section-4.3.6) goes on to say that a payload on a `CONNECT` request has no defined meaning, but it does not disallow it:\r\n\r\n>  _A payload within a CONNECT request message has no defined semantics;\r\n   sending a payload body on a CONNECT request might cause some existing\r\n   implementations to reject the request._\r\n\r\nSo, this line may be wrong: https://github.com/nodejs/http-parser/pull/235/files#diff-5c62f371bf37583234d2462ad49ce33dR1837", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/403/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/397", "title": "typos in http-parser/test.c", "body": "https://github.com/nodejs/http-parser/blob/05525c5fde1fc562481f6ae08fa7056185325daf/test.c#L156\r\n\r\nhttps://github.com/nodejs/http-parser/blob/05525c5fde1fc562481f6ae08fa7056185325daf/test.c#L374\r\n\r\nhttps://github.com/nodejs/admin/blob/master/CODE_OF_CONDUCT.md ?", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/397/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "tianchao-haohan": {"issues": [{"url": "https://api.github.com/repos/nodejs/http-parser/issues/401", "title": "Need to consider the noBody situation for HEAD method", "body": "Here is the diff code:\r\n```\r\n+++ b/src/3rd_party/http_parser/http_parser.c\r\n@@ -1783,8 +1783,9 @@ reexecute:\r\n\r\n         hasBody = parser->flags & F_CHUNKED ||\r\n           (parser->content_length > 0 && parser->content_length != ULLONG_MAX);\r\n-        if (parser->upgrade && (parser->method == HTTP_CONNECT ||\r\n-                                (parser->flags & F_SKIPBODY) || !hasBody)) {\r\n+        if ((parser->upgrade && (parser->method == HTTP_CONNECT ||\r\n+                                (parser->flags & F_SKIPBODY) || !hasBody))\r\n+                                || parser->method == HTTP_HEAD) {\r\n           /* Exit, the rest of the message is in a different protocol. */\r\n           UPDATE_STATE(NEW_MESSAGE());\r\n           CALLBACK_NOTIFY(message_complete);\r\n```", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/401/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "maclover7": {"issues": [{"url": "https://api.github.com/repos/nodejs/http-parser/issues/400", "title": "Group related tests into files", "body": "`test.c` is over four thousand lines long and is getting a little hard to parse... any objections to moving some related tests into separate files in a `test/` directory?\r\n\r\n@indutny @bnoordhuis ", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/400/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/399", "title": "Convert test suite to TAP output", "body": "Right now the test suite has a proprietary/unique way of outputting the status of tests. It would be better if it used something like TAP, which is already used by nodejs/node, libuv/libuv, and other projects. I'm going to try and take a look at this, but someone else can give it a shot if they want :)", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/399/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}], "commits": [{"url": "https://api.github.com/repos/nodejs/http-parser/commits/b11de0f5c65bcc1b906f85f4df58883b0c133e7b", "message": "doc: standardize project name\n\nPR-URL: https://github.com/nodejs/http-parser/pull/398\nReviewed-By: Ben Noordhuis <info@bnoordhuis.nl>\nReviewed-By: Fedor Indutny <fedor@indutny.com>"}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "tduehr": {"issues": [{"url": "https://api.github.com/repos/nodejs/http-parser/issues/394", "title": "New release needed: 2.7.1 http_parser.h does not contain HTTP_STATUS_MAP", "body": "This is needed by tang.\r\n\r\nsee also: https://github.com/latchset/tang/issues/19", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/394/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "tatsuhiro-t": {"issues": [{"url": "https://api.github.com/repos/nodejs/http-parser/issues/386", "title": "HTTP/0.9 does not have header fields", "body": "According to https://www.w3.org/Protocols/HTTP/AsImplemented.html, HTTP/0.9 does not have header fields, and single CR + LF pair (or just LF) after a request line signals the end of request.\r\nBut current http-parser waits for 2nd CR + LF pair.\r\n\r\nSee how apache works:\r\n\r\n```\r\n$ telnet 127.0.0.1 80\r\nTrying 127.0.0.1...\r\nConnected to 127.0.0.1.\r\nEscape character is '^]'.\r\nGET /\r\n<html><body><h1>It works!</h1>\r\n<p>This is the default web page for this server.</p>\r\n<p>The web server software is running but no content has been added, yet.</p>\r\n</body></html>\r\nConnection closed by foreign host.\r\n```", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/386/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}], "commits": [{"url": "https://api.github.com/repos/nodejs/http-parser/commits/7d75dd73258812d052e483593002a47e63420517", "message": "src: support IPv6 Zone ID as per RFC 6874\n\nIPv6 scoped address contains Zone ID, which is appended to IPv6\naddress after '%' separator.  RFC 6874 says that Zone ID after '%'\nmust consist of 1*(unreserved or pct-encoded).  This commit adds this\nIPv6 Zone ID support.\n\nPR-URL: https://github.com/joyent/http-parser/pull/253\nReviewed-By: Fedor Indutny <fedor@indutny.com>"}], "pull_requests": [{"url": "https://api.github.com/repos/nodejs/http-parser/pulls/311", "title": "Allow non-standard HTTP method", "body": "This change adds non-standard HTTP method support.  We added new\ncallback on_method of type http_data_cb, which notifies incoming\nmethod.  For non-standard HTTP method, method field in struct\nhttp_parser becomes HTTP_METHOD_UNKNOWN.\n\nThe non-standard HTTP method is disabled by default, and must be\nexplicitly enabled by giving -DHTTP_PARSER_METHOD_CB=1 on build time.\nThis is for backward compatibility; because non-standard HTTP method\nis now accepted rather than rejected.\n", "author_association": "CONTRIBUTOR"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "TechnikEmpire": {"issues": [{"url": "https://api.github.com/repos/nodejs/http-parser/issues/384", "title": "When parsing response that omits status message text, on_status is never called", "body": "On status callback does not get invoked when we're dealing with a web server that omits the status text from the status line. Examples of servers doing this are kijiji.\r\n\r\nExample from in the wild:\r\n```\r\nGET \r\nhttps://www.kijiji.ca/h-lloydminster-ab/1700095\r\n\r\nStatus: HTTP/1.1 200\r\n```\r\n\r\nServer is advertised as being nginx.\r\n\r\nWhen parsing the response, `on_status` will never be called. Not sure if this is intended or not, I started looking into the spec for this and didn't see any `MUST`'s with regards to the status text. I came up with a solution to work around this personally so I don't care anymore, just FYI.", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/384/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "sachinHPrabhu": {"issues": [{"url": "https://api.github.com/repos/nodejs/http-parser/issues/382", "title": "Request for information about the schedule of next release", "body": "The master branch of the http-parser project already has a fix that I am interested in.\r\n\r\nTolerate non-compliant status line responses \r\nhttps://github.com/nodejs/http-parser/commit/3b0da34d83e4eace29cc49e3b659bf630537b94c\r\n\r\nHence I wished to know if there is any schedule for next release of the http-parser.\r\n\r\nThanking You.\r\nRegards.", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/382/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "WilCrofter": {"issues": [{"url": "https://api.github.com/repos/nodejs/http-parser/issues/381", "title": "Request new release: v2.7.1, does not build with gcc 7.1.1 due to FALLTHROUGH issue", "body": "Although the FALLTHROUGH issue was fixed in [0852bea](https://github.com/nodejs/http-parser/commit/0852bea482e0842b0445c14b19dc9b318a6c4eba) the last release predates the fix.\r\n\r\nv2.7.1 is currently a dependency of [JuliaWeb/HttpParser.jl](https://github.com/JuliaWeb/HttpParser.jl) which will, of course, not build with current versions of gcc.", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/381/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "rnburn": {"issues": [{"url": "https://api.github.com/repos/nodejs/http-parser/issues/380", "title": "Makefile is broken for OS X", "body": "If you try to install on OS X, you'll get this error\r\n```\r\ncc  -I. -DHTTP_PARSER_STRICT=0  -Wall -Wextra -Werror -O3  -fPIC -c http_parser.c -o libhttp_parser.o\r\ncc  -shared -o libhttp_parser.2.7.1.dylib libhttp_parser.o\r\ninstall -D  http_parser.h /usr/local/include/http_parser.h\r\ninstall: illegal option -- D\r\nusage: install [-bCcpSsv] [-B suffix] [-f flags] [-g group] [-m mode]\r\n               [-o owner] file1 file2\r\n       install [-bCcpSsv] [-B suffix] [-f flags] [-g group] [-m mode]\r\n               [-o owner] file1 ... fileN directory\r\n       install -d [-v] [-g group] [-m mode] [-o owner] directory ...\r\nmake: *** [install] Error 64\r\n```\r\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/380/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "RekGRpth": {"issues": [{"url": "https://api.github.com/repos/nodejs/http-parser/issues/371", "title": "http_status_str", "body": "```c\r\nconst char *http_status_str(enum http_status s) {\r\n    switch (s) {\r\n#define XX(num, name, string) case HTTP_STATUS_##name: return #num \" \" #string;\r\n    HTTP_STATUS_MAP(XX)\r\n#undef XX\r\n        default: return \"<unknown>\";\r\n    }\r\n}\r\n```", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/371/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "povilasb": {"issues": [{"url": "https://api.github.com/repos/nodejs/http-parser/issues/362", "title": "How to disable automatic chunks decoding?", "body": "> The parser decodes the transfer-encoding for both requests and responses transparently. That is, a chunked encoding is decoded before being sent to the on_body callback.\r\n\r\nIs it possible to configure parser not to decode chunked encoding?\r\nI would like to receive chunks in `on_body` unmodified.", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/362/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "vinniefalco": {"issues": [{"url": "https://api.github.com/repos/nodejs/http-parser/issues/319", "title": "http-parser fails to detect chunked encoding at the end of a list", "body": "Given the header:\n\n```\nTransfer-Encoding: gzip, chunked\\r\\n\n```\n\nThe parser will not set chunked encoding when it should:\nhttps://tools.ietf.org/html/rfc7230#section-3.3.1\n\nEncodings are applied left to right and removed from right to left. If the parser encounters the `chunked` token as the last item when the Transfer-Encoding value is a comma separated list, it should consider the message body to be chunk encoded.\n\nI haven't actually tried this so I might be wrong but I see no code for finding a comma in Transfer-Encoding. However, the parser DOES handle comma separated lists correctly for the Connection header.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/319/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/318", "title": "http-parser impossible condition check", "body": "Consider this code (from http_parser.c):\n\n```\n            /* Transfer-Encoding: chunked */\n            case h_matching_transfer_encoding_chunked:\n              parser->index++;\n              if (parser->index > sizeof(CHUNKED)-1\n                  || c != CHUNKED[parser->index]) {\n                h_state = h_general;\n              } else if (parser->index == sizeof(CHUNKED)-2) {\n                h_state = h_transfer_encoding_chunked;\n              }\n              break;\n```\n\nIt seems `parser->index > sizeof(CHUNKED)-1` can never be true, because if the token being checked matches, we would set `h_state = h_transfer_encoding_chunked` before `parser->index` can ever exceed `sizeof(CHUNKED)-2`. And if the token being checked doesn't match, then we will set `h_state = h_general` before `parser->index` can exceed `sizeof(CHUNKED)-1`.\n\nI haven't actually tested this so I am not 100% sure.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/318/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/317", "title": "http-parser invalid octets allowed in reason-phrase", "body": "rfc7230 defines:\n\n```\nreason-phrase = *( HTAB / SP / VCHAR / obs-text )\n```\n\n`VCHAR` excludes all control characters except HTAB, but http-parser allows them:\nhttps://github.com/nodejs/http-parser/blob/f2c26ee500ab3921010fa7ec66243365611e77dd/http_parser.c#L916\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/317/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/315", "title": "http-parser allows extra spaces before the status code?", "body": "The strict definition of status-line is:\n\n```\n    status-line = HTTP-version SP status-code SP reason-phrase CRLF\n```\n\nBut the http-parser allows an unlimited number of spaces before status-code:\nhttps://github.com/nodejs/http-parser/blob/f2c26ee500ab3921010fa7ec66243365611e77dd/http_parser.c#L873\n\nShouldn't this be allowed only if `HTTP_PARSER_STRICT` is defined?\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/315/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/314", "title": "uri-parser allows extra characters after asterisk?", "body": "rfc7230 defines asterisk-form:\n\n```\nasterisk-form   = \"*\"\n```\n\nBut it seems `parse_url_char` allows additional characters after reading an asterisk. Note how state changes to `s_req_path` after encountering an asterisk at the beginning of the parse:\nhttps://github.com/nodejs/http-parser/blob/master/http_parser.c#L505\n\nIf I'm reading the code right this means the uri-parser considers `*/xyz` valid even though it does not follow the BNF in rfc7230.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/314/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/313", "title": "uri-parser incorrect escape of pct-encoded?", "body": "From rfc3986:\n\n```\nuserinfo      = *( unreserved / pct-encoded / sub-delims / \":\" )\npct-encoded   = \"%\" HEXDIG HEXDIG\n```\n\nHowever, `parse_url_char` accepts a percent symbol followed by any userinfo characters. For example this is valid in the server field: `x%z`\nhttps://github.com/nodejs/http-parser/blob/master/http_parser.c#L560\n\nIs this intended?\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/313/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/301", "title": "Is this valid according to rfc2616?", "body": "My reading of rfc2616 is that both spaces and horizontal tabs are allowed as LWS in field values:\n\n```\n LWS = [CRLF] 1*( SP | HT )\n```\n\nBut in http_parser.c where there should be checks for both SP and HT I see only a check for SP:\nhttps://github.com/nodejs/http-parser/blob/master/http_parser.c#L1660\n\nThat means the following HTTP message is malformed:\n\n```\nGET / HTTP/1.1\\r\\n\nHost: example.com:80\\r\\n\nConnection: keep-alive\\t\\r\\n\n\\r\\n\n```\n\nAm I reading this correctly?\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/301/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}], "commits": [{"url": "https://api.github.com/repos/nodejs/http-parser/commits/24e2d2d43f55d5f53e3f5d6e0532b9ea55c74b20", "message": "Allow HTTP_MAX_HEADER_SIZE to be defined externally"}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "nazar-pc": {"issues": [{"url": "https://api.github.com/repos/nodejs/http-parser/issues/309", "title": "Custom methods should be supported", "body": "Initially reported here: https://github.com/nghttp2/nghttp2/issues/602\n\nI see in sources big switch with [hardcoded](https://github.com/nodejs/http-parser/blob/f2c26ee500ab3921010fa7ec66243365611e77dd/http_parser.c#L968) HTTP methods and rejects any custom methods, however, there is nothing in specs that forbids usage of custom methods (see referred issue for examples).\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/309/reactions", "total_count": 6, "+1": 6, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "rtvd": {"issues": [{"url": "https://api.github.com/repos/nodejs/http-parser/issues/307", "title": "Making it easier to build it for OpenIndiana", "body": "Hello,\n\nI tried packaging this library for OpenIndiana.\nWould it be possible for you to have the following changes to the Makefile?\n1. Change `LIBDIR = $(PREFIX)/lib` to `LIBDIR ?= $(PREFIX)/lib` so that LIBDIR could be re-defined externally.\n2. Change both lines `ln -s $(LIBDIR)/$(SONAME) $(LIBDIR)/libhttp_parser.$(SOEXT)` to `ln -s $(SONAME) $(LIBDIR)/libhttp_parser.$(SOEXT)` so that relative paths are used for symbolic links.\n\nThank you.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/307/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "cbargren": {"issues": [{"url": "https://api.github.com/repos/nodejs/http-parser/issues/275", "title": "Support for digits, -, +, and . in uri scheme", "body": "The parser does not support non-alpha characters in the scheme of a URI. This is supported as part of the [spec for URIs](https://tools.ietf.org/html/rfc3986#section-3.1).\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/275/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/nodejs/http-parser/pulls/276", "title": "Add support for digits, '+', '-', and '.' to the scheme of a URI", "body": "Addresses #275.\n", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "wonder-mice": {"issues": [{"url": "https://api.github.com/repos/nodejs/http-parser/issues/257", "title": "CMake support", "body": "Hi, I'm going to write CMakeLists.txt for http-parser to use it in my project.\nI could put a bit more effort into it (add tests support, install step, etc.) if you are interested in merging CMake support in.\nI see that http-parser also has Make and GYP support, and having third build system could be too much.\nWhat do you think about it?\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/257/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "huyuguang": {"issues": [{"url": "https://api.github.com/repos/nodejs/http-parser/issues/251", "title": "HEAD, 1xx, 204, 304 have content-length but do not have body", "body": "There are some comments in http_parser.cc, line 1837:\n        /\\* Here we call the headers_complete callback. This is somewhat\n         \\* different than other callbacks because if the user returns 1, we\n         \\* will interpret that as saying that this message has no body. This\n         \\* is needed for the annoying case of recieving a response to a HEAD\n         \\* request.\n         *\n         \\* We'd like to use CALLBACK_NOTIFY_NOADVANCE() here but we cannot, so\n         \\* we have to simulate it by handling a change in errno below.\n         */\nExcludes the HEAD request, the 1xx, 204, 304 response also have Content-Length but do not have HTTP body.\n\nSo maybe the following code should add:\n\n```\n    if (settings->on_headers_complete) {\n      switch (settings->on_headers_complete(parser)) {\n        case 0:\n         if (status_code / 100 == 1 || status_code == 204 || status_code == 304)\n            parser->flags |= F_SKIPBODY;\n          break;\n```\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/251/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "hissohathair": {"issues": [{"url": "https://api.github.com/repos/nodejs/http-parser/issues/250", "title": "Parser type HTTP_BOTH only works for first HTTP message encountered?", "body": "In my application I don't know for sure if I'm about to receive a HTTP request or response, so I've been using HTTP_BOTH as the type argument to http_parser_init. I then read in my data stream and call http_parser_execute as the data comes in. The first HTTP message is always OK, but if the next HTTP message is a different type (eg first is a request but second is a response) then the parser raises a HPE_INVALID_METHOD error.\n\nYou can reproduce this behaviour with the parsertrace.c command in contrib. For example if you feed it [two GET requests in a row](http://pastebin.com/M8Bs2s90) it traces both messages fine.  But if you feed it [one GET and one response in a row](http://pastebin.com/xzpXPrUA) it aborts with the same error.\n\nSaving that second pastebin link to a file 'get-response.txt' and then calling parsertrace you'd get:\n\n``` bash\n$ ./contrib/parsertrace -b test-data/get-response.txt \n\n***MESSAGE BEGIN***\n\nUrl: http://www.google.com/\nHeader field: Host\nHeader value: www.google.com\nHeader field: Proxy-Connection\nHeader value: keep-alive\nHeader field: Cache-Control\nHeader value: max-age=0\nHeader field: Accept\nHeader value: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\nHeader field: User-Agent\nHeader value: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_8_2) AppleWebKit/537.17 (KHTML, like Gecko) Chrome/24.0.1312.52 Safari/537.17\nHeader field: X-Chrome-Variations\nHeader value: CK+1yQEIh7bJAQigtskBCKS2yQEIqLbJAQiptskBCLy2yQEI0IPKAQ==\nHeader field: DNT\nHeader value: 1\nHeader field: Accept-Encoding\nHeader value: gzip,deflate,sdch\nHeader field: Accept-Language\nHeader value: en-US,en;q=0.8\nHeader field: Accept-Charset\nHeader value: ISO-8859-1,utf-8;q=0.7,*;q=0.3\n\n***HEADERS COMPLETE***\n\n\n***MESSAGE COMPLETE***\n\n\n***MESSAGE BEGIN***\n\nError: invalid HTTP method (HPE_INVALID_METHOD)\n```\n\nBut maybe this is my error -- should I reset the http parser on message complete? I was doing that before but it seemed to cause issues with extra bytes (http_parser.c line 1901).\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/250/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "KjellSchubert": {"issues": [{"url": "https://api.github.com/repos/nodejs/http-parser/issues/238", "title": "http_parser should invoke the begin message callback on first byte, regardless of whether or not its valid", "body": "I'm creating this issue on behalf of the Proxygen team, to gauge the odds of the corresponding Proxygen fork's changeset being accepted back into http_parser, quoting Proxygen task description:\n\n> Title: http_parser should invoke the begin message callback on first byte, regardless of whether or not its valid\n> Summary: RIght now, http_parser calls the on_message callback only if the first byte of the message is valid. If any subsequent byte is invalid, it will call on_message_error. This is a bit weird, as it means that there's asymmetric behavior depending on which byte contains the error -- one cannot depend on on_message always being called before on_message_error.\n\n(I dont think there is an actual on_message_error callback, where it says on_message_error we mean the parser returns nparsed != recved). The current http_parser behavior for calling parse(\"ZZZZ\") is: the returned nparsed will be 0 (since a 'Z' doesnt start a valid HTTP request or response), on_message_begin will not be called. The Proxygen fork's behavior is: nparsed will also be 0, but on_message_begin will actually be called.\n\n@indutny : what are the odds of this change being accepted by your or the http_parser team in general? I'm asking this before I bother to create the pull request for this change, just in case the odds are slim to none. The change is not terribly complex, it adds 3 states s_pre_start_req_or_res s_pre_start_res s_pre_start_req plus a dozen lines of code plus a few tests.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/238/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}], "commits": [{"url": "https://api.github.com/repos/nodejs/http-parser/commits/dff604db203986e532e5a679bafd0e7382c6bdd9", "message": "src: support body in Upgrade requests\n\nInvoke message_complete cb for upgrade with body.\n\n(D1364677 + D1380182 orig author afrind@fb.com)\n\nFix: #234\nPR-URL: https://github.com/joyent/http-parser/pull/235\nReviewed-By: Fedor Indutny <fedor@indutny.com>"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/d7675453a6c03180572f084e95eea0d02df39164", "message": "src: callbacks chunk boundaries: header/complete\n\n(Proxygen fork merge D508755 D521404, orig author simpkins@fb.com)\n\nFix: #231\nPR-URL: https://github.com/joyent/http-parser/pull/233\nReviewed-By: Fedor Indutny <fedor@indutny.com>"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/2872cb7e6ac12ea356b943cf8f0b243c96b384f0", "message": "test: regression test for incomplete/corrupted hdr\n\nAdd regression test that verifies that old bugs regarding corrupted\nand incomplete headers are fixed.\n\n(D512233 + D570451, orig authors brianp@fb.com + jtarnawski@fb.com)\n\nPR-URL: https://github.com/joyent/http-parser/pull/236\nReviewed-By: Fedor Indutny <fedor@indutny.com>"}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": [{"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/28797112", "body": "It's not boring, I just wasn't sure what your project's stance was on trailing whitespace (my editors are usually configured to remove it globally). Anyway, now I know, I'll make sure I'll keep trailing ws intact from now on :)\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/28797112/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/28811082", "body": "I'm not the original author (just doing the selective merge), but I figure this change here is necessary to get the chunk_complete event out at the right time. Are you suggesting an alternative simpler solution? I can't think of one.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/28811082/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/28819155", "body": "Sure, I asked him (by mail) to respond to some of your questions earlier this morning, he'll hopefully chime in soon. In the mean time I tried an alternative implementation that;s slightly closer to your original one:\n\n```\n         UPDATE_STATE(s_message_done);\n          CALLBACK_NOTIFY_NOADVANCE(chunk_complete);\n          UPDATE_STATE(NEW_MESSAGE());\n          CALLBACK_NOTIFY(message_complete);\n          break;\n```\n\nThis variant passes tests and just adds the 2 lines for firing the chunk_complete event, so the diff may look slightly less scary. I have no strong preference for either solution, just slightly prefer the shorter committed one that reuses the 'case s_message_done:' (fewer LOC, plus we had this variant in production in the Proxygen branch for a long time).\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/28819155/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/28822859", "body": "I added some tracing for processing the test.c:TWO_CHUNKS_MULT_ZERO_END message, here the output:\n\n```\nCALLBACK_NOTIFY_ message_begin\nCALLBACK_DATA_ url mark[0]=/ len=25\nCALLBACK_DATA_ header_field mark[0]=T len=17\nCALLBACK_DATA_ header_value mark[0]=c len=7\nCALLBACK_NOTIFY_ chunk_header\ntest.c:chunk_header_cb p->content_length=5\nCALLBACK_DATA_ body mark[0]=h len=5\nCALLBACK_NOTIFY_ chunk_complete\nCALLBACK_NOTIFY_ chunk_header\ntest.c:chunk_header_cb p->content_length=6\nCALLBACK_DATA_ body mark[0]=  len=6\nCALLBACK_NOTIFY_ chunk_complete\nCALLBACK_NOTIFY_ chunk_header\ntest.c:chunk_header_cb p->content_length=0\nCALLBACK_NOTIFY_ chunk_complete\nCALLBACK_NOTIFY_ message_complete\n```\n\nI hope this answers your question: the chunk_header_cb is fired even for the final len=0 (pseudo) chunk, and the tests validate the number of chunks excluding this final len=0 one. Here you could ask: do we really want chunk_header + chunk_complete events for this final length=0 chunk or not. I prefer having this callback (since the parser's job is to markup byte blocks in the byte stream with their meaning, including the meaning for 0 or 000 as a chunk list terminator).\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/28822859/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/28827640", "body": "True, I didn't understand this part fully either. In the tests I see stuff like\n\n```\n,.num_chunks= 0\n,.num_chunks_complete= 1\n```\n\nbut it looks to me like num_chunks_complete is always one larger than num_chunks, so whats the point of having both? Let me see if I can collapse these to one, checking with the original proxygen changeset's author if necessary...\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/28827640/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/28831936", "body": "OK, removed the redundant num_chunks in test declarations, see 33a79079b56af1390398d7862d2dba865e2e0002.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/28831936/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}]}, "bch": {"issues": [{"url": "https://api.github.com/repos/nodejs/http-parser/issues/130", "title": "proper behavior for wikipedia-style URIs?", "body": "Hit  http://en.wikipedia.org/wiki/Main_Page, take a look at the resultant HTML and notice that lots of its refs are of a form: \"//some.server/path/starts/here\", but without any transport. Feeding that to parse_url current interprets the whole thing as a path. Should it better handle the initial \"//\"?\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/130/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "AndreLouisCaron": {"issues": [{"url": "https://api.github.com/repos/nodejs/http-parser/issues/97", "title": "Forcing a pause at the end of HTTP headers", "body": "I've implemented a [simple C++ wrapper](https://github.com/AndreLouisCaron/httpxx) for the `http-parser` library and ran into a problem when using the parser pause feature.\n\nBasically, I have a `Request` object that wraps a `http_parser` instance.  This request object has a `feed()` method which invokes `http_parser_execute()`.  The request object also has a `headers_complete()` which reports the end of HTTP headers.  To make this test reliable (mainly for proxying purposes), I force `http_parser_execute()` to return by pausing the parser calling `http_parser_pause()` from the `on_headers_complete()` callback.  All this seemingly works, except that it doesn't consume the last byte of a request without a body.  To finish processing the request, I have to call `http_parser_execute()` again with the last byte of data.\n\nNow, calling `feed()`/`http_parser_execute()` one extra time is not that much of a problem, except that it makes it prevents clients from accurately finding the exact position of the end of HTTP headers.  In a proxying scenario (HTTP proxy, CGI/SCGI/FastCGI or even WebSockets), where you want to forward the body byte-for-byte, clients end up prefixing the HTTP request body with an extra byte.\n\nThis was reported to me on the `httpxx` issue tracker, but I believe it's an issue in `http-parser`.  Basically, the `on_headers_complete()` callback is called upon examining the last byte of the header data, and pausing in that callback prevents the library from marking the last byte (the one the triggered the callback) as consumed.\n\nVisit the `httpx` issue #5 for a [detailed discussion](https://github.com/AndreLouisCaron/httpxx/issues/5).  If it's unclear, I might be able to concoct an [SSCCE](http://sscce.org) that illustrates the problem.\n\nNote: this issue seems related to [pull request 89](https://github.com/joyent/http-parser/pull/89).\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/97/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}], "commits": [{"url": "https://api.github.com/repos/nodejs/http-parser/commits/051d6fe219b50c0c129d14493db09a19dcbe88fe", "message": "Fixes build on MSVC."}], "pull_requests": [], "issue_comments": [{"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1602078", "body": "> That issue is the fact http-parser is not a true streaming parser. If you were to send a non-blocking byte-by-byte request your callbacks get invoked many times\n\n@ellzey: I'm new to this library, and I've also found this intriguing.  However, I'm under the impression that this is a consequence of the fact that no data is buffered inside the `http_parser` structure.  To have the parser invoke the callback only once, it would need to buffer whatever content there was.  I find that this library is cool precisely _because_ it doesn't buffer the data.  In any case, changing this behavior seems like a completely different issue.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1602078/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1602372", "body": "@ellzey: Precisely my point.  You introduced a staging area to buffer data before invoking the hooks.   Classic space/time tradeoff.  Because the data length is variable and your staging area is of fixed length, the best you can do is minimize the number of times that the hooks are invoked and you can't guarantee that the hooks will only be called once, unless you use a very large staging area.  A small staging area only benefits situations where you get data in piecemeal increments and a large staging area kills the \"small footprint\" objective of this library.\n\nIn any case, this is a totally different issue from the Path+QueryString+Fragment+URL VS. only URL issue.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1602372/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3601108", "body": "I signed it right before sending the pull request.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3601108/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3601146", "body": "It looks like the same one I signed before, but the URL is different (check the `CONRIBUTIONS` file).  I signed this one too just to make sure.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3601146/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4196845", "body": "I've hacked a workaround in AndreLouisCaron/httpxx@608af01eee7cfdad579381f61edf70778eedaa58, but it's really ugly. I have to manually fix off-by-one errors because of this bug, and the count is unreliable until the `on_message_complete()` callback is called so that I can fix it.\n\nIf someone has a clear idea on how to fix this issue without breaking everything, I might be able to put in some time to fix it.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4196845/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4198946", "body": "I'll go out on a limb here, but it seems to me that we're approaching the problem from the wrong angle.  Rather than trying to fix the thorny issue of marking the last byte, wouldn't it be easier to play on the pausing semantics?  I don't really care if more callbacks are invoked after I pause the parser (e.g. `on_message_complete()` for an empty message), so long as it pauses \"soon\".\n\nPausing is currently implemented by using a special error code, which happens to be temporary (the client can reset it by calling `http_parser_pause(&parser, 0);`).  The real issue here it that the parser does not distinguish between `HPE_PAUSED` and real error codes.  A more flexible approach to pausing would prevent the parser from continuing after a change of state (e.g. from \"parsing headers\" to \"parsing body\").\n\nAny ideas on this?\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4198946/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4208941", "body": "> > If not, I think the easiest 'fix' would be to implement pause as \"don't consume any more bytes (but call whatever callbacks are necessary)\" instead of \"stop doing anything\".\n> \n> Yeah, that's certainly an option.\n\nSorry if I wasn't clear when I said I wanted the parser to stop \"soon\".   This is what I had in mind.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4208941/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4227229", "body": ">  I think the easiest 'fix' would be to implement pause as \"don't consume any more bytes (but call whatever callbacks are necessary)\" instead of \"stop doing anything\".\n\nI've worked around the issue to implement exactly this in AndreLouisCaron/httpxx@fbd0422dfeaaa53d62956a3dee302d3f704714a4.  It only works for processing the last byte after the headers, but it fixes the only instance of this problem I've encountered so far (somehow, pausing in `on_message_complete()`  correctly reports all bytes as consumed).\n\nI would still prefer this was fixed in `http-parser` for all (potential) cases, but if there is a serious design problem in implementing a real fix, I can live with this bug as long as the exact behavior of `http_parser_pause()` is documented so that no one gets \"bitten\" by this problem.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4227229/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4231984", "body": "I looked at [bnoordhuis's new test case](https://github.com/joyent/http-parser/issues/97#issuecomment-4193300) and it prevents pausing in `on_headers_complete` from invoking `on_message_complete`.  I don' t think this can ever be satisfied if we fix this issue since empty requests absolutely need to call both callbacks before marking the last byte as consumed.\n\nI pushed a sample fix that just addresses the specific case of letting `on_message_complete` be called when the parser is paused from `on_headers_complete`.  It breaks current tests for pausing, which validate that absolutely no more callbacks should be called after a pause.  All other tests still pass, but **don't use this** since I think this is somewhat of a hack, and I'm not sure what the behavior is for pausing in other callbacks (e.g. `on_url()`).\n\n> I think everyone agrees that it should be fixed on our side, the question is how?\n\nFirst, we need to define the semantics of pausing.  Should pausing be allowed all callbacks, or should it be limited to specific cases?  AFAICT, the only interesting places to call this are in `on_headers_complete` for proxying purposes and in `on_message_complete` for HTTP/1.1 pipelined requests.\n\nAlso, in what (other) cases is this a problem?  So far, the only problematic instance is for `on_headers_complete()`, which must potentially call `on_message_complete` when the request has no body.  Are there any other situations that can call more than one callback for a single byte?\n\nSince it already works for the `on_message_complete` callback and it's a question of a single byte in `on_headers_complete` and other cases don't seem so interesting, can we just hack in a solution for the `on_headers_complete` case and document  `http_parser_pause` as only supported in those two callbacks?\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4231984/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4232082", "body": "After further reading of the code, it seems to me that the only risky bits are parser states that use `goto reexecute_byte;` _and execute callbacks_.  I only found only two states that do this:\n1. `s_body_identity`; and\n2. `s_headers_almost_done`.\n\nFWIW, the latter is our problematic case and the former already has somewhat of a hack:\n\n``` C\n/* Mimic CALLBACK_DATA_NOADVANCE() but with one extra byte.\n *\n * The alternative to doing this is to wait for the next byte to\n * trigger the data callback, just as in every other case. The\n * problem with this is that this makes it difficult for the test\n * harness to distinguish between complete-on-EOF and\n * complete-on-length. It's not clear that this distinction is\n * important for applications, but let's keep it for now.\n */\n CALLBACK_DATA_(body, p - body_mark + 1, p - data);\n goto reexecute_byte;\n```\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4232082/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4232233", "body": ">  Couldn't they consume the last byte, but leave the parser in a state of s_paused_before_message_complete, and have that state just call the callback and then do \"goto reexecute_byte;\"?\n\nHadn't thought of introducing anoher state!  However, I don't think this will work, since the byte will no longer available on the next call to `http_parser_execute` (the client will have considered it already consumed by the parser).  Also, that would mean that on an empty request, the client would have to call `http_parser_execute` with 0 bytes to \"complete\" the message even though all the message data has been processed, and I believe this breaks one of the key invariants of `http-parser`.  See [pgriess's earlier comment](https://github.com/joyent/http-parser/issues/97#issuecomment-4197874).\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4232233/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}], "commit_comments": [], "review_comments": []}, "grobian": {"issues": [], "commits": [{"url": "https://api.github.com/repos/nodejs/http-parser/commits/fd3850c048f7a69db2f066d267797fbc3680d9a0", "message": "Makefile: set install_name on macos\n\ninstall_name on Mach-O is similar to SONAME on ELF, except that it needs\na full path instead of just the basename.\n\nFixes: https://github.com/nodejs/http-parser/issues/356\nPR-URL: https://github.com/nodejs/http-parser/pull/358\nReviewed-By: Ben Noordhuis <info@bnoordhuis.nl>"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/8ea9532378291b5a9c27ab61bb5cff336cc396b5", "message": "Makefile: set versions for SONAME correctly\n\nRaised in issue #356, reduce version number in SONAME to MAJOR.MINOR.\nWhile at it, create a symlink the from SONAME to the library, instead of\nthe other way around, and add a (standard) unversioned symlink to the\nlibrary to aid the ordinary linking process.\n\nPR-URL: https://github.com/nodejs/http-parser/pull/359\nReviewed-By: Ben Noordhuis <info@bnoordhuis.nl>\nReviewed-By: Fedor Indutny <fedor@indutny.com>"}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "bnoordhuis": {"issues": [], "commits": [{"url": "https://api.github.com/repos/nodejs/http-parser/commits/89279ab6135a63159200928da6e544135bf98301", "message": "Update license boilerplate.\n\nThe boilerplate included attribution to NGINX that created confusion\nbecause NGINX is distributed under a different license (BSD, not MIT.)\n\nTo the best of everyone's knowledge, no actual NGINX code remains.\nRemove the attribution to clear up the confusion.\n\nFixes: https://github.com/nodejs/http-parser/issues/389\nPR-URL: https://github.com/nodejs/http-parser/pull/390\nReviewed-By: Fedor Indutny <fedor@indutny.com>"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/05525c5fde1fc562481f6ae08fa7056185325daf", "message": "Ignore Upgrade header outside of 101 response.\n\nPR-URL: https://github.com/nodejs/http-parser/pull/364\nReviewed-By: Fedor Indutny <fedor@indutny.com>"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/260c52233044cdfad4d84b01d3dba11c2786c794", "message": "Fix typo in test name.\n\nPR-URL: https://github.com/nodejs/http-parser/pull/364\nReviewed-By: Fedor Indutny <fedor@indutny.com>"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/cacb07d2b4ebcd86fc44fd6ee3f0020125e7a9a6", "message": "parser: fix Content-Length header parsing.\n\nCommit e2e467b (\"Update http-parser to 2.6.1\") enforces that messages\ncontain no more than one Content-Length header but it considers any\nheader that starts with \"Content-Length\" as a duplicate.\n\nFix: https://github.com/nodejs/http-parser/issues/324\nPR-URL: https://github.com/nodejs/http-parser/pull/325\nReviewed-By: Fedor Indutny <fedor@indutny.com>\nReviewed-By: James M Snell <jasnell@gmail.com>"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/f5c779bb8502ea9632d8894309f7e737efce5ef9", "message": "Update misleading comment.\n\nThe HTTP_MAX_HEADER_SIZE check is not there to guard against\nbuffer overflows, it's there to protect unwitting embedders\nagainst denial-of-service attacks."}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/3cbd13daca608ba92d2ce2cd6b6e6e5ba3730339", "message": "test: add amazon.com response test"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/547553b0909c9ce10a3730baeff7c7d1f76c0ea6", "message": "Further request method check strengthening."}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/d3264312e131bd281007eaad6909f2d2fba01e5f", "message": "Add function http_parser_version().\n\nFixes #115."}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/6df37aa52d7063a5dde0c86b5b0c992756b67577", "message": "build: set SONAME in shared object file\n\nFixes #151."}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/80819384450b5511a3d1c424dd92a5843c891364", "message": "Bump to version 2.1"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/e77957a091719e98ef2fe1fccfe2e89c9b46f034", "message": "Update AUTHORS and .mailmap"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/120a2c5c9b21952715bea00f7024d4f91d8d5c25", "message": "Move url_parser.c to contrib/"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/fe9fb34e538f9c51b6f0aec4e73bb2318d6827cf", "message": "Update AUTHORS and .mailmap"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/43ccd6aa7667194a60ac8b7ca82a25c999e3e54a", "message": "Update AUTHORS"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/cd01361819463af82e2c6cc088f47ad4a9bc0133", "message": "test: fix buffer overflow in large header test\n\nFixes #136."}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/14d42be21aacb1b3d67cf4e1532f0afaee342f9a", "message": "test: use error-checking strncat/strncpy replacements"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/245f6f007881fc6cb752e0fc6641bc0c8910e857", "message": "Remove HTTP_PARSER_DEBUG macro.\n\nRemove the HTTP_PARSER_DEBUG macro for two reasons:\n\n* It changes the size of struct http_parser, resulting in spurious memory\n  corruption bugs if part of your application is built with HTTP_PARSER_DEBUG=1\n  and other parts with HTTP_PARSER_DEBUG=0.\n\n* It's a debugging tool for maintainers. It should never have been exposed in\n  the API in the first place."}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/02f06ff290a62e2213e738a247c3dc8be78ed043", "message": "gitignore: ignore gyp build dir"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/a0fd3323ddaa3cb5123ea6a8beca9776ff134c02", "message": "build: add default build flags to gyp script"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/ce6d7efff74ee19cb75d6ccd3af4b8f3bd63f3d6", "message": "build: compile strict and non-strict tests\n\nMake gyp compile the library and the test suite in both strict and non-strict\nmode.\n\nFixes a failing test where the test was strict but the library was not.\n\nFixes #129."}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/3fb4e061ec106077f5f1a1279c2dcd9c158e009b", "message": "Bump to version 2.0"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/0e67f6b532d788eb57615ac066117e4fd23887de", "message": "Update AUTHORS"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/ad3b631d4f1b4524f7acca5d5c2e67f844ee21e4", "message": "Turn normal_url_char into a bit array.\n\nMakes http_parser slightly more cache friendly."}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/4e1a6ab65582609a645ff4047806de375164aa63", "message": "Update AUTHORS"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/add3018ce7281d87e4cc2b82c4884858a66eecd3", "message": "Add bounds check to http_method_str()."}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/9f92347851e2a408a9ac6669e63f82d271476d72", "message": "Make http_should_keep_alive() const correct."}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/2b7e87cc778f45a88fc49d92da13a658a9f1ad4b", "message": "Fix bad http_should_keep_alive() comment."}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/b97fdb051307afe018bf22b5f09cc83e83fec6e9", "message": "Don't assert() on whitespace in URL.\n\nBe lenient about tabs and form feeds in non-strict mode."}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/8bec3ea459fe2369a1e7d4d08f1ac598eb877247", "message": "Create method_strings array with HTTP_METHOD_MAP macro."}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/36808f4fad0d6ccda8ee0d5e199fe30691242952", "message": "Replace HTTP methods enum with X-macro map.\n\nMakes it easier for integrators to generate bindings for the HTTP methods that\nwe support. Example:\n\n    // stringify method names\n    const char *methods[] = {\n    #define XX(num, name) #name,\n    HTTP_METHOD_MAP(XX)\n    #undef XX\n    };"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/99c08502402bfe6480ab56db6255603cea49fa62", "message": "test: abort(), don't exit()\n\nMakes it easier to debug failing test cases: abort() dumps core and asserts\nin a debugger."}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/efb72f175ce3899861d98855b4335117a5ef754e", "message": "Remove unused struct http_parser_result from header."}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/c6e10e98e349d772692bf75198006b4b527fa80e", "message": "docs: update links to examples"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/f4053c719c3ba3f52c3bb22ec5f9e6d1917d3bfa", "message": ".gitignore gyp build artifacts"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/62110efe7ae268d6e6435ac0e7e7690c0e998655", "message": "Support PURGE request method.\n\nFixes joyent/node#2775."}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/7bc668c5f47f26c8bfa34c106898fb1a940d43ca", "message": "Update AUTHORS"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/c3153bd1a949ab86e4601ff6481aed95bfcea196", "message": "Eat CRLF between requests, even on connection:close.\n\nFixes #47."}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/489860682620ea5af40490e013f4ee821b472482", "message": "Add AUTHORS and .mailmap files."}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/89a9da056086112d88f3076246e9a7cbdc91c446", "message": "Merge pull request #78 from bnoordhuis/unsigned-content-length\n\nMake content_length unsigned, add overflow checks."}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/f668e723800b65113ec55643fc011c930c0cc9d5", "message": "Make content_length unsigned, add overflow checks."}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/3e626c6cb632f488cc8f9f5bbb4ca5a2d87bef19", "message": "Don't use 'inline'.\n\n'inline' is not a recognized C89 keyword, it made the build fail with strict or\nolder compilers (msvc 2008, gcc with -std=c89).\n\n'inline' is also just a hint, one that gcc 4.4.3 in this particular case happily\nignored. Ergo, remove it."}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/e4c13a878420aefa8dfc49c76fd910a71669517d", "message": "Merge pull request #82 from ivosh/master\n\nhttp_parser_init does not clear status_code"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/7f89b913144d96fbecfa0905b7e153659bd68490", "message": "Merge pull request #77 from AndreLouisCaron/compile-fix\n\nFixes build on MSVC."}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/75dc103fd020fa30fe7389cad07ad30114f9f531", "message": "Single-bit bitfield 'upgrade' should be unsigned.\n\nFixes sparse error report: dubious one-bit signed bitfield."}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/cbb194ea8cdf8e4b26ee4f59c0b72f5c96a85c15", "message": "Replace C++ style comments with C comments so it compiles with `gcc -ansi -Wall`"}], "pull_requests": [], "issue_comments": [{"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1143743", "body": "Jonas, on what platforms / architectures are you having linker trouble?\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1143743/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1145876", "body": "I think I see what you mean. This is for bjoern, right? And you are trying to build a .so with a non-PIC http_parser.o? This can be fixed from within bjoern, I'll try to submit a pull request later today. I don't think it's a good idea to add this to the default http-parser build flags, PIC code is often slower and bigger than non-PIC code.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1145876/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1149222", "body": "You're confusing two things here, Jonas. A .so is compiled with -fPIC because it's shared among processes and each process loads it at a different location (in theory anyway). Client code that links against a shared object doesn't have to be position independent unless it's a shared object itself - which is the case for bjoern.so.\n\nThe idea behind https://github.com/ry/http-parser/pull/40 and https://github.com/jonashaag/bjoern/pull/35 is that the integrator decides whether or not to compile with -fPIC. The PIC version of http_parser.o uses 16 additional cache lines on my Core 2 Duo so I'd rather not see it as the default in node.js.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1149222/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1383331", "body": "Fixed if you can live with the fact that message_complete_on_eof == FALSE. The on_message_complete event fires when there is still data in the input buffer so currently_parsing_eof is FALSE at that point.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1383331/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1384827", "body": "I love how GitHub gets confused when you prune/delete branches. The commits that matter are cc58dd715b47042abd6d86783c9e4b30e816ff9b and 41ac20859fe0c7bf1b3e391edf4c16381297bc49.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1384827/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/2229992", "body": "477ca43 bumps `sizeof(http_parser)` from 28 to 32 on i386 and 32 to 40 on x86_64 (likewise for b2c5568). If the sole purpose is to placate an overzealous compiler, I'd rather drop it.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/2229992/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/2265636", "body": "Thanks, Paul. Merged in f1d48aa.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/2265636/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/2482506", "body": "For future reference, you need to pass a few additional arguments: `-Dlibrary=static_library -Dcomponent=static_library`\n\nThat's not necessary if you check out the upstream version at joyent/http-parser, by the way.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/2482506/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3354199", "body": "See #54 and #58. Older versions of http-parser had those callbacks but they were removed for the reasons stipulated in #54.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3354199/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3375874", "body": "Otherwise LGTM (though it probably won't hurt to have it reviewed by at least one more person).\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3375874/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3392670", "body": "LGTM. One or two test cases would be good.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3392670/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3398724", "body": "LGTM.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3398724/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3412640", "body": "Do we want it fixed? Bug or feature, you can argue either way.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3412640/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3599246", "body": "Why don't we turn `content_length` into an `uint64_t`? The reason it's signed is to assign -1 as a guard value but `(uint64_t) -1` would work just as well for that.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3599246/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3599344", "body": "bnoordhuis/http-parser@6185bcb does exactly that.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3599344/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3600192", "body": "> If it were me, I'd check explicitly and fail when a message comes through that is logically too large to be handled correctly by the parser\n\nYou're right. I added overflow checks in bnoordhuis/http-parser@1f0250a.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3600192/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3600198", "body": "Looks good, thanks. I'll merge it but can you sign [the CLA](http://nodejs.org/cla.html) first?\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3600198/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3603834", "body": "Thanks, Andr\u00e9. Didn't see you on the list yesterday but you're there now. Merged in 7f89b91.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3603834/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3631354", "body": "Thanks, but like @koichik said, it's not possible to determine the response body's size so there is no alternative but to read until EOF.\n\nThe 'single-line response to a HEAD request' case doesn't set the keep-alive flag right now because the parser doesn't know that it's a response to a HEAD request. I suppose that could be fixed (probably not easily) and it should be sufficiently uncommon that it's a minor optimization at best.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3631354/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3632345", "body": "@koichik: You're right. So much the better.\n\n@gwik: See #72. The 'read until EOF if no Content-Length' behaviour was added in response to real-world scenarios.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3632345/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3688139", "body": "Looks good, Ivo. You're right about the other C99-isms but we try to keep the number of infidelities to a minimum. I'll merge it but can you sign [the CLA](http://spreadsheets2.google.com/viewform?hl=en&formkey=dDJXOGUwbzlYaWM4cHN1MERwQS1CSnc6MQ) first?\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3688139/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3692616", "body": "Thanks Ivo, merged in e4c13a8.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3692616/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3692909", "body": "Thanks, James. I decided to simply remove inline altogether in 3e626c6 since the function wasn't getting inlined anyway. I merged your other commit in 03e0d52.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3692909/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3692964", "body": "Fixed in 89a9da0.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3692964/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3692982", "body": "Closing. Please submit a new PR if you're still interested in seeing these changes land.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3692982/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3693025", "body": "This PR is pretty stale by now. Do we still want this functionality?\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3693025/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3837821", "body": "LGTM at first glance. Can you add one or two tests of the 'fails before, passes afterwards' variety?\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3837821/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3858112", "body": "It doesn't have to be complicated, you can just call your test from inside `main()`. See `test_preserve_data()` for an example.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3858112/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3869430", "body": "Otherwise LGTM. Can you sign [the CLA](http://spreadsheets2.google.com/viewform?hl=en&formkey=dDJXOGUwbzlYaWM4cHN1MERwQS1CSnc6MQ) if you haven't already?\n\nOther committers: aye or nay? I say aye and if you don't respond in a timely manner, aye it is. >:-)\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3869430/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3889212", "body": "I suppose I could tag it v1.1 or v2.0 but what does it mean? There's been steady on-going development. I don't know of a key commit that would warrant a version bump. It'd be somewhat arbitrary.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3889212/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3896058", "body": "Thanks David, merged in 0499525. Your comment about formatting is duly noted. :-)\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3896058/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3896103", "body": "Merged in c3153bd.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3896103/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3896554", "body": "Fair point about the API changes. I'll tag v2.0 in a week or two, remind me if I forget.\n\nFor now, use 2498961 if you want a newer-but-stable commit to work with, it's what node.js ships with.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3896554/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3896630", "body": "Closing, no response in almost two weeks.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3896630/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3917070", "body": "LGTM. Can you sign [the CLA](http://spreadsheets2.google.com/viewform?hl=en&formkey=dDJXOGUwbzlYaWM4cHN1MERwQS1CSnc6MQ)?\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3917070/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3940142", "body": "Can you sign [the CLA](http://spreadsheets2.google.com/viewform?hl=en&formkey=dDJXOGUwbzlYaWM4cHN1MERwQS1CSnc6MQ)? It's different from the Node CLA.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3940142/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3943623", "body": "Thanks Thomas, merged in f1fe50e.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3943623/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3960824", "body": "> i still hate git.\n\nIt grows on you. Then again, so does fungus.\n\nThe patch LGTM. Other committers, aye or naye?\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3960824/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3973188", "body": "Thanks, I'll happily merge your patch but I'm afraid I need a signed [CLA](http://spreadsheets2.google.com/viewform?hl=en&formkey=dDJXOGUwbzlYaWM4cHN1MERwQS1CSnc6MQ) first.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3973188/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3979500", "body": "Thanks Randy, merged in b215eaa. It's odd, I didn't see you on the list yesterday but you're on it twice now. Maybe the first one got delayed in a queue somewhere. Anyway, thanks again!\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3979500/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3979582", "body": "Thanks, I'll merge your patch if you can sign [the CLA](http://spreadsheets2.google.com/viewform?hl=en&formkey=dDJXOGUwbzlYaWM4cHN1MERwQS1CSnc6MQ). You should probably report this error to the cygwin maintainers, it looks like a bug in the implementation of `isspace()`.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3979582/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3979726", "body": "Okay, no problem.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3979726/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3979948", "body": "> This is sad. A one line patch does not require a CLA.\n\nWhere do you draw the line? A two-line patch? Three? Ten? Better to be strict and consistent.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3979948/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4029073", "body": "See #93.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4029073/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4030785", "body": "I interpret silence as agreement. Thanks David, merged in 8da60bc.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4030785/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4038258", "body": "Thanks David, merged in 6756842 and 662e523. I carved up the commits a little, the new test is now part of 6756842.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4038258/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4042543", "body": "Fixed in 6756842.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4042543/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4045560", "body": "I can't reproduce whatever it is you're experiencing. I added a test in bnoordhuis/http-parser@332ee6a and it's passing. Can you post a test case of your own?\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4045560/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4046134", "body": "> My callback function was returning the number of bytes processed, while the http_parser was halting if anything other than 0 was returned, as far as I understand.\n\nThat's correct. You're supposed to return `HPE_OK`, anything else signals an error.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4046134/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4055210", "body": "Thanks, Dave. Landed in 62110ef.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4055210/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4155711", "body": "Thanks Andr\u00e9, merged in 9db90de.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4155711/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4155734", "body": "Fixed in 8da60bc.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4155734/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4155760", "body": "Fixed in 8da60bc.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4155760/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4193300", "body": "Confirmed.\n\nIt's annoying: while it's obviously a bug, fixing it breaks a number of assumptions that http-parser users may have made about the order of events or when it's safe to call the parser (evidenced by the number of tests the fix breaks).\n\nRock, meet hard place.\n\nEDIT: I've added a failing test in bnoordhuis/http-parser@e3028fe.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4193300/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4219890", "body": "No particular reason. I imagined I might someday want to stuff them into an array, something like that.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4219890/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4221187", "body": "Merged in 36808f4.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4221187/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4229606", "body": "> I would still prefer this was fixed in http-parser for all (potential) cases, but if there is a serious design problem in implementing a real fix, I can live with this bug\n\nI think everyone agrees that it should be fixed on our side, the question is how?\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4229606/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4255676", "body": "@jduell: Can you post the verbatim HTTP headers? I can't get http://www.twimbow.com/dashboard.php to send me any WS upgrade headers.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4255676/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4260264", "body": "> Here's your reminder. Lots of activity on the project: clearing issues out for a tag?\n\nYes, kind of. There are two issues I want to lick (#97 and #99, provided that last one turns out to be a real bug) and then I'll put out v2.0.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4260264/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4285569", "body": "Okay, I think @einaros is right: this is not a node or http-parser bug. I was under the impression that the client sent a Connection header without an Upgrade header (technically a violation of the spec but something we could work around) but that's not the case.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4285569/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}], "commit_comments": [{"url": "https://api.github.com/repos/nodejs/http-parser/comments/2916835", "body": "> What is the status_complete is for?\n\nTo deal with HTTP/0.9 responses.\n\n\"breaks my program\" is a little vague but I'm guessing it's an ABI issue. Do a clean rebuild of http_parser and your project.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/comments/2916835/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/comments/2920375", "body": "node.js ships an older http_parser version. If you build your add-on against a newer version, you need to link that newer version statically against your add-on or bad things will happen.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/comments/2920375/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/comments/2920561", "body": "Bundle http_parser with your add-on and declare it as a dependency in your gyp file.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/comments/2920561/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/comments/3052379", "body": "I wager you're looking at an old version of http-parser. With the current master (8081938) the logic you describe is around line 1300. But yeah, it will accept headers without values for the sake of interoperability (think: buggy servers.)\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/comments/3052379/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/comments/8854628", "body": "It looks alright to me, at a glance.  You already landed it, right?\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/comments/8854628/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}], "review_comments": [{"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/330920", "body": "Trailing whitespace.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/330920/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/330921", "body": "s/seciont/section/\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/330921/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/330929", "body": "Maybe avoid the extra level of indentation:\n\n``` c\nif (parser->type != HTTP_RESPONSE) {\n  return 1;\n}\nif (parser->status_code / 100 == 1 || /* etc */\n```\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/330929/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/334905", "body": "s/swtich/switch/\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/334905/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/334906", "body": "Trailing whitespace. Happens in one other place too.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/334906/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/334909", "body": "This doesn't catch URLs like `http://example.com:/`, v will be zero. I'm not sure if that's a bug or a feature.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/334909/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/387694", "body": "James, isn't that redundant? If the `on_headers_complete` callback hasn't fired yet, you know you're still parsing headers.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/387694/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/391760", "body": "You need to preserve `parser->data`.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/391760/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/374878", "body": "No, to make it easier to detect overflow (signed overflow is undefined, unsigned overflow is not).\n\n`(uint64_t) -1` is a shorthand / fallback for ULLONG_MAX.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/374878/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/374920", "body": "Yes-ish. The reason that I don't is that `<limits.h>` doesn't always define it. I can add something like this:\n\n``` c\n#include <limits.h>\n\n#ifndef ULLONG_MAX\n#define ULLONG_MAX ((uint64_t) -1)\n#endif\n```\n\nYour call.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/374920/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/374981", "body": "Cool. Updated in 8f290a5.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/374981/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/427578", "body": "Style issue: arguments should line up if split over multiple lines.\n\n``` c\nrv = http_parser_parse_url(test->url,\n                           strlen(test->url),\n                           test->is_connect,\n                           &u);\n```\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/427578/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/428125", "body": "Sorry, missed this one. Don't use `u_int`, it's a POSIX-ism.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/428125/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/1039622", "body": "What's this supposed to do?\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/1039622/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/1039624", "body": "Oh, I think I get it - you need to know _if_ this version of http-parser is compiled in debug mode.\n\nI initially read it as a switch to turn on/off debug mode.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/1039624/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/1175064", "body": "Wrap at 80 columns.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/1175064/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/1175069", "body": "Style: too much whitespace.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/1175069/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/1175077", "body": "Use NULL, not zero. Signals to the reader that it's a pointer.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/1175077/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/1175083", "body": "Superfluous blank line.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/1175083/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/1175089", "body": "Why is that here?\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/1175089/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/1175091", "body": "Don't use C++/C99 comments.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/1175091/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/1175101", "body": "Long line.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/1175101/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/1175104", "body": "Long line.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/1175104/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/1175114", "body": "Why the side channel? Why not e.g. a separate s_req_host_at state?\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/1175114/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/1506586", "body": "Non-idiomatic code, use `return parser->state == s_message_done;`\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/1506586/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/1506594", "body": "s/checks/Checks/ and add punctuation. (Yes, I'm a language/grammar Nazi).\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/1506594/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/1506598", "body": "Style: brace on the same line.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/1506598/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/1506602", "body": "Long line, wrap at 80 columns.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/1506602/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/1729080", "body": "Why is this necessary and are you confident that it won't break MSVS 2008 or 2010?\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/1729080/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/2406821", "body": "Preferably use `(void) arg;` if you want to squelch unused argument warnings. `__attribute__((unused))` is a gcc extension.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/2406821/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/2406826", "body": "Doesn't have to be malloc'd.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/2406826/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/2406833", "body": "Free this at the end.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/2406833/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/2406843", "body": "Use fopen/fread/fclose instead? open/read/close are only available on POSIX platforms.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/2406843/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/2406849", "body": "Not (void*), just (void). :-)\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/2406849/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/2429726", "body": "Put this in a function `void usage(void)`. Backward gotos are a minor evil.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/2429726/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/2429727", "body": "Indent error.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/2429727/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/2429728", "body": "Why the cast to unsigned? It does the wrong thing when ftell() returns -1.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/2429728/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/2429730", "body": "Style: space between if and paren.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/2429730/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/2429731", "body": "And a style thing: arguments need to line up.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/2429731/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/2429732", "body": "Can't this be `#include \"http_parser.h\"`?\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/2429732/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/2429735", "body": "Last style issue: http_parser uses `type*`, not `type *` (i.e. no space).\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/2429735/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/2666920", "body": "Wrong fork. :-)\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/2666920/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/2689399", "body": "Sorry, I can't take this. http_parser tries very hard remain small and lightweight. sizeof(http_parser) == 32 bytes on x86_64 and now you add a 4 kB buffer?\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/2689399/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/2705414", "body": "Style errors: missing spaces.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/2705414/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/2705415", "body": "Remove this obsolete comment.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/2705415/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/2705417", "body": "Style: Newline here.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/2705417/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/2705419", "body": "Style\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/2705419/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/2705421", "body": "That's to silence unused argument warnings? Use this instead:\n\n``` c\n(void) p;\n(void) buf;\n(void) len;\n```\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/2705421/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/2705423", "body": "Sorry, ignore that comment. I see that the other callbacks do the same thing.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/2705423/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/21046584", "body": "I believe this will parse e.g. `\"Foo: bar\\nBar: baz\\r\\n\"` incorrectly.  You should probably scan forward one character at a time until you find CR _or_ LF.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/21046584/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/21046830", "body": "I'm not sure I follow.  With `\"Foo: bar\\nBar: baz\\r\\n\"` as input, this code would skip to the `'\\r'` character and miss the Baz header altogether, right?\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/21046830/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/26346025", "body": "Can you add `INSTALL ?= install` at the top and use that instead of a literal `install`?\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/26346025/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/26346280", "body": "Maybe place this after the install of the header so that erroring on an existing symlink doesn't leave a partially installed libhttp_parser (i.e. the library gets installed but not the headers.)\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/26346280/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/80648002", "body": "The M-SEARCH method is why this PR won't work.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/80648002/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/102496052", "body": "Can you ensure the backslashes line up properly here and elsewhere?", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/102496052/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/102497466", "body": "Style: 1) indent by two spaces, not four, and 2) use snake_case for local variables, not camelCase.\r\n\r\nCorrectness: don't use true/false, they don't exist in C89.", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/102497466/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/102497764", "body": "I don't understand why it's `sizeof(string) - 2` instead of `sizeof(string) - 1`.", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/102497764/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/102498302", "body": "Can you wrap the expression in parens for consistency?", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/102498302/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/102498511", "body": "Use int here (and in general), not bool.", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/102498511/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/102498964", "body": "I don't love this macro, I have to say.", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/102498964/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/102499131", "body": "Can you wrap in parens?", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/102499131/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/102499255", "body": "Ditto.  I'll stop pointing it out from now on.", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/102499255/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/102499673", "body": "Please use C89-style comments, not C99/C++-style comments.", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/102499673/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/102500097", "body": "I think this changes the size of struct http_parser, which would make it a semver-major change.", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/102500097/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/102678723", "body": "The latter, it obscures things and it saves only a few keystrokes.", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/102678723/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/111594347", "body": "Test runner bug fix.  This check doesn't make sense for `test_message_connect(&responses[i])` (which is what calls this function) but it went unnoticed because none of the responses had the `.upgrade` field set.", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/111594347/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/140748881", "body": "Macros with control flow in them that don't announce it in their name are a special kind of evil.", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/140748881/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/140748967", "body": "`static`", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/140748967/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/140749202", "body": "Long line, please wrap it at 80 columns.  (Also applies to any other long lines this PR may introduce, I won't point them out individually.)\r\n\r\nAs well, this would be better written as:\r\n```c\r\n#if defined(_MSC_VER) || (defined(__SSE2__) && defined(__GNUC__))\r\n# define USE_INTRISICS_CRLF 1\r\n#endif\r\n```", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/140749202/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/140750023", "body": "`static`.  I'll stop pointing this out from here on.", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/140750023/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/140750290", "body": "Aliases.  It's also not directly obvious to me if it respects alignment.", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/140750290/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/140794807", "body": "Okay, but defining it like this doesn't work, the `#if USE_INTRISICS_CRLF` is always going to evaluate to true.\r\n\r\nTry changing it to `#define USE_INTRISICS_CRLF defined(florp)` and you'll see it still evaluates to true.", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/140794807/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/140801075", "body": "I'll leave some comments in find_crlf().", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/140801075/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/140802487", "body": "`HTTP_MAX_HEADER_SIZE + p` is not legal C when it points beyond the last element + 1 of the array that `p` points to.  Not a strictly academic concern: whole program optimizers can see through this.", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/140802487/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/140802918", "body": "Shifting into the sign bit (what you do below) is implementation-defined behavior.  This should be `uint32_t`.", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/140802918/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/140803007", "body": "Use `uintptr_t`, `long` isn't necessarily wide enough to hold a pointer.", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/140803007/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/140803114", "body": "What guarantees that this is a valid pointer?", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/140803114/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/140803595", "body": "It reads beyond the end of the input, doesn't it?  Or am I misunderstanding your comment?", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/140803595/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}]}, "ploxiln": {"issues": [], "commits": [{"url": "https://api.github.com/repos/nodejs/http-parser/commits/1b79abab34d4763c0467f1173a406ad2817c1635", "message": "simplify parsing M-SEARCH method, group P methods\n\ncan use same switch-lookup for '-' char case\nmove PROPFIND and PURGE to be next to the other P methods\n\nchange IS_ALPHA(ch) to  A <= ch <= Z\n(very slight optimization, only uppercase will match in switch)\n\nPR-URL: https://github.com/nodejs/http-parser/pull/323\nReviewed-By: Fedor Indutny <fedor@indutny.com>\nReviewed-By: James M Snell <jasnell@gmail.com>"}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": [{"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/69180434", "body": "It does, just for the check. It does not modify `ch` for later code.\n\nBut if `ch` is originally lowercase instead of uppercase, it will (when mixed with the other variables for the fancy select value) never match any case statement. It will always hit the \"default\" case. Which is the same as not matching this `if` condition.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/69180434/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}]}, "misery": {"issues": [], "commits": [{"url": "https://api.github.com/repos/nodejs/http-parser/commits/0852bea482e0842b0445c14b19dc9b318a6c4eba", "message": "Fix FALLTHROUGH warning in switch of GCC7\n\nPR-URL: https://github.com/nodejs/http-parser/pull/357\nReviewed-By: Ben Noordhuis <info@bnoordhuis.nl>"}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "gatzka": {"issues": [], "commits": [{"url": "https://api.github.com/repos/nodejs/http-parser/commits/291a32cc51698318adfbe81ca24e77da1a735365", "message": "Include stddef.h instead of sys/types.h.\n\nThe include is required for type size_t. stddef.h should be available\non every platform, sys/types.h is not.\n\nPR-URL: https://github.com/nodejs/http-parser/pull/360\nReviewed-By: Ben Noordhuis <info@bnoordhuis.nl>"}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "fake666": {"issues": [], "commits": [{"url": "https://api.github.com/repos/nodejs/http-parser/commits/3b0da34d83e4eace29cc49e3b659bf630537b94c", "message": "Tolerate non-compliant status line responses\n\n- original fix is from daeon: https://github.com/daeon/http-parser/\n\n  \"Tolerate web servers which do not return a status message in the\n   return response.\n\n   I have noticed this usse on several websites such downloads from\n   mediafire.com\"\n\n- original pull request: https://github.com/nodejs/http-parser/pull/254\n- i merely added the status_cb_called unit test check, there already\n  is a test that triggers this without the patch (a 301 without a\n  reason phrase).\n\nPR-URL: https://github.com/nodejs/http-parser/pull/367\nReviewed-By: Ben Noordhuis <info@bnoordhuis.nl>\nReviewed-By: Fedor Indutny <fedor@indutny.com>"}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "mscdex": {"issues": [], "commits": [{"url": "https://api.github.com/repos/nodejs/http-parser/commits/9f489a474d5761ca5715f1e13a3d39023a656424", "message": "parser: fix HTTP version parsing\n\nOnly one digit is allowed for the major version and only one is\nallowed for the minor version according to RFC 7230.\n\nPR-URL: https://github.com/nodejs/http-parser/pull/366\nReviewed-By: Fedor Indutny <fedor@indutny.com>"}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": [{"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/117398104", "body": "<s>Yeah I wasn't sure about it style-wise.</s> Er... nevermind this was unintentional.", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/117398104/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/117398179", "body": "I dunno, I just went for the most straightforward change.", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/117398179/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/117398361", "body": "It is over 80 yes, but there are also many other lines in the file that are over 80 so I assumed that rule wasn't being observed, at least for that file...", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/117398361/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/117398727", "body": "I would say no. It's pretty clear in the RFC that the HTTP version in the request line should be followed by CRLF.", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/117398727/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/117398739", "body": "Fixed.", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/117398739/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/117398832", "body": "Changed.", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/117398832/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/140591175", "body": "Perhaps it might be a good idea to make this an overridable define so that the plain C versions of functions can be tested more easily.", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/140591175/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/140591364", "body": "Inconsistent spacing. Personally I prefer a space between the keyword and parenthesis.", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/140591364/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/140591385", "body": "Indentation off here.", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/140591385/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/140640089", "body": "Shouldn't this be `vLF` and the other `vCR` since 0x0a is line feed?", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/140640089/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/140640607", "body": "Don't we need to check that `len >= 16` before trying to use the intrinsics which operate on 16 bytes at a time? For example, a valid HTTP request could just be `GET /<CR><LF><CR><LF>` which is only 9 bytes.", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/140640607/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/140640787", "body": "I get multiple compiler errors for this same macro, looks like additional braces are needed or the `else` should be dropped (and `\\` dropped at end of line)?:\r\n\r\n```\r\nhttp_parser.c:937:25: error: suggest braces around empty body in an \u2018else\u2019 statement [-Werror=empty-body]\r\n         NEXTHEADERCHAR();\r\n```", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/140640787/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/141383196", "body": "Why out of luck? I don't see a problem with requiring SSE3, which was introduced in early 2004.", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/141383196/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/145586959", "body": "This is probably a rarity, but perhaps we should put an `else` here which sets the define to 0.", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/145586959/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/145587099", "body": "The extra spacing like this should be removed to match the style of the rest of the code. This also applies to the other added lines that contain such spacing.", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/145587099/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/145587441", "body": "Minor nit: missing space before brace.", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/145587441/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/145587605", "body": "What is the significance of this same code comment for each newly added test?", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/145587605/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}]}, "npmccallum": {"issues": [], "commits": [{"url": "https://api.github.com/repos/nodejs/http-parser/commits/335850f6b868d3411968cbf5a4d59fe619dee36f", "message": "parser: HTTP_STATUS_MAP(XX) and enum http_status\n\nThis patch provides an enum for the standardized HTTP status codes.\nAdditionally, the HTTP_STATUS_MAP(XX) can be used for other purposes as\nwell, such as code-to-name lookups and code-based switch statements.\n\nPR-URL: https://github.com/nodejs/http-parser/pull/337\nReviewed-By: Fedor Indutny <fedor@indutny.com>\nReviewed-By: Brian White <mscdex@mscdex.net>\nReviewed-By: Ben Noordhuis <info@bnoordhuis.nl>"}], "pull_requests": [], "issue_comments": [], "commit_comments": [{"url": "https://api.github.com/repos/nodejs/http-parser/comments/19565825", "body": "@AaronCAlbers, some compilers will complain about the lack of a default. This version will avoid that problem:\n\n``` c\nconst char *\nhttp_status_str (enum http_status s)\n{\n  switch (s) {\n#define XX(num, name, string) case num : return #string;\n      HTTP_STATUS_MAP(XX)\n#undef XX\n      default: return \"<unknown>\";\n  }\n}\n```\n\nThere is also the question of being able to detect an error condition: should you return `\"<unknown>\"` or `NULL`?\n\nI suspect that since the consumer of this API has all the tools to make this same function, that the consumer should implement it based on the properties they need.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/comments/19565825/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/comments/19567133", "body": "Well, I think we draw the line at having more complexity than a single switch statement. :) But I don't really have a strong opinion. I just know that some people will want `\"<unknown>\"` and some people will want `NULL`.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/comments/19567133/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}], "review_comments": []}, "indutny": {"issues": [], "commits": [{"url": "https://api.github.com/repos/nodejs/http-parser/commits/feae95a3a69f111bc1897b9048d9acbc290992f9", "message": "Bump version to 2.7.1"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/9b0d5b33ebdaacff1dadd06bad4e198b11ff880e", "message": "Bump version to 2.6.0"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/04d28a7377c03bac762e44927c234d9b3d58462a", "message": "parser: returning 2 from on_headers_complete\n\nReturning `2` from on_headers_complete will tell parser that it\nshould not expect neither a body nor any futher responses on\nthis connection. This is useful for handling responses to a\nCONNECT request which may not contain `Upgrade` or\n`Connection: upgrade` headers.\n\nSee: https://github.com/nodejs/node/pull/6198\nPR-URL: https://github.com/nodejs/http-parser/pull/299\nReviewed-By: Brian White <mscdex@mscdex.net>"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/777ba4ededf53040f4c5cc5d53f26201e705ebaf", "message": "src: introduce `http_parser_url_init`\n\nThe struct must be zero-initialized, but this wasn't explicitly stated\nanywhere in headers. Introduce `http_parser_url_init` API method that\nwill do it.\n\nFixes: #209\nReviewed-By: James M Snell <jasnell@gmail.com>\nReviewed-By: Brian White <mscdex@mscdex.net>\nPR-URL: https://github.com/nodejs/http-parser/pull/225"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/39c2c1e5733eb2cb7397a370cf50508ea1214bf7", "message": "Bump version to 2.5.0"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/7ecf775d71337927acbacf64e4267175c5a51187", "message": "src: partially revert 959f4cb to fix nread value\n\nWith 959f4cb on reexecution - header byte was accounted twice, leading\nto the incorrect `parser->nread` value.\n\nFix: #220\nPR-URL: https://github.com/joyent/http-parser/pull/221\nReviewed-By: Ben Noordhuis <info@bnoordhuis.nl>"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/7ba312397c2a6c851a4b5efe6c1603b1e1bda6ff", "message": "header: fix field sizes\n\nThe flags enum does not fit into 6 bits anymore.\n\nFix: #218\nPR-URL: https://github.com/joyent/http-parser/pull/219\nReviewed-By: Ben Noordhuis <info@bnoordhuis.nl>"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/1b315808932486656cfa30e46932a93cbe231b42", "message": "Bump version to 2.4.2"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/59569f2125211ed7ce4163f34d0cc6f4b6801f1c", "message": "src: skip lws between `connection` values\n\nFix: https://github.com/iojs/io.js/issues/588\nPR-URL: https://github.com/joyent/http-parser/pull/216\nReviewed-By: Ben Noordhuis <info@bnoordhuis.nl>"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/36f107fa2e62ca1f0fe7087e49f58624c45a24f1", "message": "Bump version to 2.4.1"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/280af6984cb4d674e700854f40558832e6dcaa0b", "message": "src: fix build on MSVC\n\nDo explicit casts from/to enums, convert type of `memchr`'s return value\nto `const char*`.\n\nPR-URL: https://github.com/joyent/http-parser/pull/213\nReviewed-By: Bert Belder <bertbelder@gmail.com>"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/956c8a054a8d8e8fd8eaca6827aedfaf08911cab", "message": "Bump version to 2.4.0"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/3f7ef500bdcc01c06ac6d18a38fb1c441a9b9c60", "message": "src: annotate with likely/unlikely\n\nReviewed-By: Fedor Indutny <fedor@indutny.com>"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/265f9d0edc3b501912bf5df4f4b553d46e526608", "message": "bench: add chunked bytes\n\nReviewed-By: Fedor Indutny <fedor@indutny.com>"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/959f4cb12748ea3aa2c4ec3183ff4acbf0fd222f", "message": "src: remove reexecute goto"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/0097de5895e4ec79e0191682d600a8e450051cb6", "message": "src: use memchr() in h_general header value"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/c6097e1d7667457765c42e73ef26aa74b961ca4d", "message": "src: faster general header value loop"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/263006044a6bc0057e45dbf39a788e647a3afb72", "message": "src: less loads in header_value loop"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/0cb0ee672c640d4fe08498b87bf5bf3c89b938b5", "message": "src: tighten header field/value loops"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/6132d1fefa03f769a3979355d1f5da0b8889cad2", "message": "src: save progress"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/3f1a05a24c46e3ffb7bd95c6f0242fa5846f2ec9", "message": "benchmark: initial"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/56f7ad0e2e5a80f79d214015c91e1f17d11d109f", "message": "Bump version to 2.3.0"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/cba704cb2d9f1df80994dd4a791a0fa6cce65720", "message": "Bump version to 2.2.1"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/fd609ab272f94bb58e65449b4faeaa4abe02b558", "message": "Bump version to 2.2"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/efcf75d837fd693712e7feec9f5d9aa9584dad0d", "message": "test: better fix for __APPLE__ test build"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/9ca484d4c6f7f429552655ca7b9e5226698cc30b", "message": "test: fix build on osx"}], "pull_requests": [{"url": "https://api.github.com/repos/nodejs/http-parser/pulls/295", "title": "http_parser: skip lws/rws in header field", "body": "Skip whitespace from the left and the right sides of the header field.\n\nSee: https://github.com/nodejs/node/pull/5844\n\ncc @jasnell \n", "author_association": "OWNER"}], "issue_comments": [], "commit_comments": [{"url": "https://api.github.com/repos/nodejs/http-parser/comments/8853218", "body": "cc @bnoordhuis please take a look, I have rebased it and fixed a couple of times before pushing out.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/comments/8853218/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/comments/8854871", "body": "Yep.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/comments/8854871/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/comments/9826021", "body": "Thanks!\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/comments/9826021/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/comments/19528507", "body": "@AaronCAlbers possibly\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/comments/19528507/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}], "review_comments": [{"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/8736996", "body": "How is that related to this PR?\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/8736996/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/8737001", "body": "Please move `\\` to 79th column.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/8737001/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/8737021", "body": "2 space indent\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/8737021/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/8737034", "body": "80 column limit (I think)\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/8737034/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/8737037", "body": "Indent\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/8737037/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/8737043", "body": "Indent\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/8737043/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/8737056", "body": "Indent\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/8737056/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/8737085", "body": "Also, why do you need to change this?\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/8737085/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/8737113", "body": "I think this could be solved with a `#define HPE_CB_unknown_method HPE_INVALID_METHOD` at top\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/8737113/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/8964036", "body": "Unrelated change, please remove.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/8964036/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/9193676", "body": "May be `ULLONG_MAX / 10 - 1` ?\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/9193676/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/9193680", "body": "Same here.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/9193680/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/10639791", "body": "Could you add a comment, like one above, about the way to configure this value during compilation?\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/10639791/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/10746282", "body": "I think you could insert label here and do `goto` in all cases above, right?\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/10746282/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/10749056", "body": "Please put it at the start of the line.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/10749056/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/10749063", "body": "Two spaces to the left.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/10749063/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/10749147", "body": "Oh, and move it after `return EXIT_SUCCESS;`\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/10749147/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/10749798", "body": "Unnecessary whitespace change.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/10749798/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/10768987", "body": "Heh, now you have removed newline :)\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/10768987/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/10772149", "body": "Yeah, please do.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/10772149/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/18901385", "body": "Hm... why have you added and commented it out?\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/18901385/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/21046602", "body": "Oooh, right. I guess it should be enough to just search for `\\r`, as it is a general case.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/21046602/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/21046605", "body": "Wait, I don't see any problems with this. It goes back to `s_header_value` anyway after finding either `\\r` or `\\n`.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/21046605/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/23496497", "body": "Style `void http_parser...(...) {`\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/23496497/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/23503445", "body": "Why not just `memset()`? ;)\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/23503445/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/23524873", "body": "Arrrgh, you are right! Nginx legacy, damn it.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/23524873/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/25238081", "body": "Style, please line up `\\` as we do in defines below.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/25238081/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/26301032", "body": "Perhaps, it could be made overridable? Like `PREFIX ?= ...`\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/26301032/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/28760174", "body": "I know it is boring, but let's do it without style fixes in not relevant parts ;)\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/28760174/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/28761264", "body": "Unnecessary style fix.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/28761264/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/28761594", "body": "I know it does the same thing internally, but why is it necessary to change it? Just for consistency?\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/28761594/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/28761798", "body": "Why?\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/28761798/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/28761820", "body": "I'd rather use `i++` throughout this file for consistency.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/28761820/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/28761832", "body": "Let's use postfix `++` here.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/28761832/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/28761834", "body": "Ditto.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/28761834/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/28811888", "body": "Well, the previous code has quite similar behaviour, except that the state will be different in chunk_complete_cb. I just want to be sure I understand the reasons behind this. Is it possible to ask the person who implemented it?\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/28811888/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/28826974", "body": "Yep, it just feels a bit odd that you have different number of complete and seen chunks in test declarations :)\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/28826974/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/28949014", "body": "Right! Thank you!\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/28949014/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/30508628", "body": "80 column limit, please move stuff to the new lines.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/30508628/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/30551485", "body": "Unnecessary change? ;)\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/30551485/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/33433252", "body": "80 column limit! ;)\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/33433252/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/34752869", "body": "Please apply 80 column limit. I know it is different in other places of the file, but I'd like to enforce this style on all future changes.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/34752869/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/34752879", "body": "Actually, you may just want to leave it as it is ;)\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/34752879/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/34752342", "body": "No style changes, please.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/34752342/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/34752372", "body": "Let's split it on 80 column, and do two line `#if`.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/34752372/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/40508903", "body": "Unnecessary style change?\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/40508903/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/40508904", "body": "Ditto.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/40508904/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/44988690", "body": "Please put the operator before the newline.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/44988690/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/54327211", "body": "Why can't `MSEARCH` be here too?\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/54327211/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/54327215", "body": "Ah, because of this, I guess?\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/54327215/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/54327218", "body": "And this... gotcha\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/54327218/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/54327319", "body": "Please place braces on the same line as the main expression.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/54327319/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/54327325", "body": "No need in extra parens for every subcondition.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/54327325/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/54327331", "body": "Please move it to previous line.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/54327331/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/54327343", "body": "Odd indent, please put it at the same ident level as above defines.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/54327343/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/54327348", "body": "Could be merged with previous line into `else if`\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/54327348/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/52944544", "body": "Alright, nit: `(unsigned char) ch`.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/52944544/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/61678290", "body": "Any reason to not use `$@` here?\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/61678290/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/61678294", "body": "Where is `DESTDIR` defined?\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/61678294/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/61678297", "body": "Argh, nevermind.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/61678297/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/61678301", "body": "Shouldn't there be `/` between `DESTDIR` and `INCLUDEDIR`?\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/61678301/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/69179025", "body": "Doesn't `IS_ALPHA` also cast the character to the lower case?\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/69179025/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/69181128", "body": "Good point. Thank you!\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/69181128/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/69639699", "body": "Superfluous parens?\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/69639699/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/69639798", "body": "`HTTP_SETTINGS_...`?\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/69639798/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/78716402", "body": "These symbols are globally available everywhere, where `http_parser.h` is included. I'm not sure it is a good idea to declare it with such unprefixed names.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/78716402/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/117392610", "body": "Nitpicking: does it violate 80 column limit?", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/117392610/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/117392631", "body": "Do we still want to allow any spaces after the digit?", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/117392631/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/117392705", "body": "Superfluous break", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/117392705/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/117392828", "body": "I wonder if state machine for req and req can be united without sacrificing speed? Would branching in `http_minor` be too heavy for us?", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/117392828/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/117398398", "body": "We're moving to 80 column limit in a very very slow way :)", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/117398398/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/117398763", "body": "Let's remove this comment then.", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/117398763/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/117616431", "body": "Nit: Indent, should be two-spaces less.", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/117616431/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/93975345", "body": "Please use C style comments `/* */`", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/93975345/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/93975356", "body": "Also 80 column limit?", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/93975356/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/93975417", "body": "`(!result)`", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/93975417/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/93975478", "body": "Just `*(__m128i*) p`, maybe?", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/93975478/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/93975554", "body": "No need in parens.", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/93975554/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/93975584", "body": "`while (!result && lastp >= p+32) {`", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/93975584/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/93975599", "body": "Please put block's statement on a next line.", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/93975599/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/93975648", "body": "Please remove spaces after `(` and before `)`.", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/93975648/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/93975658", "body": "`data + len`", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/93975658/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/93975700", "body": "Superfluous change?", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/93975700/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/93975738", "body": "`p + 1 == data + len`", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/93975738/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/93975838", "body": "Please wrap contents of define with `do { } while (0)`, and align `\\`.", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/93975838/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/93975859", "body": "`(long) p & 15`", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/93975859/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/93997504", "body": "Yep, they are not required.", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/93997504/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/93998037", "body": "Oh right, I didn't see break here... It can be left as it is then, sorry!", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/93998037/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/140601014", "body": "I agree that overridable define should be introduced here.", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/140601014/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/141444195", "body": "I have a proposal. What do you think about moving this into a separate header file? This way we could write extensive tests for this function.", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/141444195/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/141505741", "body": "I'd just put it into internal header file, so that it could be included and covered by tests.", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/141505741/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}]}, "guoxiao": {"issues": [], "commits": [{"url": "https://api.github.com/repos/nodejs/http-parser/commits/b2cc8e49f39277b197c6f3592708309ee78c015e", "message": "test: remove \u2018nread\u2019, which is not used\n\nPR-URL: https://github.com/nodejs/http-parser/pull/300\nReviewed-By: Fedor Indutny <fedor@indutny.com>"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/2896229a1383cd60715087df177455338bb1f6a8", "message": "make: fix dynamic library extension for OS X"}], "pull_requests": [], "issue_comments": [], "commit_comments": [{"url": "https://api.github.com/repos/nodejs/http-parser/comments/17209537", "body": "Should be `bump version to 2.7.0` :smiley: \n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/comments/17209537/reactions", "total_count": 3, "+1": 0, "-1": 0, "laugh": 3, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}], "review_comments": []}, "oldratlee": {"issues": [], "commits": [{"url": "https://api.github.com/repos/nodejs/http-parser/commits/737627b2b232f6a47dffca7ea17a8e3c3e2231a0", "message": "readme: improve format, fix code syntax\n\nPR-URL: https://github.com/nodejs/http-parser/pull/305\nReviewed-By: Fedor Indutny <fedor@indutny.com>"}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "jbergstroem": {"issues": [], "commits": [{"url": "https://api.github.com/repos/nodejs/http-parser/commits/5651aea80472bf9a1f7d2718c78c0de08984aa1f", "message": "test: add a test for for obstext characters (> 0x80)\n\nCreate a test added for nodejs in nodejs/node@954a4b4b.\n\nPR-URL: https://github.com/nodejs/http-parser/pull/287\nReviewed-By: James M Snell <jasnell@gmail.com>"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/dbcda1961c25a4f945a55da8e9dd3af6e4df65f0", "message": "Update http-parser to 2.6.2\n\nFixes a header parsing bug for obstext characters (> 0x80)\n\nAdaption of nodejs/node@954a4b4b:\n\n    Author: James M Snell <jasnell@gmail.com>\n    Date:   Mon Feb 15 09:40:58 2016 -0800\n\n    deps: update to http-parser 2.6.2\n\n    Fixes http-parser regression with IS_HEADER_CHAR check\n    Add test case for obstext characters (> 0x80) is header\n\n    PR-URL: https://github.com/nodejs/node/pull/5237\n    Reviewed-By: Ben Noordhuis <info@bnoordhuis.nl>\n    Reviewed-By: \u0421\u043a\u043e\u0432\u043e\u0440\u043e\u0434\u0430 \u041d\u0438\u043a\u0438\u0442\u0430 \u0410\u043d\u0434\u0440\u0435\u0435\u0432\u0438\u0447 <chalkerx@gmail.com>\n    Reviewed-By: Myles Borins <myles.borins@gmail.com>\n\nPR-URL: https://github.com/nodejs/http-parser/pull/287\nReviewed-By: James M Snell <jasnell@gmail.com>"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/678a9e21f11e5ea93e5e17a2302390f88a6a8c46", "message": "test: Assert against correct error messages\n\nPR-URL: https://github.com/nodejs/http-parser/pull/279\nReviewed-By: James M Snell <jasnell@gmail.com>"}], "pull_requests": [], "issue_comments": [], "commit_comments": [{"url": "https://api.github.com/repos/nodejs/http-parser/comments/121228", "body": "Hey, any reason you didn't merge my commit (http://github.com/jbergstroem/http-parser/commit/4c521a67fe5eaaee539cb68a4b66c8367afcc4fd)? Let me know if I'm doing something wrong and i'll try to fix it.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/comments/121228/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}], "review_comments": []}, "dolmen": {"issues": [], "commits": [{"url": "https://api.github.com/repos/nodejs/http-parser/commits/fd65b0fbbdb405425a14d0e49f5366667550b1c2", "message": "src: refactor method parsing\n\nUse a switch and a macro to branch parsing of HTTP methods.\nEasier to read and much shorter.\n\nIn this commit, the order of branches dispatching is the same as in the\noriginal code, to ease review. Reordering branches by descending\nfrequency will improve speed too.\n\nPR-URL: https://github.com/nodejs/http-parser/pull/273\nReviewed-By: Fedor Indutny <fedor@indutny.com>"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/e557b62744e4f487a303b25b27c56947d7a8bacc", "message": "src: support LINK/UNLINK (RFC 2068, draft-snell-link-method)\n\nAdd support for HTTP methods LINK and UNLINK originally defined in RFC2068\nsection 19.6.2.2, but with semantic added in a Internet draft.\nhttps://tools.ietf.org/html/rfc2068#section-19.6.1.2\nhttps://tools.ietf.org/html/draft-snell-link-method-12\n\nReviewed-By: James M Snell <jasnell@gmail.com>\nReviewed-By: Fedor Induty <fedor@indutny.com>\nPR-URL: https://github.com/nodejs/http-parser/pull/267"}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": [{"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/54331387", "body": "Because this is `M-SEARCH`. We have to handle the dash differently.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/54331387/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}]}, "jasnell": {"issues": [], "commits": [{"url": "https://api.github.com/repos/nodejs/http-parser/commits/e2e467b91262246b339fb3d80c8408d498b4a43b", "message": "Update http-parser to 2.6.1\n\nIncludes parsing improvements to ensure closer HTTP spec conformance\n\nAdaption of nodejs/node@4f4c8ab3b4cea246d2ece6ca006fe280241d84a4:\n\n    Author: James M Snell <jasnell@gmail.com>\n    Date:   Wed Feb 3 17:28:48 2016 -0800\n\n    deps: update http-parser to version 2.6.1\n\n    includes parsing improvements to ensure closer HTTP spec conformance\n\n    PR-URL: https://github.com/nodejs/node-private/pull/26\n    Reviewed-By: Rod Vagg <r@va.gg>\n    Reviewed-By: \u0421\u043a\u043e\u0432\u043e\u0440\u043e\u0434\u0430 \u041d\u0438\u043a\u0438\u0442\u0430 \u0410\u043d\u0434\u0440\u0435\u0435\u0432\u0438\u0447 <chalkerx@gmail.com>\n    Reviewed-By: Ben Noordhuis <info@bnoordhuis.nl>\n\nPR-URL: https://github.com/nodejs/http-parser/pull/279\nReviewed-By: James M Snell <jasnell@gmail.com>"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/bee4817ebea0eaa592143c7825f5c96f040c84e4", "message": "Bump version to 2.6.0"}], "pull_requests": [{"url": "https://api.github.com/repos/nodejs/http-parser/pulls/326", "title": "add settings flags, refactor lenient_http_headers setting", "body": "A previous change during a security fix added the ability to set a `lenient_http_headers` flag on the HTTP Parser instance. The way it was done was a bit of a hack at the time in order to avoid an ABI breaking change. This PR adds a new `uint32_t` flags field to `http_parser_settings` in order to provide a more robust and correct way of passing these kinds of settings into a parser instance.\n\n_Note_: This is an ABI change so it would require a semver-major bump\n\n/cc @indutny \n", "author_association": "OWNER"}], "issue_comments": [], "commit_comments": [], "review_comments": [{"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/40508926", "body": "Grr.. Thanks. Missed those. Looks like I need to tweak my atom editor\nsettings so it's not doing these silly style edits\nOn Sep 27, 2015 12:57 PM, \"Fedor Indutny\" notifications@github.com wrote:\n\n> In http_parser.c\n> https://github.com/joyent/http-parser/pull/266#discussion_r40508903:\n> \n> > @@ -123,7 +123,7 @@ do {                                                                 \\\n> >      FOR##_mark = NULL;                                               \\\n> >    }                                                                  \\\n> > \n> > ##  } while (0)\n> \n> Unnecessary style change?\n> \n> \u2014\n> Reply to this email directly or view it on GitHub\n> https://github.com/joyent/http-parser/pull/266/files#r40508903.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/40508926/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "OWNER"}]}, "geek": {"issues": [], "commits": [{"url": "https://api.github.com/repos/nodejs/http-parser/commits/4e382f96e6d3321538a78f2c7f9506d4e79b08d6", "message": "readme: fix build status badge\n\nPR-URL: https://github.com/nodejs/http-parser/pull/277\nReviewed-By: Fedor Indutny <fedor@indutny.com>"}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "lberezy": {"issues": [], "commits": [{"url": "https://api.github.com/repos/nodejs/http-parser/commits/483eca7989d655b34b01f65a8faad82ddb79813c", "message": "doc: updated README.md to include multi-threading example\n\nIncluded information and example on communicating data between\nthread local and callback scopes. This shows how http-parser\ncan be used in a multi-threaded context.\n\nReviewed-By: James M Snell <jasnell@gmail.com>\nReviewed-By: Fedor Indutny <fedor@indutny.com>\nPR-URL: https://github.com/nodejs/http-parser/pull/256"}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "sebastian-philipp": {"issues": [], "commits": [{"url": "https://api.github.com/repos/nodejs/http-parser/commits/e01811e7f4894d7f0f7f4bd8492cccec6f6b4038", "message": "src: fixed compile error C2143 for vs2012\n\nPR-URL: https://github.com/joyent/http-parser/pull/261\nReviewed-By: Fedor Indutny <fedor@indutny.com>"}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "Tatsh": {"issues": [], "commits": [{"url": "https://api.github.com/repos/nodejs/http-parser/commits/b36c2a9ece033b7313f81c24e355a09f9c135315", "message": "header: treat Wine like MinGW\n\nPR-URL: https://github.com/joyent/http-parser/pull/259\nReviewed-By: Fedor Indutny <fedor@indutny.com>"}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "Hywan": {"issues": [], "commits": [{"url": "https://api.github.com/repos/nodejs/http-parser/commits/eb5e9928b458e541ed1583e01b58833d78a653a7", "message": "src: support ACL (WebDAV, RFC3744, Section 8.1).\n\nPR-URL: https://github.com/joyent/http-parser/pull/260\nReviewed-By: Fedor Indutny <fedor@indutny.com>"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/4f69be2221db0fa783b56621a45a2edab22cdc8e", "message": "readme: update WebSocket link to RFC6455\n\nPR-URL: https://github.com/joyent/http-parser/pull/240\nReviewed-By: Fedor Indutny <fedor@indutny.com>"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/b5bcca8f928cafff36b8a0d04c2c3a771205cb62", "message": "test: `SEARCH`, `PURGE` and `MKCALENDAR`\n\nThese methods are defined in `http_parser.h` but not tested.\n\nPR-URL: https://github.com/joyent/http-parser/pull/241\nReviewed-By: Fedor Indutny <fedor@indutny.com>"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/8b1d652322c4b98508a92b60f21a6d48fd05d37b", "message": "src: support BIND/REBIND/UNBIND (WebDAV, RFC5842)\n\nSupport BIND/REBIND/UNBIND methods, see sections 4, 5, 6 of\nRFC5842.\n\nPR-URL: https://github.com/joyent/http-parser/pull/242\nReviewed-By: Fedor Indutny <fedor@indutny.com>"}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "deleisha": {"issues": [], "commits": [{"url": "https://api.github.com/repos/nodejs/http-parser/commits/ab0b162ef63f919b7e436b07a794134570d792ab", "message": "src: use ARRAY_SIZE instead of sizeof()\n\nPR-URL: https://github.com/joyent/http-parser/pull/252\nReviewed-By: Fedor Indutny <fedor@indutny.com>"}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "jscissr": {"issues": [], "commits": [{"url": "https://api.github.com/repos/nodejs/http-parser/commits/39ff0975c220ef76a2d98c8ac61b0d36f4dce80f", "message": "src: remove double check\n\nThis is already included in `http_message_needs_eof`.\n\nPR-URL: https://github.com/joyent/http-parser/pull/248\nReviewed-By: Fedor Indutny <fedor@indutny.com>"}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "OnixGH": {"issues": [], "commits": [{"url": "https://api.github.com/repos/nodejs/http-parser/commits/f6f436a12edf209be806be8833bced9419d985ca", "message": "src: fix invalid memory access in http_parse_host\n\nhttp_parse_host() depends on `u->field_data[UF_HOST]`, but this\nif() allowed the method to be called if only\n`u->field_data[UF_SCHEMA]` was set, resulting in use of\nunintialized pointers.\n\nPR-URL: https://github.com/joyent/http-parser/pull/246\nReviewed-By: Fedor Indutny <fedor@indutny.com>"}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "Umorrian": {"issues": [], "commits": [{"url": "https://api.github.com/repos/nodejs/http-parser/commits/5d414fcb4b2ccc1ce9d6063292f9c63c9ec67b04", "message": "makefile: add un/install targets\n\nAdd install, install-strip and uninstall targets, make DESTDIR usable.\n\nPR-URL: https://github.com/joyent/http-parser/pull/228\nReviewed-By: Fedor Indutny <fedor@indutny.com>\nReviewed-By: Ben Noordhuis <info@bnoordhuis.nl>"}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "jay": {"issues": [], "commits": [{"url": "https://api.github.com/repos/nodejs/http-parser/commits/d547f3b1a98ed07fdcdaf401a8cbc5fffe9bfa6c", "message": "url_parser: remove mixed declarations\n\n(dump_url)\n- Remove erroneous quote in output.\n\n(main)\n- Remove mixed declarations for compatibility with pre-c99 compilers\nlike msvc.\n\nReviewed-By: Fedor Indutny <fedor@indutny.com>\nPR-URL: https://github.com/joyent/http-parser/pull/224"}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "RomainGiraud": {"issues": [], "commits": [{"url": "https://api.github.com/repos/nodejs/http-parser/commits/53063b780be8bff84895006409ae390ca96be1cf", "message": "Add function to initialize http_parser_settings\n\nPR-URL: https://github.com/joyent/http-parser/pull/215\nReviewed-By: Fedor Indutny <fedor@indutny.com>"}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": [{"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/23516726", "body": "All function definitions have this same style.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/23516726/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/23516736", "body": "Indeed, I will change that.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/23516736/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}]}, "Akagi201": {"issues": [], "commits": [{"url": "https://api.github.com/repos/nodejs/http-parser/commits/167dcdfc063e16adba1af2f7ad5ad77b3994c8d3", "message": "readme: fix typo\n\nPR-URL: https://github.com/joyent/http-parser/pull/207\nReviewed-By: Fedor Indutny <fedor@indutny.com>"}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "kolbyjack": {"issues": [], "commits": [{"url": "https://api.github.com/repos/nodejs/http-parser/commits/091ebb87783a58b249062540bbea07de2a11e9cf", "message": "src: simple Connection header multi-value parsing\n\nReviewed-By: Fedor Indutny <fedor@indutny.com>\nPR-URL: https://github.com/joyent/http-parser/pull/100"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/81534666431cc82606e56451237d2da0c9a5ae0a", "message": "Group POST refinements, test all request methods, make IS_ALPHA use LOWER internally"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/a6934445e81c20b1339291db9df9781bbd0ff1c7", "message": "Allow uppercase chars in IS_ALPHANUM"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/dc314a3cb917e2f23680fa6b13ba4930d5f1b658", "message": "Return error when bad method starts with M or C"}], "pull_requests": [], "issue_comments": [{"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1402774", "body": "Updated the commit range to add back the LOWER(ch) and adjust the CONNECT uppercase test\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1402774/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1402821", "body": "I didn't think it'd be so simple to make IS_ALPHA use LOWER internally, I thought there'd be more places to change than just these few.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1402821/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1403983", "body": "Right, I'll send that new pull request in a moment.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1403983/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1405072", "body": "I tried to do that, just hitting 'Pull Request' from the squashed branch, but it wanted to create a new pull request instead of modifying the existing one.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1405072/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4287530", "body": "It doesn't, but it's a trivial fix.  I'll update the pull request in a minute.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4287530/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4290305", "body": "I don't see anything in the rfc about precedence between the settings.  The current PR doesn't deal with lws properly at all, and a quick attempt to fix it isn't working either, so I'll have to wait a bit until I can fix it.  My multi-header, do you mean multiple Connection: headers?  I don't see that explicitly covered in the rfc either.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4290305/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}], "commit_comments": [{"url": "https://api.github.com/repos/nodejs/http-parser/comments/2341414", "body": "I think you need to goto reexecute_byte when switching to a request here in case ch is a space\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/comments/2341414/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/comments/2341429", "body": "This will still fail on GENERICLONGMETHOD, since that 'L' isn't a space, it'll fall through to where it still indexes method_strings\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/comments/2341429/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/comments/2341498", "body": "Since it's walking through the full HTTP now, would it be better to deal with s_req_or_resp as a single state kind of like the request methods?  Use a string \"HTTP\" and parser->index?\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/comments/2341498/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}], "review_comments": [{"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/2477008", "body": "I think this should always set parser->type to HTTP_REQUEST, and set parser->method to HTTP_HEAD or HTTP_GENERIC depending on ch.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/2477008/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/2477256", "body": "If parser->method is HTTP_GENERIC, you need to avoid checking matcher[parser->index] or REALLYLONGMETHODNAME will have you walking off the end of the array.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/2477256/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/8744193", "body": "Setting the mark only when the state is s_start_req means that the unknown method callback will only be called if the method + trailing space are all available in a single call.  It's unlikely that the method won't be available in a single buffer, but it should at least be noted that the callback won't be called in that situation.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/8744193/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}]}, "tjfontaine": {"issues": [], "commits": [{"url": "https://api.github.com/repos/nodejs/http-parser/commits/94a55d1b3859ce1bae3a6b9aba24550f93212cb3", "message": "send travis irc notifications to #node-ci"}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "alagoutte": {"issues": [], "commits": [{"url": "https://api.github.com/repos/nodejs/http-parser/commits/5fd51fd59d7edfa8bf13a08e0097b7eef95b24a6", "message": "Fix warning on test suite found by Clang Analyzer\n\ntest.c:2210:9: warning: Value stored to 'char_len' is never read\n        char_len = 2;\n        ^          ~\ntest.c:2921:3: warning: Value stored to 'pass' is never read\n  pass &= (parsed == 0);\n  ^       ~~~~~~~~~~~~~\n\nReviewed-By: Fedor Indutny <fedor@indutny.com>"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/5b951d74bd66ec9d38448e0a85b1cf8b85d97db3", "message": "src: fix clang warning\n\nFix http_parser.c:2147:3: warning: Value stored to 'uf' is never\nread found by Clang Analyser.\n\nReviewed-By: Fedor Indutny <fedor@indutny.com>"}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "marcomorain": {"issues": [], "commits": [{"url": "https://api.github.com/repos/nodejs/http-parser/commits/11ecb42061aba9b336c58519e833bccfaa7ab0ba", "message": "Docs fix\n\nReviewed-By: Fedor Indutny <fedor@indutny.com>"}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": [{"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/21176293", "body": "Sounds like a good test-case to add?\n\nOn Fri, Nov 28, 2014 at 3:48 PM, Ben Noordhuis notifications@github.com\nwrote:\n\n> In http_parser.c:\n> \n> > -        c = LOWER(ch);\n> > -          switch (h_state) {\n> > -            case h_general:\n> > -            {\n> > -              const char\\* pos;\n> >   +\n> > -              pos = memchr(p, CR, data + len - p);\n> > -              if (pos == NULL)\n> > -                pos = memchr(p, LF, data + len - p);\n> \n> I'm not sure I follow. With \"Foo: bar\\nBar: baz\\r\\n\" as input, this code\n> would skip to the '\\r' character and miss the Baz header altogether,\n> right?\n> \n> \u2014\n> Reply to this email directly or view it on GitHub\n> https://github.com/joyent/http-parser/pull/200/files#r21046830.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/21176293/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/23503567", "body": "Yeah, `memset` will be more robust if members are changed / added to the\nstruct.\n\nOn Sunday, January 25, 2015, Fedor Indutny notifications@github.com wrote:\n\n> In http_parser.c\n> https://github.com/joyent/http-parser/pull/215#discussion_r23503445:\n> \n> > @@ -2134,6 +2134,19 @@ http_parser_init (http_parser *parser, enum http_parser_type t)\n> >    parser->http_errno = HPE_OK;\n> >  }\n> > \n> > +void\n> > +http_parser_settings_init(http_parser_settings *settings)\n> > +{\n> > -  settings->on_message_begin = 0;\n> \n> Why not just memset()? ;)\n> \n> \u2014\n> Reply to this email directly or view it on GitHub\n> https://github.com/joyent/http-parser/pull/215/files#r23503445.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/23503567/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}]}, "mmalecki": {"issues": [], "commits": [{"url": "https://api.github.com/repos/nodejs/http-parser/commits/7bbb77467f6e48b12f51376d01acacab970d9615", "message": "doc: add very basic docs for `http_parser_execute`\n\nReviewed-By: Fedor Indutny <fedor@indutny.com>"}], "pull_requests": [], "issue_comments": [{"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3943720", "body": "@bnoordhuis CLA signed.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3943720/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}], "commit_comments": [], "review_comments": []}, "laggyluke": {"issues": [], "commits": [{"url": "https://api.github.com/repos/nodejs/http-parser/commits/17ed7deb7c7a3c4f88300fc18333e93c8a33b460", "message": "header: typo fix in a comment\n\nReviewed-By: Fedor Indutny <fedor@indutny.com>"}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "helje5": {"issues": [], "commits": [{"url": "https://api.github.com/repos/nodejs/http-parser/commits/1317eeca43b7c3c48a3f291483bb807648016d22", "message": "Added support for MKCALENDAR\n\nSigned-off-by: Fedor Indutny <fedor@indutny.com>"}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "markmontymark": {"issues": [], "commits": [{"url": "https://api.github.com/repos/nodejs/http-parser/commits/08a2cc36eb30b0e5e4bd83ec476970af40d5f04c", "message": "very minor spelling/grammar changes in README.md\n\nSigned-off-by: Fedor Indutny <fedor@indutny.com>"}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "rlidwka": {"issues": [], "commits": [{"url": "https://api.github.com/repos/nodejs/http-parser/commits/158dd3bb22a10320d9c893bc4beb15c3033179de", "message": "signing the CLA is no longer a requirement\n\nSigned-off-by: Fedor Indutny <fedor@indutny.com>"}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "xta": {"issues": [], "commits": [{"url": "https://api.github.com/repos/nodejs/http-parser/commits/8d9e5db981b623fffc93657abacdc80270cbee58", "message": "fix typo in README comment"}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "alibitek": {"issues": [], "commits": [{"url": "https://api.github.com/repos/nodejs/http-parser/commits/d19e12911a1b523885bdf0d82f1f3e91df90711d", "message": "contrib: fixed resource leak in parsertrace"}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": [{"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/10747855", "body": "Yes, no need to have duplicate code. I've updated the commit, is it better now?\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/10747855/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/10750102", "body": "I've updated again. Now there is no whitespace...\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/10750102/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/10770805", "body": "You want me to add it back? :-) Style is a PITA\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/10770805/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/10772813", "body": "How about now?\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/10772813/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}]}, "dpw": {"issues": [], "commits": [{"url": "https://api.github.com/repos/nodejs/http-parser/commits/76f0f1690fb4ea80e655327a96c7549f4c1fdf5d", "message": "Fix issues around multi-line headers\n\nAlways discard leading whitespace in a header value, even if it\nis folded.\n\nPay attention to values of interesting headers (Connection,\nContent-Length, etc.) even when they come on a continuation line.\n\nAdd a test case to check that requests and responses using only LF\nto separate lines are handled correctly."}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/5d9c3821729b194eef60f41fcc5f8b4657c3d8ff", "message": "Include separating ws when folding header values\n\nThe support for folding of multi-line header values does not conform\nto the specs.  Given a request containing\n\n    Multi-Line-Header: foo<CRLF>\n     bar<CRLF>\n\nhttp-parser will eliminate the whitespace breaking the header value to\nyield a header value of \"foobar\".  This is confirmed by the\nLINE_FOLDING_IN_HEADER case in tests.c.\n\nBut from rfc2616, section 2.2:\n\n   A CRLF is allowed in the definition of TEXT only as part of a header\n   field continuation. It is expected that the folding LWS will be\n   replaced with a single SP before interpretation of the TEXT value.\n\nAnd from draft-ietf-httpbis-p1-messaging-25, section 3.2.4:\n\n   A server that receives an obs-fold in a request message that is not\n   within a message/http container MUST either reject the message by\n   sending a 400 (Bad Request), preferably with a representation\n   explaining that obsolete line folding is unacceptable, or replace\n   each received obs-fold with one or more SP octets prior to\n   interpreting the field value or forwarding the message downstream.\n\nSo in the example above, the header value should be interpreted as\n\"foo bar\", possibly with multiple spaces.  The current http-parser\nbehaviour of eliminating the LWS altogether clearly deviates from the\nspecs.\n\nFor http-parser itself to confirm exactly would involve significant\nchanges in order to synthesize replacement SP octets.  Such changes\nare unlikely to be worth it to support what is an obscure and\ndeprecated feature.  But http-parser should at least preserve some\nseparating whitespace when folding multi-line header values, so that\napplications using http-parser can conform to the specs.\n\nThis commit is a minimal change to preserve whitespace when folding\nlines.  It eliminates the CRLF, but retains any trailing and leading\nwhitespace in the header value."}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "orangemocha": {"issues": [], "commits": [{"url": "https://api.github.com/repos/nodejs/http-parser/commits/a252d4eebcb641e1e44a0d23844407fa3280cc45", "message": "fix content-length and chunk-size overflow test\n\nThe overflow check didn't work for all possible inputs."}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": [{"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/9194608", "body": "Well it's the same but this way it's more obvious where the number comes from: if you multiply by 10 and add a decimal digit, you cannot possibly reach ULLONG_MAX.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/9194608/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}]}, "runner-mei": {"issues": [], "commits": [{"url": "https://api.github.com/repos/nodejs/http-parser/commits/42d654157784c1104ad2298aee68907d13150f60", "message": "add vc project files to .gitignore"}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "VanCoding": {"issues": [], "commits": [{"url": "https://api.github.com/repos/nodejs/http-parser/commits/d7b938bdca9c683800c9aaa4530c082f1e28b5ee", "message": "Parse and emit status message of response"}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "charliesome": {"issues": [], "commits": [{"url": "https://api.github.com/repos/nodejs/http-parser/commits/11419c8e417c12ba78387d2ba914dd698700e4d4", "message": "Use unsigned int as bitfield type."}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "ulikoehler": {"issues": [], "commits": [{"url": "https://api.github.com/repos/nodejs/http-parser/commits/c4079e7c381a76688159f9f0812bbaa206d3b2eb", "message": "Add syntax highlighting to README C code"}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "chrisdickinson": {"issues": [], "commits": [{"url": "https://api.github.com/repos/nodejs/http-parser/commits/c6ee6ada69fabdbc03c074a08dd2882ed84b18b4", "message": "Do not accept PUN/GEM methods as PUT/GET.\n\n* Encountering them returns an error, `HPE_INVALID_METHOD`\n* Tests have been added."}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "cmr": {"issues": [], "commits": [{"url": "https://api.github.com/repos/nodejs/http-parser/commits/fa7455081a53f5513f55a7a21a766558f2090457", "message": "doc: add travis build status link"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/798eb9012e9a2fa2695ede9cc228fce996bc792d", "message": "Add a simple utility to dump events as they happen"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/54f6c78530f005c7cc36682e3bed23aa8d4727f7", "message": "Fix unmatched quote in dump_url output."}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/1c7f8cac9ea328647558a42f24206f3ad5da24b7", "message": "Fix IPv6 address parsing.\n\nFixes #133."}], "pull_requests": [], "issue_comments": [], "commit_comments": [{"url": "https://api.github.com/repos/nodejs/http-parser/comments/2341440", "body": "Herp, I knew there was a reason I initially had a nested if.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/comments/2341440/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/comments/2342216", "body": "That would simplify the code a lot, great suggestion (thanks for all the help!)\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/comments/2342216/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}], "review_comments": [{"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/2406836", "body": "I had tried `(void*) arg` but that didn't shut gcc up.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/2406836/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/2406861", "body": "Not sure what was going on there.. works fine here on my laptop now. It was late, what can I say :confused:\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/2406861/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/2429968", "body": "Sure can, after a tiny fix to the makefile.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/2429968/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/2477052", "body": "Looking back the logic I wrote doesn't even make sense. \"HTTP\" is a valid extension method, so setting the type to RESPONSE before encountering a / doesn't make sense.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/2477052/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/2481419", "body": "Fixed up in ff4d643\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/2481419/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}]}, "tomika": {"issues": [], "commits": [{"url": "https://api.github.com/repos/nodejs/http-parser/commits/0938fe599f7e3e4405880216ea445d634a974375", "message": "Add on_status_complete callback.\n\nAdd a \"status complete\" callback to support Simple-Response handling with HTTP\nversion <= 1.0.\n\nPatch by T\u00f3th Tam\u00e1s, tests by Corey Richardson."}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "bog-dan-ro": {"issues": [], "commits": [{"url": "https://api.github.com/repos/nodejs/http-parser/commits/1ca7de52587f19cb87a28b8ace2e0f2e6cfcde7f", "message": "Add \"int http_body_is_final(const http_parser *parser)\" method.\n\nIt's useful to check if the current chunk is the last one."}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": [{"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/1508426", "body": "Done\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/1508426/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/1508429", "body": "Done :)\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/1508429/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/1508435", "body": "Done.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/1508435/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/1508437", "body": "Done.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/1508437/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}]}, "pgriess": {"issues": [], "commits": [{"url": "https://api.github.com/repos/nodejs/http-parser/commits/ba5acd532f18e3937691d0c2fc28d3621aab3d3c", "message": "Merge pull request #104 from simonz05/patch-1\n\nCorrect misspelling in http_parser.h"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/fb3eeb7d058148959bc0b7a50b18d2ce8036124c", "message": "Merge pull request #118 from bpaquet/master\n\n#116 : refactor to allow url with basic auth a:b@toto.com"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/2ec48fd65d7fb78ea5c6fc79a3cc25f3d8c94643", "message": "Merge pull request #111 from ErikDubbelboer/master\n\nIgnore output of package build"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/26f508a289d45e143f6efcbdd00fe5822d529e33", "message": "Merge pull request #110 from ErikDubbelboer/master\n\nIgnoring .so files"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/eb04bbe1faa5a2999c5de7d9c6cb8de722118b8e", "message": "Merge pull request #73 from pgriess/http-10-message-length\n\nGet HTTP/1.1 message length logic working for HTTP/1.0"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/cd9404ad93254b164d1bfa76d2a84ce9dd459e70", "message": "Merge pull request #55 from pgriess/pause\n\nRFC: Implement http_pause()"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/d0bb867d1b58db453dd2a0845ec6b4d347645bdb", "message": "Implement http_parser_pause().\n\nSummary:\n- Add http_parser_pause() API. A callback may invoke this at any time.\n  This will cause http_parser_parse() to return indicating that it\n  parsed less than the number of requested bytes and set an error to\n  HBE_PAUSED. A paused parser with fail with HBE_PAUSED until it is\n  un-paused with http_parser_pause().\n- Stop using 'state', 'header_state', 'index', and 'nread' shadow\n  variables and then updating their http_parser fields when we're done.\n  Instead, update the live values as we go. This will make it possible\n  to return from anywhere in the parser (say, due to EPAUSED) and have\n  valid/expected state.\n- Update state before making callbacks so that if the want to pause,\n  we'll know the correct state already.\n- Make sure that every callback has a state that uniquely identifies the\n  next step so that we can resume in the right place if we were suppoed\n  to be paused.\n- Clean and re-factor up CALLBACK() macros.\n- Use CALLBACK() macros for (almost) all callbacks; on_headers_complete\n  is still a special case. This includes on_body which we used to invoke\n  manually with a long run of bytes. We now use a 'body' mark and hit\n  its callback just like every other data callback.\n- Clean up (most) gotos and replace with real states.\n- Add some unit tests.\n\nFixes #70"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/b115d110a3e82b8dceb6941534c3ed1c4378458f", "message": "Don't wait for EOF on 0-length KA messages.\n\n- Break EOF handling out of http_should_keep_alive() into\n  http_message_needs_eof(), which we now use when determining what to do\n  with a message of unknown length. This prevents us from falling into\n  the s_body_identity_eof state in the cases where we actually *do* know\n  the length of the message (e.g. because the response status was 204)."}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/248fbc3ab459d987a40eae8ed2bce7cc13e58372", "message": "Get HTTP/1.1 message length logic working for HTTP/1.0\n\n- Port message length logic from #72 to HTTP/1.0.\n- Add a bunch of unit tests for handling 0-length messages."}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/c48351fbdea2341fc5d185e72317b301a71df290", "message": "Merge pull request #58 from pgriess/parse_url\n\nAdd http_parser_parse_url()."}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/d7675cd9a6d90b4a38c6b7e6a1ac20f441bc0329", "message": "Add http_parser_parse_url().\n\n- Add an http_parser_parse_url() method to parse a URL into its\n  constituent components. This uses the same underlying parser\n  as http_parser_parse() and doesn't do any data copies.\n- Re-add the URL components in various test.c structures; validate\n  them when parsing."}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/c4ae661afc1f9a633931f0d615ea7c5eb78bf4ad", "message": "Merge pull request #64 from pgriess/i13\n\nRemove some chars from tokens[] per RFC."}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/48a4364fdd940f2173084e6be3d46e213d836646", "message": "Remove some chars from tokens[] per RFC.\n\n- Treat ' ' specially, as apparently IIS6.0 can send this in headers.\n  Allow this character through if we're not in strict mode.\n- Move some test code around so that test indices don't break when\n  HTTP_PARSER_STRICT changes.\n\nFixes #13."}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/f832bf3b21e9ac75b30b80e3ce5d25d6a53f06bc", "message": "Merge pull request #57 from fmardini/master\n\nA struct member rename for compatibility with errno.h"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/31ee648709d745e599cd094ab562323f1a6f2f0b", "message": "Cleanup doc references to removed CBs."}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/6bc88cc6e97e60e928d2f71d3f57586ee18f4da8", "message": "Merge pull request #54 from pgriess/path-query-frag-callbacks\n\nAPI CHANGE: Remove path, query, fragment CBs."}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/53adfacad1c16ec7da7de4a0aee03c2d70f19618", "message": "API CHANGE: Remove path, query, fragment CBs.\n\n- Get rid of support for these callbacks in http_parser_settings.\n- Retain state transitions between different URL portions in\n  http_parser_execute() so that we're making the same correctness\n  guarantees as before.\n- These are being removed because making multiple callbacks for the same\n  byte makes it more difficult to pause the parser."}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/49faf2e9cda1f9aac35877def071b0926333b883", "message": "Merge pull request #53 from pgriess/callback_noclear\n\nGet rid of CALLBACK_NOCLEAR()."}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/1e071a5087655fc110643b7d78068f99d0ab88d5", "message": "Merge pull request #52 from pgriess/errno\n\nBreak out errno into its own field."}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/54698275423cda03191cd3ed3163a4a4e8d8f47f", "message": "Get rid of CALLBACK_NOCLEAR().\n\n- This was only used by CALLBACK() (which then cleared the mark anyway),\n  and the end of the http_parser_execute() body (after which they\n  go out of scope)."}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/761a5eaeb1c312cd5f0649f84ca490a1e9bfb0db", "message": "Break out errno into its own field."}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/1786fdae36d3d40d59463dacab1cfb4165cf9f1d", "message": "Merge pull request #51 from kolbyjack/is_alpha\n\nGroup POST refinements, test all request methods, make IS_ALPHA use LOWER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/8e8344518e7f3592d8a780c4359ec32425e661e9", "message": "Re-jigger Makefile.\n\n- Uses more standard $CFLAGS and $CPPFLAGS variables to populate the set\n  of flags to build with.\n- Allow extending compilation and linking flags with\n  $CPPFLAGS_DEBUG_EXTRA, $CPPFLAGS_FAST_EXTRA, $CFLAGS_DEBUG_EXTRA, and\n  $CFLAGS_FAST_EXTRA.\n\nCloses #40."}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/0aa3e522eb782353d51f3e12115f81814f4ee083", "message": "Merge pull request #43 from pgriess/error-reporting\n\nFacility to report detailed parsing errors."}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/9114e58a776bf0add8d56e49da2f90247c7ce26e", "message": "Facility to report detailed parsing errors.\n\n- Add http_errno enum w/ values for many parsing error conditions. Stash\n  this in http_parser.state if the 0x80 bit is set.\n- Report line numbers on error generation if the (new) HTTP_PARSER_DEBUG\n  cpp symbol is set. Increases http_parser struct size by 8 bytes in\n  this case.\n- Add http_errno_*() methods to help turning errno values into\n  human-readable messages."}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/ddbbc07c10167964fcac5cc5a5ee6e3433c807a5", "message": "Fix minor compilation bug introduced by merge."}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/056bcd36728e52bef6fb42607be13037e4f474de", "message": "Merge pull request #49 from pgriess/upgrade-off-by-one\n\nFix off-by-one in handling upgrade bodies."}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/d4ca280af5287d6753099e1624727f4b530fe2cb", "message": "Fix off-by-one in handling upgrade bodies.\n\n- When handling upgraded bodies, http_parser_execute() used to return\n  one fewer bytes parsed than expected. This caused the final LF to be\n  interpreted by the caller as part of the body.\n- Add a bunch of upgrade body unit tests."}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/f684abdcc5a02e45ea70b8e0e17b3d0482bb392f", "message": "Merge pull request #27 from a2800276/master\n\nlowercasing in header after check for CR LF"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/e1d79e194081e00d4e879ad1cc2952fb98127084", "message": "Merge pull request #46 from kolbyjack/master\n\nAlso return error for bad requests starting with M or C"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/3bd18a779e880d996fda3cf4c35ef4dc4f6a24e1", "message": "IS_* macros for char classes.\n\n- Add IS_ALPHA(), IS_NUM(), IS_HOST_CHAR(), etc. macros for determining\n  membership in a character class. HTTP_PARSER_STRICT causes some of\n  these definitions to change.\n- Support '_' character in hostnames in non-strict mode.\n- Support leading digits in hostnames when the method is HTTP_CONNECT.\n- Don't re-define HTTP_PARSER_STRICT in http_parser.h if it's already\n  defined.\n- Tweak Makefile to run non-strict-mode unit tests. Rearrange non-strict\n  mode unit tests in test.c.\n- Add test_fast to .gitignore.\n\nFixes #44"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/b1c2cf83fd655f1347b76efd65a2206ca2b6676f", "message": "Expose F_* flags as public API.\n\nFixes #42."}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/9639c7c21c868cc743f5cce9ec1cffc1cbcafe01", "message": "Support ?-terminated hostnames per RFC 2396.3.2.\n\n- Bust out of s_req_host and s_req_port on '?'.\n- Add tests for query string parsing.\n\nFixes #38."}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/50b9bec552ef6ff6ecb8d0e26fcb4da30ac62934", "message": "Allow octets > 127 in path components.\n\n- This is non-spec behavior, but it appears that most HTTP servers\n  implicitly support non-ASCII characters when parsing path components.\n  Extend http-parser to allow this.\n- Fill out slots [128, 256) in normal_url_char[] with 1 so that these\n  high octets are accepted in path components.\n- Add unit test for paths that include such non-ASCII characters.\n\nFixes #37."}], "pull_requests": [], "issue_comments": [{"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1213231", "body": "Thanks for taking a look at this, Mark.\n\nThe use-case for this is that I have an http-parser-based proxy (not Node) that is rejecting requests with UTF-8 paths as malformed. I don't control the clients that are sending requests to this proxy, and it appears that this type of traffic is not as uncommon as I would have hoped.\n\nI suppose http-parser could support both strict and lenient modes for those who wished to control this a bit more closely. Ry, would you be interested in that? In practice, I'd imagine that most (all?) people would run with strict mode disabled unless they controlled request generation.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1213231/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1225568", "body": "I'm not in love with the API changes, but I think the functionality is right.\n\nI'd have preferred to dump the result data into http_parser but didn't want to inflate the struct since I know you worked hard to make it so small. That said, it's just 8 extra bytes ;)\n\nAlso, I opted against creating RETURN_SET_ERRNO() and GOTO_SET_ERRNO() macros as I wanted to keep flow-control logic visible in the main function body.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1225568/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1297305", "body": "Any thoughts on this? Happy to iterate on it.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1297305/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1301888", "body": "Ok, I'll go with (2). I hate the API mangling that went into the existing change anyway ;)\n\nI do, however, feel somewhat strongly about exposing source-level information. This is quite useful for debugging (e.g. to figure out which of the 12 callsites that set INVALID_VERSION w/o setting a breakpoint on all of them). I'll update the pull with a a uint16_t line number that's visible only under (the to be created) HTTP_PARSER_DEBUG flag and see what you guys think.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1301888/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1351331", "body": "I believe the CONNECT parsing issue was fixed by 3bd18a779e880d996fda3cf4c35ef4dc4f6a24e1.\n\nLet me know if this isn't working for you.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1351331/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1388041", "body": "We check that we're in CONNECT mode because then we're accepting a hostname (which can start w/ a digit). If we're not in CONNECT mode, we're looking for a URI scheme must start with an alpha character (see RFC 2396 section 3.1).\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1388041/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1398322", "body": "This should get the job done, but is slightly different than what you were asking for, Ben.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1398322/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1403892", "body": "Looks great. Can you re-base this all into a single commit before I merge it?\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1403892/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1405009", "body": "If it makes it easier,  in the future you can just push the branch that you made the pull request from. This pull request is just a request to merge changes from a repo/branch pair anyway, not a specific diff.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1405009/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1595338", "body": "I'd like to remove these because their existence makes pausing the parser difficult.\n\nThe problem is the 'mark' state that we retain, which points to the beginning of a run of bytes for some data callback (e.g. a header name, a header value, a url, a path, etc). The path/query/fragment marks are special because they share a mark with URL. If we make a path/query/fragment callback and the parser is paused as a result, we need to remember where our mark is and use it to replay the subsequent URL callback when parser execution resumes. We can indeed handle this by tracking the # of bytes that need to be sent over to the URL callback in the http_parser struct and dumping logic to handle this at the top of http_parser_execute().\n\nAnyway, so while this is fixable, I'd prefer to just dump this special-case alltogether, especially in light of the relatively plentiful ecosystem of URL parsers available in most languages (e.g. uriparser for C, google-url for C++). Of course, one would need to handle concatenation of multiple URL callbacks and only hand the URL off to to the parser when it's known to be finished (unless your parser is resumable, which seems unlikely).\n\n@ellzey: Will you be able to plug in a third party URL parser?\n\n@clifffrey: Yeah, maybe that's a good compromise in case meaningful use-cases emerge for this functionality. I think it's somewhat telling that the known 3 major users of this library don't use the path/query/fragment callbacks.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1595338/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1595543", "body": "@ellzey The problem is not that any individual callback can be called more than once. Rather, the problem is that multiple callbacks can own the same range of bytes, and pausing between the two requires accumulating extra state in the parser.\n\nDo you actually need schema/authorization/host/path/etc callbacks to come form http-parser itself? I'm not sure what your use-case would be such that you'd need this functionality vs. using some other URL parser as soon as you have the full URL (i.e. as soon as you get a callback that is not on_url).\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1595543/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1619454", "body": "Oops, fixing.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1619454/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1619496", "body": "Fixed.\n\n@jonashaag You won't be able to get these callbacks back. This change removes support for them. If you want to parse the URL that results from on_url callbacks, you should use a third-party URL parser like google-url, etc.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1619496/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1660693", "body": "A simple zero-copy URL parser submitted for pull at ry/http-parser#58.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1660693/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1682088", "body": "Thanks @coreyfarrell. I'll fix that.\n\nBTWs in the meantime, I'm going to merge this into our private repository and start testing with it. If things look good, I'll merge it (including any bugfixes of course) unless there are any strong objections. Look for that to happen in a week or two.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1682088/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/2039618", "body": "- @mnot @arhrodriguez\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/2039618/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/2039628", "body": "Oops, didn't mean to close this. There's a pull request out for this fix now. If nobody complains w/in a few days, I'll merge it in.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/2039628/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/2039690", "body": "We're hitting this as well. @ry I think the patch you sent out is missing the logic for responses that are mandated not to have a body (100-continue, HEAD responses, 204, 304, etc). I'll throw up a pull request today or tomorrow.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/2039690/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/2042441", "body": "If this really needs to stay in, we could gate the behavior of space in particular on HTTP_PARSER_STRICT.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/2042441/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3385644", "body": "Closing, as I believe this was fixed by #72. Mark, please re-open if you disagree.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3385644/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3391299", "body": "I updated the pull to reject /, } and \" always, but ' ' conditional depending on whether or not we're in strict mode.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3391299/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3391914", "body": "I updated the API slightly to allow using this with CONNECT <host>:<port> \"url\"s. If nobody has any objections, I'll merge this this weekend.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3391914/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3392259", "body": "@carlosmn Please re-base and I'll merge it.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3392259/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3392966", "body": "We've been using this without incident for a few months at this point. I'd like to merge it in if there are no additional objections.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3392966/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3397596", "body": "Added some tests. I'll give people a few days to comment before merging this.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3397596/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3406565", "body": "This will be fixed when #55 gets merged.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3406565/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3406583", "body": "Duplicate of #60.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3406583/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3406586", "body": "Fixed by d7675cd9a6.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3406586/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3406704", "body": "Ok, here we go.\n\n@clifffrey and @ry please yell if this breaks anything for you guys.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3406704/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3406746", "body": "The first case fails because the test definition needs to indicate that an upgrade was expected. You can set\n\n```\n,upgrade= \"\"\n```\n\nin your definition to fix this.\n\nThe second case is a real bug -- we just don't handle user:password@host:port syntax. I'll rename this issue appropriately.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3406746/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3412680", "body": "For the hostname, I think this is a bug.\n\nFor port, though it does violate the RFC, I could see allowing the digits after the ':' to be optional (and just treating this case as though no non-default port was specified).\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3412680/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3546524", "body": "@rrizun Yeah, looks like I missed that. Thanks.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3546524/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3940686", "body": "What is this feature for? I read joyent/node#2612 but I'm not entirely clear on how this would enable faster proxying. Is the idea that you want to know where the headers end so that you can slice off a `Buffer` representing the request/status line + headers and send it un-modified to the other end of the connection? To use that, I think you'd also have to know where messages _begin_. Would you just walk back `boundary` bytes and consider this the beginning of the message?\n\nIncidentally, this change adds 4 bytes to the `http_parser` size, which I suspect @clifffrey would like to avoid.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3940686/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3940757", "body": "Another way to go, which would enable `Buffer` re-use when handling the message body would be to stop de-chunking bodies when parsing them. This would also have the side-effect of preserving chunking decisions made on either side of the connection, which might be useful in some situations (though not required by the RFC).\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3940757/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3948543", "body": "A slight clarification: The callbacks that @indexzero is referring to are those that cross the JavaScript<->C++ boundary in Node (which are particularly slow relative to those that do not cross the boundary).\n\nI'm still -1 on this because fundamentally I think this is a Node issue (callbacks into JavaScript are expensive), not an http_parser issue. Providing an API that allowed the caller to inspect the raw byte stream is kind of counter to the ethos of this parser library, which as it stands now owns all framing and data manipulation decisions and delegates action by callbacks: it decides when to eat characters (spurious whitespace), join header values when they span lines, de-chunks body data, etc.\n\nInstead, I think we can solve this in the Node/http_parser integration layer by providing an `http_parser_execute()` workalike API that populates a structure describing the event stream (event X fired at byte N, Y fired at byte M, etc) and returns it to the caller in one shot. This would be a behavior similar to what's in the un-finished [event_stream](https://github.com/joyent/http-parser/blob/event_stream) branch.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3948543/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4197874", "body": "Yeah, this is tricky to fix because a single byte can trigger multiple callbacks, and if a callback other than the last results in the parser being paused, we need a way to track that these addition callbacks need to be executed. We're doing this now by not consuming the byte until we're done with all of the callbacks that it should trigger. For callbacks where we do _not_ re-execute the same byte, this isn't an issue, of course.\n\nWe could fix this to return that all bytes were consumed (e.g. by stashing the last byte in `http_parser` and using it when continuing execution), but we'd be breaking the assumption of users of the `http_parser_execute()` API that if all bytes are consumed, there is no reason to call `http_parser_execute()` again until there is more data to parse (or an EOF has been received). We'd also need a way to poke the parser to consume this stashed byte -- calling `http_parser_execute(NULL, 0)` isn't going to cut it, as that would look eerily like an EOF to the un-trained eye. Some options here include adding a new `http_parser_execute_buffered()` API, or having `http_parser_pause(0)` kick off execution.\n\nMercifully, these changes in execution behavior might okay-ish because these assumptions about return value/byte consumption only break if you're using `http_parser_pause()`, and AFAIK there are a limited number of users of this function (possibly only us and AndreLouisCaron/httpxx).\n\nAny other ideas @bnoordhuis, @ry or @clifffrey?\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4197874/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4201113", "body": "_I don't really care if more callbacks are invoked after I pause the parser (e.g. on_message_complete() for an empty message), so long as it pauses \"soon\"._\n\nI think having a immediate, non-advisory pause is pretty useful, particularly as evidenced by the Node community's continued struggles to deal with its absence: the fact that `ServerRequest.pause()` doesn't actually pause bites people frequently, and is a work-around that looks likely to land in the latest release (by buffering in the application) is both highly desired and looked at with skepticism because of what it has to do to work around the fact that `http_parser` couldn't natively pause (they don't know about `http_parser_pause()` yet, it seems).\n\nThat said, there's certainly a trade-off between implementation complexity and value, but I don't think we've crossed that threshold.\n\n_The real issue here it that the parser does not distinguish between HPE_PAUSED and real error codes._\n\nIs your expectation that calling `http_parser_execute()` should implicitly un-pause the parser? If so, I'm not sure I follow how that's related to reporting the correct number of bytes consumed.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4201113/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4201469", "body": "_Is node (or any other library) relying on http-parser not executing on_message_complete after pausing from inside on_headers_complete?_\n\nNot that I know of. AFAIK there are very few users of `http_parser_pause()`.\n\n_If not, I think the easiest 'fix' would be to implement pause as \"don't consume any more bytes (but call whatever callbacks are necessary)\" instead of \"stop doing anything\"._\n\nYeah, that's certainly an option.\n\nI do think it's worth spending some amount of effort to get the API to work with the more rigid semantics, though, as this provides a more powerful API. I'll spend some on that this weekend and see how far I get.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4201469/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4219693", "body": "LGTM. Why the ordinals, though?\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4219693/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4258315", "body": "Yeah, @AndreLouisCaron is right that the particular devil here is the extra byte that you need to stash: where to stash it, and how to kick off parsing with it. I don't think we need to add any more parser states to accomplish this, as there is already a state for every place where we might have paused (i.e. after every callback). We just need to tweak these states to look at the stashed byte.\n\nI'm starting to think that renaming `http_parser_pause()` to `http_parser_unpause_and_execute()` (or something) is the right way to go. I can't think of a meaningful situation where one would un-pause the parser without wanting to then immediately process any data that remained. The major benefit of this API name change would be that it's obvious that the parser going to start executing without being given any additional data.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4258315/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4258996", "body": "What do you think of moving the header comparison logic _out_ of `http-parser` and requiring the application to deal with it? A proxy application is going to need this logic anyway (since they're manually generating HTTP bytes for the request/response), and even non-proxies still need to communicate whether or not this is a response to a `HEAD` request via the `on_headers_complete()` callback. What if we delegated all header processing logic to the application and added a channel to communicate knowledge derived from those headers (keep-alive? is there a response body? how long is it?) from the application to the parser?\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4258996/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4263146", "body": "@einaros Yeah, but to get message framing right, the parser needs to know if there is a `keep-alive` or `upgrade` connect token. Right now, it doesn't know how to tokenize `Connection` headers -- it just assumes there is a single token in the header value.\n\nIf we instead offloaded this header-interpretation work to the application, the parser would get a lot simpler.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4263146/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4286530", "body": "So I think that this particular issue is not an `http-parser` bug, but it did expose another bug to the light of day: the parser is treating the `Connection` header as though it always contains a single token. This is a problem because it relies on being able to figure out if `Connection: close` or `Connection: keep-alive` was set to handle message framing. For example, if the client sent\n\n```\nGET / HTTP/1.0\nConnection: foobar, keep-alive\n```\n\nThe parser should recognize this as a valid `keep-alive` request.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4286530/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4286547", "body": "Oh, sweet. It looks like @kolbyjack has a pull request for this already: #100.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4286547/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}], "commit_comments": [{"url": "https://api.github.com/repos/nodejs/http-parser/comments/397306", "body": "Thanks. I was just about to submit a patch for this ;)\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/comments/397306/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/comments/487487", "body": "Yeah, it's just request_url now. Check out the discussion on this pull request for the justification at ry/http-parser#54.\n\nWhat were you using the callbacks for? If this is node-land, can you just use the the 'url' module to parse what you want?\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/comments/487487/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/comments/845227", "body": "I believe we need to be doing this status code check for HTTP/1.0 as well.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/comments/845227/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/comments/846407", "body": "Yeah, if the client and server both agree on keep-alive (i.e. by both sending \"Connection: keep-alive\" headers), we're dealing with the same situation as HTTP/1.1: we have a bytestream that contains a response with no body followed by another response. The case we're dealing with here is not that we can't determine the response length -- it's that we know that the length is 0.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/comments/846407/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}], "review_comments": [{"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/334088", "body": "Accepting any non-CR/LF character is a bit more liberal than the RFC allows, but I don't really think it's a problem. Also, this doesn't handle LWS properly (we can get a CRLF followed by some number of HTs or SPs and continue the reason). Check out the way the s_header_value_lws state works.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/334088/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/334931", "body": "Yeah, agreed that we should be validating that.\n\nHowever, this isn't a regression. I'll file a bug for this. We have similar problems with handling empty hosts as well, both of which probably need a new state to indicate the beginning of the entity so that we can verify that there is at least one character.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/334931/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/335628", "body": "Filed #74 for this.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/335628/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/1226449", "body": "Rather than copying into `part` to do null-termination, you could use a format specifier to indicate the number of characters in the string. For example, something like this:\n\n```\nprintf(\"%.*s\\n\", u->field_data[i].len, url + u->field_data[i].off);\n```\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/1226449/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/1226526", "body": "These are starting to get long. At some point, we might want to replace this with lookups into an array.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/1226526/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/1226810", "body": "Let's check this before the `IS_USERINFO_CHAR() ...` check above because it's cheaper.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/1226810/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/1226840", "body": "Since the \"host\" parsing is now really parsing full-fledged RFC2396 authorities, maybe we should rename these states and the other symbols that reference host parsing.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/1226840/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/1226921", "body": "I'm not sure we really need this state. The caller is feeding in characters one-at-a-time anyway. If they care about whether or not there's a literal `@` in the authority, they can check for themselves. The only thing information is used for in `parse_url_char()` is to make sure that we don't have consecutive `@`s, but even that's not a complete check -- we should really be checking for whether or not there are more than one. Again, the caller is pretty well positioned to do this with a simple counter.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/1226921/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/1226963", "body": "Maybe a comment here about how `http_parse_host()` will fail for empty hosts? Otherwise it's not clear why we think we're going to be able to correctly fail this condition.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/1226963/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/1227172", "body": "Some day it'd be nice to unify the switch statement/logic from here and in `http_parser_parse_url()`, both of which do basically the same thing.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/1227172/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/1227343", "body": "Why do we need the `s_http_userinfo_start` state at all? It sees to behave the same as `s_http_userinfo`.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/1227343/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/1227434", "body": "There's some weird spacing going on before the `++` operator, here and below.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/1227434/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}]}, "martell": {"issues": [], "commits": [{"url": "https://api.github.com/repos/nodejs/http-parser/commits/9852e5d048987ac245ef23f4326ff72fc94b57b1", "message": "test: %zu to %lu for msvcrt fixes for Mingw64"}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "erikdubbelboer": {"issues": [], "commits": [{"url": "https://api.github.com/repos/nodejs/http-parser/commits/4d7b5dcb9a471d6de80dedee0200ce1d751b107e", "message": "ignore output of package build"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/4c1e785a04dd93e2fa00f1fdd11ca11c28e9b1b4", "message": "Merge branch 'master', remote-tracking branch 'upstream/master'"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/0067f54dbe868a26b1afc41d77ba405166ed4a9b", "message": "Ignoring .so files"}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "TooTallNate": {"issues": [], "commits": [{"url": "https://api.github.com/repos/nodejs/http-parser/commits/a3373d7627c8e141c932ad48dcb8613e6c4011ea", "message": "add support for \"SEARCH\" request methods"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/5a1e5562397e8048d0be5d082ba0d376b9412fa0", "message": "test.c: fix off-by-one on the requests test cases"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/f825b52b7f2d4bf86c3300ae33ceb3dd1fa64571", "message": "Added support for \"SUBSCRIBE\" and \"UNSUBSCRIBE\" request methods."}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/d56a0700d0d9ccad427995e3da88856a96d2a455", "message": "Add support for \"M-SEARCH\" and \"NOTIFY\" request methods.\n\nAllow a request path of \"*\" (for SSDP requests)."}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/84578ae7a883a799c454f0e176782d01c801e61e", "message": "Set http_major when a request omits the HTTP version\n\nI.E. \"GET /\" in telnet"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/a66c61c190a90653da3fd7c1443a1a7329472567", "message": "Allow whitespace in the 'Content-Length' header."}], "pull_requests": [], "issue_comments": [{"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/477050", "body": "Yes sir!\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/477050/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/490316", "body": "Anything else this needs, ry?\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/490316/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/533942", "body": "Ok, added a test. But if you'd rather, I can 1) combine the commits into a single patch, and 2) write them against the current master branch. Let me know.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/533942/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/558205", "body": "Thanks ry!\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/558205/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}], "commit_comments": [], "review_comments": []}, "dgwynne": {"issues": [], "commits": [{"url": "https://api.github.com/repos/nodejs/http-parser/commits/662e523a929c488106f4b319c69a574fa3a4a96c", "message": "fix non-CONNECT tests missing port/hostname bits\n\nset is_connect properly"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/67568421e9ede487860aa376889f68e0eeb626ed", "message": "allow extra ? at the beginning of a query_string.\n\nfixes joyent/http-parser issue #25"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/8da60bc423d0243588854e5c4b2f3ae0c637cb8d", "message": "implement parsing of v6 addresses and rejection of 0-length host and ports.\n\nthe v6 parsing works by adding extra states for working with the\n[] notation for v6 addresses. hosts and ports cannot be 0-length\nbecause we url parsing from ending when we expect those fields to\nbegin.\n\nhttp_parser_parse_url gets a free check for the correctness of\nCONNECT urls (they can only be host:port).\n\nthis addresses the following issues:\n\ni was bored and had my head in this space."}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/04995251103354870eb4d6ee1a65e95827721e06", "message": "Fix http_parser_parse_url for urls like \"http://host/path\".\n\nBefore this change it would include the last slash in the separator between the\nschema and host as part of the host. we cant use the trick used for skipping the\nseparator before ports, query strings, and fragments because if it was a CONNECT\nstyle url string (host:port) it would skip the first character of the hostname.\n\nWork around this by introducing a few more states to represent these separators\nin a url differently to what theyre separating. this in turn lets us simplify\nthe url parsing so can simply skip what it considers delimiters rather than\nhaving to special case certain types of url parts and skip their prefixes.\n\nAdd tests for the http_parser_parse_url().\n\nThis compares the http_parser_url struct that http_parser_parse_url()\nproduces against one that we expect from the test. If they differ\nthen http_parser_parse_url() misbehaved."}], "pull_requests": [], "issue_comments": [{"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3840712", "body": "to test.c? not easily, there's about too many layers of abstraction in there for my tiny brain. i'll write a crappy standalone test for you to look at.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3840712/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3840744", "body": "https://gist.github.com/1756453 is some crappy test code i wrote.\n\nwith joyent/http-parser:\n\n$ ./test2\n\"proxy request\" failed, bad u\ntarget u:\n        fields: 0xb, port: 0\n        field 0: off: 0 len: 4 part: \"http\"\n        field 1: off: 7 len: 8 part: \"hostname\"\n        field 2: off: 0 len: 0 part: \"\"\n        field 3: off: 15 len: 1 part: \"/\"\n        field 4: off: 0 len: 0 part: \"\"\n        field 5: off: 0 len: 0 part: \"\"\nresult u:\n        fields: 0xb, port: 0\n        field 0: off: 0 len: 6 part: \"http:/\"\n        field 1: off: 6 len: 9 part: \"/hostname\"\n        field 2: off: 0 len: 0 part: \"\"\n        field 3: off: 15 len: 1 part: \"/\"\n        field 4: off: 0 len: 0 part: \"\"\n        field 5: off: 0 len: 0 part: \"\"\n$ echo $?\n1\n$ \n\nwith dgwynne/http-parser:\n\n$ ./test2\n$ echo $?\n0\n$ \n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3840744/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3859732", "body": "there you go\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3859732/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3867350", "body": "i think i fixed the style issues.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3867350/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3874927", "body": "type fixed.\n\ni utterly hate CLAs, but I've filled it in.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3874927/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3904844", "body": "this git thing is hard. will you laugh at me if i say i miss cvs?\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3904844/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3904935", "body": "too messy, lemme clean up\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3904935/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3905290", "body": "i still hate git.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3905290/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4039369", "body": "cool.\n\nyou should be able to close a few issues now...\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4039369/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}], "commit_comments": [], "review_comments": []}, "ivosh": {"issues": [], "commits": [{"url": "https://api.github.com/repos/nodejs/http-parser/commits/2a2f99f9cde42c687bb8e47cb5cfa03d52d33969", "message": "http_parser_init does not clear status_code"}], "pull_requests": [], "issue_comments": [{"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3684676", "body": "this is a pull request for issue #75\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3684676/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3684705", "body": "this is a duplicate of #82\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3684705/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3687252", "body": "see my second commit which addresses the problem you pointed out\nI hope it is ok now\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3687252/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3687666", "body": "I'll fix it in a while.\nBut it does not compile with these settings anyway, see:\n\n<pre>\n> gcc -I. -DHTTP_PARSER_STRICT=1 -DHTTP_PARSER_DEBUG=1  -Wall -Wextra -Werror -ansi -std=c89 -pedantic -O0 -g  -c http_parser.c -o http_parser_g.o\n\nIn file included from http_parser.c:24:\n./http_parser.h:187: error: comma at end of enumerator list\n./http_parser.h:205: error: type of bit-field 'type' is a GCC extension\n./http_parser.h:206: error: type of bit-field 'flags' is a GCC extension\n./http_parser.h:219: error: type of bit-field 'http_errno' is a GCC extension\n./http_parser.h:226: error: type of bit-field 'upgrade' is a GCC extension\nhttp_parser.c:406: error: expected '=', ',', ';', 'asm' or '__attribute__' before 'enum'\nhttp_parser.c: In function 'http_parser_execute':\nhttp_parser.c:963: error: implicit declaration of function 'parse_url_char'\n</pre>\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3687666/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3688372", "body": "The CLA signed. Thanks for your comments.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3688372/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}], "commit_comments": [], "review_comments": []}, "koichik": {"issues": [], "commits": [{"url": "https://api.github.com/repos/nodejs/http-parser/commits/b47c44d7a660d9ee6ab365864e345081f237b433", "message": "Fix response body is not read\n\nWith HTTP/1.1, if neither Content-Length nor Transfer-Encoding is present,\nsection 4.4 of RFC 2616 suggests http-parser needs to read a response body\nuntil the connection is closed (except the response must not include a body)\n\nSee also joyent/node#2457.\nFixes #72"}], "pull_requests": [], "issue_comments": [{"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3381173", "body": "@bnoordhuis - Thanks for your review, updated.\n\n@ry - Signed!\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3381173/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3381396", "body": "@ry - Thanks!\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3381396/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3388713", "body": "Oops, sorry, I did not notice this.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3388713/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3628990", "body": "```\nHTTP/1.1 200 OK\\r\\n\\r\\n\n```\n\nUnless this is a response to a HEAD request, http-parser cannot determine the length of the body. So, it should read until EOF. (It does not match .1-4 of sec 4.4, then .5 is applied.)\n\n> This was making the parser to close the connection for every message without a body\n\nYou should respond with `204 No Content`, not `200`.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3628990/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3631581", "body": "@bnoordhuis - If `on_headers_complete()` returns `1`, then `F_SKIPBODY` flag is set. It indicates that it is a response to a HEAD request.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3631581/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}], "commit_comments": [{"url": "https://api.github.com/repos/nodejs/http-parser/comments/845937", "body": "@pgriess - With HTTP/1.0 or earlier, Keep-Alive is disabled by default. Therefore, I think that we do not need it. Keep-Alive is used if and only if the response has `Connection: Keep-Alive` (or legacy `Keep-Alive:`, but http-parser does not seem to support it).\n\n[EDIT] I may understand what you mean. HTTP/1.0 server sends `Connection: Keep-Alive`, but the body length may be unable to be determined.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/comments/845937/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}], "review_comments": []}, "ry": {"issues": [], "commits": [{"url": "https://api.github.com/repos/nodejs/http-parser/commits/3cf68f9a7065325bfbc69917a16245579940c226", "message": "Fix compilation on MSVC 2008 which doesn't bundle stdint.h\n\nThanks to Steve Ridout for the patch. Fixes #69."}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/918a071542ed1913ac5450979d08799ab1339e35", "message": "Peter Bright's VC fixes"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/965f91bc76b2d1601e23dadec1b6da41c2293236", "message": "Support MSVS"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/ec74d9294c98e86cfdd06269444c1c6fdd155d65", "message": "Add GYP file for integration into GYP projects."}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/eee60127c0df551be085cc8e7983e36d7700d885", "message": "Support PATCH method\n\nRequested in https://groups.google.com/forum/#!topic/nodejs-dev/iEOyiDkJRLs"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/1efd9ac6a07fcd66f8f53f223f12c18a3fda686c", "message": "Number HOSTNAME_UNDERSCORE test"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/2839784927c82410e5a618bce0c540254cf66ce0", "message": "HTTP_STRICT ifdefs out behavior introduced in 50b9bec\n\nFixes #37."}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/8dabce6ec7142319bc5c883ff53bf7302f0d83ce", "message": "It was pointed out we're missing attribution to NGINX"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/32c0e1158361b5952bd0cfed2355e33639664bc4", "message": "bump to v1.0"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/63daf22f2cb5c606448ecd509a726ac8ee7a48a5", "message": "Update copyright headers"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/1c3624a963dab6809aeda9615d0cfe277d1d43a3", "message": "Detect errors on EOF"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/fcdbc2629f9df0d84e427051a501d61731f36dd8", "message": "Add hack for tmm1"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/03970a576da4fc921d164be35e0a27b5fbdb1cc5", "message": "Test that it can handle $ in header field"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/b75cea580a6a283ab162d734831948eaa96ee7ab", "message": "Test for dots at the begging on header fields"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/04bc364610469954711349c7c6e67881a5487868", "message": "Make sure it can handle spaces in content-length"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/37e900936965862ef15c1dc5382b73cb11a059e7", "message": "Digits in hostname on CONNECT req allowed"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/fb875caa43c585ee6017f09b6bee69a7f857fab3", "message": "Add non-ascii in status line test\n\nfrom Ben Noordhuis"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/51de89f8b026b38ff8edb9e68fdbbf08b499a61d", "message": "Accept tokens + SP for header fields"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/047ced37841b7f42b9254bce2b2e5e6b95cb7ef8", "message": "readme typo (thanks tmm1)"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/c1d48fdce8c63a1cf1951fda4b2297214b325c63", "message": "Changes to compile with clang"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/6f12467a8af7c365c5d072e3b5456a5c4159957a", "message": "Use lookup tables of my own."}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/d6f34ae9924d7f690a9f7f7519a031fae58682d2", "message": "Add CONTRIBUTIONS file"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/f0d50c3fb1093ba92aa12d07ab1271879abbad8b", "message": "Update size of struct in README"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/c7c242d55ce1fab17d6e1db71d10d9f20e81d09f", "message": "typo"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/a59ba4d866ef6abfa25e3f763e6c4f8990a4877d", "message": "Support long messages"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/120f0f6e09773dbe003841b5b339f9284dd63aad", "message": "Allow spaces in header fields"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/5f27ea8179af48a1ac5a8f2583f27a05be28a91e", "message": "Fix long line"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/c46b3e3942a8ae605a89810683ef36c22cc0ff7a", "message": "Fix typo s_start_res_or_resp"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/03b8eaa5f8d312f44893cdb61de550993ce3e0c0", "message": "Reset url_mark on s_req_host\n\nadd a new scan test. Report and fix by Master Becker."}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/ddbd5c3728e2663166d84917e178b2d915958c32", "message": "Expose http_method_str() to get a string version of a method"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/9dc258f9dd8357db6177d5afa9a2c26618c10daa", "message": "Add subversion request methods\n\nREPORT, MKACTIVITY, CHECKOUT, MERGE"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/4cf39fd2fa8d1b52338ad3c4dd9ae6b3f32d72f4", "message": "Support request URLs without schema\n\nTest case from Poul T Lomholt <pt@lomholt.com>"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/cdda8b6a606742a4842e2f3a5a9dfba72dba5330", "message": "Support empty header values\n\nTest case by Pierre Ruyssen <pierre@ruyssen.fr>"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/d95b484e41a7c321bb8d32e652fe3e608777cb55", "message": "Update readme"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/8beed7ef17982e7e5fcd60413a30a01fdc971f74", "message": "Fix whitespace"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/c2acc213ac522d68f41b40f25af85dda098fd4f2", "message": "Skip body for HEAD responses\n\nTODO: need test for response with non-zero content length but no body."}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/443a6ea625fa9cc3af94465257db9e728a4d0a49", "message": "Use _g for the debug build"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/7cfa645fc7813a8a633ade71f622047cd414c9f1", "message": "Fix long chunked message bug\n\nThe HTTP_MAX_HEADER_SIZE was being consulted at the end of the chunked\nmessage (when you look for trailing headers).\n\nhttp://github.com/ry/node/issues#issue/77"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/88d11b394d37cb6a5420bd8b3df4d550f74c80ef", "message": "Support Upgrade header"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/6f72c780f0a237a775150a9963bcdf5299685cde", "message": "Remove stddef include, it's included in http_parser.c"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/69cf8d8da9ba0907192f26239eb41223871dd46c", "message": "Add documentation about callback return valeus"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/e09651c6bbe3e8d8659d6364c86395412b573a1e", "message": "cross platfom size_t printing"}], "pull_requests": [], "issue_comments": [{"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/31078", "body": "Yes this is still true. Annoying but it make a lot of other things much simpler (i.e. the http_parser does not have to make decisions about how how you might pre-allocate this)\n\nHere are two examples\n1) http://github.com/ry/http-parser/blob/37a0ff8928fb0d83cec0d0d8909c5a4abcd221af/test.c#L403 \n2) http://github.com/ry/node/blob/842eaf446d2fdcb33b296c67c911c32a0dabc747/src/http.js#L284 (in javascript, but it's just a thin abstraction over the parser callback)\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/31078/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/31080", "body": "Here is an untested code snippit which more directly answers your question: http://gist.github.com/155877\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/31080/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/31082", "body": "I would gladly accept a patch for better documentation of this tricky part of the library. :)\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/31082/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/104067", "body": "fixed in b5b116e59ea3a22b4898705f30c5b0ffe7ce1e7c\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/104067/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/104182", "body": "sorry, i guess you're the same that reported the news.ycombinator.org bug in node. i just realized this is the same error. the fix I gave doesn't solve the problem.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/104182/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/154421", "body": "It should.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/154421/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/154623", "body": "Please show an example where it is not called. \n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/154623/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/155408", "body": "You're not making the call for EOF. Do this:\n    http_parser_execute(&parser, settings, response, strlen(response));\n    http_parser_execute(&parser, settings, NULL, 0);\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/155408/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/156062", "body": "Your response is missing the last `\\r\\n`. Chunked messages must be terminated by `0\\r\\n\\r\\n` \nhttp://www.w3.org/Protocols/rfc2616/rfc2616-sec3.html#sec3.6.1\n\nAre you seeing a response like this in real-life?\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/156062/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/158512", "body": "thanks for the note. i added some text in 69cf8d8da9ba0907192f26239eb41223871dd46c\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/158512/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/221346", "body": "you can see where it failed by looking at the result of http_parser_execute()\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/221346/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/221361", "body": "yes, but it exits immediately if there was an error. so if http_parser_execute() < sizeof(buf) then there was an error (or an Upgrade). You can use this to point out where the error was - which is perhaps more useful than an error code.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/221361/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/221407", "body": "You can communicate your state (or what action to take) to the code calling `http_parser_execute()` through your `void *data` object. \n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/221407/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/244479", "body": "Can you please provide a dump of such a request?\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/244479/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/265901", "body": "closing.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/265901/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/265935", "body": "Fixed in 4cf39fd2fa8d1b52338ad3c4dd9ae6b3f32d72f4.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/265935/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/325375", "body": "Thanks for the report. Fixed in 120f0f6e09773dbe003841b5b339f9284dd63aad.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/325375/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/463885", "body": "thanks. comitted in a66c61c190a90653da3fd7c1443a1a7329472567\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/463885/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/519149", "body": "This breaks the test on \"HTTP/1.1 404 Not Found\\r\\n\\r\\n\"\n\nhttps://github.com/ry/http-parser/blob/047ced37841b7f42b9254bce2b2e5e6b95cb7ef8/test.c#L635-648\n\nWhich I'm unclear the origin of. Should this message cause an error?\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/519149/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/521392", "body": "Mark, please review this patch: https://github.com/ry/http-parser/commit/fffa54f1111bdb0ea03026220b4ef62da421fe4f\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/521392/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/530371", "body": "Actually that patch I gave is breaking the 100-continue test in NodeJS. Gr.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/530371/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/533689", "body": "Thanks for the notice. I fixed this in 37e900936965862ef15c1dc5382b73cb11a059e7.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/533689/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/533696", "body": "Already fixed. Added test in 04bc364610469954711349c7c6e67881a5487868\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/533696/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/533701", "body": "Fixed in 51de89f8b026b38ff8edb9e68fdbbf08b499a61d\nDots tested in b75cea580a6a283ab162d734831948eaa96ee7ab\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/533701/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/533704", "body": "please supply tests and i'll take these patches.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/533704/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/533712", "body": "thanks. applied in cae8a96c1639f8a1e6335c46b48721b3e76578c8\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/533712/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/533713", "body": "this has been fixed already in 24be793f64c82b4c8d38c2d048c43ec78c82e5d8\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/533713/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/533714", "body": "closing.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/533714/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/533715", "body": "closing\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/533715/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/533721", "body": "Thank you. Applied in 84578ae7a883a799c454f0e176782d01c801e61e.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/533721/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/533728", "body": "Fixed in 51de89f8b026b38ff8edb9e68fdbbf08b499a61d\n\nDollar sign in header field tested in 03970a576da4fc921d164be35e0a27b5fbdb1cc5\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/533728/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/533730", "body": "duplicated of Issue #16. already fixed.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/533730/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/558199", "body": "thanks. landed in d56a0700d0d9ccad427995e3da88856a96d2a455 and f825b52b7f2d4bf86c3300ae33ceb3dd1fa64571.\n\npulled into node in d695486185257533f3ef591654d2ce69dfeff74f\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/558199/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/558201", "body": "and complete in ry/node/master@1255438\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/558201/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1142085", "body": "LGTM. thanks!\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1142085/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1213404", "body": "@pgriess there's already a HTTP_STRICT preprocessor symbol. I'd be for rejecting UTF8 paths based on that.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1213404/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1230300", "body": "landed in fb23d15ace64c102813d8a84546284598c5d1848. thanks\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1230300/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1297718", "body": "yes - test cases failing. sorry for delay\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1297718/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1301420", "body": "I like @clifffrey's (2) suggestion\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1301420/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1396485", "body": "awesome +1\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1396485/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1587870", "body": "Update the readme - otherwise LGTM!\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1587870/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1993720", "body": "http-parser compiles on MSVS already so I'm not sure why we need these fixes.\n\nhttp-parser doesn't have anything to do with Ruby. Including `ruby/config.h` it is not allowed.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1993720/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1994681", "body": "i just tried it - seemed to work... have you generated your MSVS project with the included .gyp file?\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1994681/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/2042429", "body": "this should be done for strict mode only since IIS 6.0 does not follow the RFC\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/2042429/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/2229397", "body": "We require contributors to sign a CLA: https://github.com/joyent/http-parser/blob/c0ecab0516147401b5fd02a2272ebfb5dce8deb4/CONTRIBUTIONS\n\nPatch looks fine to me. Any interest in porting test.c over?\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/2229397/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/2230041", "body": "@clifffrey are you going to notice the +4 bytes on the parser?\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/2230041/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/2230469", "body": "Keep the bitfields then.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/2230469/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3378725", "body": "Hey @koichik great work. LGTM except we stupidly set this up have a separate CLA from node: please sign here https://raw.github.com/joyent/http-parser/2498961231853311675d6e3bcf4f5c988b15ed4e/CONTRIBUTIONS and then i'll land\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3378725/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3934182", "body": "lgtm. this changes binary compatibility - but for Node I don't consider http_parser.h to be public - so it could be landed in v0.6 if desired.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3934182/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}], "commit_comments": [{"url": "https://api.github.com/repos/nodejs/http-parser/comments/26139", "body": "There is no reason phrase callback.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/comments/26139/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/comments/26181", "body": "Currently there is no way. The status code can is set in the parser structure.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/comments/26181/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/comments/35949", "body": "no, unfortunately not. \n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/comments/35949/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/comments/36277", "body": "no\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/comments/36277/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/comments/37595", "body": "CONNECT too. thanks\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/comments/37595/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/comments/116267", "body": "cliff suggests the name 'lowcase' should change. i agree. can't think of anything appropriate right now though.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/comments/116267/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/comments/121239", "body": "Sorry - it got lost in my inbox.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/comments/121239/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/comments/131419", "body": "nread is just for the header\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/comments/131419/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}], "review_comments": [{"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/374793", "body": "why unsigned? just to save a bit?\n\nforgive my ignorance but what is `(uint64_t) -1` ?\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/374793/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/374913", "body": "can you use `ULLONG_MAX` instead?\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/374913/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/374969", "body": "that's fine - i just want it for clarity\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/374969/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}]}, "felixge": {"issues": [], "commits": [{"url": "https://api.github.com/repos/nodejs/http-parser/commits/2498961231853311675d6e3bcf4f5c988b15ed4e", "message": "Accept HTTP/0.9 responses\n\nSee joyent/node#1711"}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "pquerna": {"issues": [], "commits": [{"url": "https://api.github.com/repos/nodejs/http-parser/commits/f1d48aa31c932f80a64122a75a87bc909b4073f9", "message": "Move all data to before code to fix http parser for c89."}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "clifffrey": {"issues": [], "commits": [{"url": "https://api.github.com/repos/nodejs/http-parser/commits/c0ecab0516147401b5fd02a2272ebfb5dce8deb4", "message": "Merge pull request #61 from bnoordhuis/master\n\nSingle-bit bitfield 'upgrade' should be unsigned."}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/5bb958a9f4750e4f731b8c4a7900c5b5d7fbd9be", "message": "Merge pull request #48 from kolbyjack/master\n\nAllow uppercase chars in IS_ALPHANUM"}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/d34a2ad26c279e3a6fbdaf57a6a828635a7f76a3", "message": "Merge pull request #45 from scunningham/tracking\n\n  Support multi-line folding in header values."}], "pull_requests": [], "issue_comments": [{"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1297771", "body": "I don't really like adding the extra argument to http_parser_execute.  My gut feeling says to do one of three things instead:\n1. Just add a uint8_t field to the http_parser struct that contains the errno.  I would drop the line number I think.\n2. Use the \"state\" field.  Just have the error numbers go from 128 and up or something.  You could add a function http_parser_get_errno that would return 0 if state is < 128, and return state - 128 otherwise.\n\nThe downside of (2) is that it makes the error non-recoverable, but I am having trouble imagining a use-case for recoverable errors.\n\nI think that this is awesome data to add, that will be very useful for logging of errors.  I don't really like the line number because that is not what we want to maintain/reveal.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1297771/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1298094", "body": "I definitely think that 62b68e75 is a real candidate to be merged.  Could you submit a new pull request with just that change?  Could the commit message refer to HTTP protocol description of the desired behavior?  Also, you seem to have some trailing whitespace in lines that you added, and it would be great to avoid that.\n\nFor the CRLF compliance change, I'd like to hear more about what you need it for.  Are you trying to recognise requests that nginx will reject and notice them yourself?\n\nI'm closing this request for now, but if you submit these separately, then I think that we can definitely merge in 62b68e75, and maybe the other one.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1298094/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1299529", "body": "Thanks for finding this issue!  I checked in a different fix in 3258e4a.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1299529/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1299553", "body": "I'm closing this, as the votes seem to be for https://github.com/ry/http-parser/pull/40 instead of this patch.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1299553/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1300365", "body": "I just merged this.  Thank you for the awesome change!\n\nOn Fri, Jun 3, 2011 at 4:32 PM, scunningham <\nreply@reply.github.com>wrote:\n\n> Normal value cb is called for subsequent lines.  LWS is skipped.\n>  Note that \\t whitespace character is now supported after header field\n> name.\n> \n>  RFC 2616, Section 2.2\n>  \"HTTP/1.1 header field values can be folded onto multiple lines if the\n>   continuation line begins with a space or horizontal tab. All linear\n>   white space, including folding, has the same semantics as SP. A\n>   recipient MAY replace any linear white space with a single SP before\n>   interpreting the field value or forwarding the message downstream.\"\n> \n> ## \n> \n> Reply to this email directly or view it on GitHub:\n> https://github.com/ry/http-parser/pull/45\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1300365/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1394242", "body": "The change looks good to me.\nIt would be cool to change test_simple to specifically take the error code that we expect to be returned, but the change is worth checking in even without that.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1394242/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1591625", "body": "I like this change, as it has always been weird to me that there are many different overlapping callbacks.\n\nI wonder if some of these concerns could be addressed if we added a function that parsed a uri into path/query/fragment parts?  I think it could be reasonable to add a function like that, but I don't feel super strongly that we need it.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1591625/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1821981", "body": "The general idea of this seems reasonable to me, but I'd love to hear from anyone else who would find this functionality useful.\n\nIf it were to actually be merged, I'd want to see updates to test.c as well.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1821981/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/2041611", "body": "Given that the test.c change was added by Ryan in one commit by itself\nSHA: 120f0f6e09773dbe003841b5b339f9284dd63aad\nI think that we need to get Ryan to agree with this.\n\nIt looks good to me though\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/2041611/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/2229939", "body": "My main use of http_parser is quite size sensitive, so I'm not excited about the bitfields part of the change, as it makes the parser structure considerably larger.  The other parts of the change seem reasonable to me.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/2229939/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/2230159", "body": "I'm trying to track both directions of every TCP connection going through an access point that has 32MB of RAM, so every byte helps.  I'm not saying that I have any firm lines (specifically 4 bytes doesn't push us over some critical threshold), but we are very aware of how much RAM we have.  I can also maintain our own version that uses bitfields.. but would rather not, and this is why I'm pushing somewhat.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/2230159/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3397939", "body": "This looks good to me\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3397939/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4204365", "body": "Couldn't we store the pause state somewhere explicitly?  It would be more\nwork to code up, but if we had different parser states for these things,\neven though they were at the same byte offset, then the parser could know\nwhich callbacks have been run already.\n\nI think that pause _needs_ to be absolute, it would be very surprising to a\nnew user of the API to see a callback called _after_ the stream was paused.\n\nOn Mon, Feb 27, 2012 at 11:50 AM, Peter Griess <\nreply@reply.github.com\n\n> wrote:\n> \n> _Is node (or any other library) relying on http-parser not executing\n> on_message_complete after pausing from inside on_headers_complete?_\n> \n> Not that I know of. AFAIK there are very few users of\n> `http_parser_pause()`.\n> \n> _If not, I think the easiest 'fix' would be to implement pause as \"don't\n> consume any more bytes (but call whatever callbacks are necessary)\" instead\n> of \"stop doing anything\"._\n> \n> Yeah, that's certainly an option.\n> \n> I do think it's worth spending some amount of effort to get the API to\n> work with the more rigid semantics, though, as this provides a more\n> powerful API. I'll spend some on that this weekend and see how far I get.\n> \n> ---\n> \n> Reply to this email directly or view it on GitHub:\n> https://github.com/joyent/http-parser/issues/97#issuecomment-4201469\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4204365/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4232065", "body": "I feel like I'm missing something.. why is it that \"... empty requests\nabsolutely need to call both callbacks before marking the last byte as\nconsumed\"?  Couldn't they consume the last byte, but leave the parser in a\nstate of s_paused_before_message_complete, and have that state just call\nthe callback and then do \"goto reexecute_byte;\"?  I'm probably missing\nsomething though, so please forgive me if this idea can't work.\n\nOn Tue, Feb 28, 2012 at 9:21 PM, Andr Caron <\nreply@reply.github.com\n\n> wrote:\n> \n> I looked at [bnoordhuis's new test case](https://github.com/joyent/http-parser/issues/97#issuecomment-4193300) and\n> it prevents pausing in `on_headers_complete` from invoking\n> `on_message_complete`.  I don' t think this can ever be satisfied if we fix\n> this issue since empty requests absolutely need to call both callbacks\n> before marking the last byte as consumed.\n> \n> I pushed a sample fix that just addresses the specific case of letting\n> `on_message_complete` be called when the parser is paused from\n> `on_headers_complete`.  It breaks current tests for pausing, which validate\n> that absolutely no more callbacks should be called after a pause.  All\n> other tests still pass, but don't use this since I think this is somewhat\n> of a hack, and I'm not sure what the behavior is for pausing in other\n> callbacks (e.g. `on_url()`).\n> \n> > I think everyone agrees that it should be fixed on our side, the\n> > question is how?\n> \n> First, we need to define the semantics of pausing.  Should pausing be\n> allowed all callbacks, or should it be limited to specific cases?  AFAICT,\n> the only interesting places to call this are in `on_headers_complete` for\n> proxying purposes and in `on_message_complete` for HTTP/1.1 pipelined\n> requests.\n> \n> Also, in what (other) cases is this a problem?  So far, the only\n> problematic instance is for `on_headers_complete()`, which must potentially\n> call `on_message_complete` when the request has no body.\n> \n> ---\n> \n> Reply to this email directly or view it on GitHub:\n> https://github.com/joyent/http-parser/issues/97#issuecomment-4231984\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4232065/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}], "commit_comments": [], "review_comments": []}, "fmardini": {"issues": [], "commits": [{"url": "https://api.github.com/repos/nodejs/http-parser/commits/2b2ba2da1adeab4c8ea4d4e8d6f5605ab3ca0b1a", "message": "rename parser->errno to parser->http_errno; conflicts with errno.h where errno is defined as a macro"}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "scunningham": {"issues": [], "commits": [{"url": "https://api.github.com/repos/nodejs/http-parser/commits/b89f94414e0bd79dab212480895cd42f5e427755", "message": "  Support multi-line folding in header values.\n\n  Normal value cb is called for subsequent lines.  LWS is skipped.\n  Note that \\t whitespace character is now supported after header field name.\n\n  RFC 2616, Section 2.2\n  \"HTTP/1.1 header field values can be folded onto multiple lines if the\n   continuation line begins with a space or horizontal tab. All linear\n   white space, including folding, has the same semantics as SP. A\n   recipient MAY replace any linear white space with a single SP before\n   interpreting the field value or forwarding the message downstream.\""}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/10270007bce671f28a29ac1aa6e5a99a5192de6d", "message": "Avoid chunk header parsing overflow.\n\nRecharacterize the chunk header states such that they are bound by the check\nfor HTTP_MAX_HEADER_SIZE."}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/81ca70aec1af3474e2b0b59d0bd196a153295b51", "message": "Avoid chunk trailer overflow.\n\nCheck for overflow during chunk trailer by removing unnecessary check in macro PARSING_HEADER.  This will force the parser to abort if the chunk trailer contains more than HTTP_MAX_HEADER_SIZE of data."}], "pull_requests": [], "issue_comments": [{"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/761386", "body": "On second look, any non-zero return from a callback function, excluding special behavior of 'on_headers_complete', will return offset-1.  This is correct behavior, as the state has not changed yet, and the parser needs to resume from the point.\n\nTo get the parser to interrupt on EOM, need to return non-zero from on_message_begin after the first callback on a stream.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/761386/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/763793", "body": "Follow up on this.\n\nWhile the parser does not abort with an error on content_length overflow, it does not crash or cause security problems either.  Instead, the parser treats it as a bad content_length, although slightly differently for the two cases:\n\n<b>1) overflow on content length in state h_content_length</b>\n\nHere, when the header processing completes, the parser checks for a zero and a positive content_length:\n\n<pre><code>\n          if (parser->content_length == 0) {\n            /* Content-Length header given but zero: Content-Length: 0\\r\\n */\n            CALLBACK2(message_complete);\n            state = NEW_MESSAGE();\n          } else if (parser->content_length > 0) {\n            /* Content-Length header given and non-zero */\n            state = s_body_identity;\n          } else {\n            if (parser->type == HTTP_REQUEST || http_should_keep_alive(parser)) {\n              /* Assume content-length 0 - read the next */\n              CALLBACK2(message_complete);\n              state = NEW_MESSAGE();\n            } else {\n              /* Read body until EOF */\n              state = s_body_identity_eof;\n            }\n          }\n</code></pre>\n\n\nIn the case where the content_length < 0, the parser will either go into NEW_MESSAGE() state or read until EOF.  For the former, the parser will likely abort shortly as it tries to read the next byte(s) on the stream.  For the latter, content_length is simply ignored until EOF which would be problematic if we actually got > LLONG_MAX bytes of data, which is unlikely.\n\n<b>2) overflow on content_length in state h_content_length</b>\n\nIn this case, the error is indirectly handled in the following state, s_chunk_data\n\n<pre><code>\n      case s_chunk_data:\n      {\n        assert(parser->flags & F_CHUNKED);\n\n        to_read = MIN(pe - p, (int64_t)(parser->content_length));\n\n        if (to_read > 0) {\n          if (settings->on_body) settings->on_body(parser, p, to_read);\n          p += to_read - 1;\n        }\n\n        if (to_read == parser->content_length) {\n          state = s_chunk_data_almost_done;\n        }\n\n        parser->content_length -= to_read;\n        break;\n      }\n</code></pre>\n\n\nHere the MIN macro leaves us with a negative 'to_read' value, which is ignored in the if stmt, but then causes the state to switch to 's_chunk_data_almost_done' and content_length reset to zero.  So here, the data in the chunk is completely unprocessed, and we are likly to error out with STRICT_CHECK enabled as parsing continues.\n\nSo in summary, it is not strictly necessary to change the code to check whether content_length overflows, but it would not hurt to be more explict about this edge case.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/763793/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/822055", "body": "Fix pushed.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/822055/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/822057", "body": "Fix pushed.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/822057/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3599436", "body": "Seems better.  The value can still overflow though; I'd have to dig\nthrough the code and see if that opens any attack surfaces. From a\nquick glance, doesn't appear to be any different than the client lying\nabout the content-length, but I haven't studied it deeply.  Parser\ndefinitely won't handle it correctly, but requests this large are so\nhuge as to be ridiculous (of course we said the same thing in the 90's\nabout those impossibly huge chunks called Gigabytes).\n\nIf it were me, I'd check explicitly and fail when a message comes\nthrough that is logically too large to be handled correctly by the\nparser, whether the parser moves content_length to uint64_t or not.\n\nThanks,\nSean\n\nOn Sat, Jan 21, 2012 at 5:06 PM, Ben Noordhuis\nreply@reply.github.com\nwrote:\n\n> bnoordhuis/http-parser@6185bcb does exactly that.\n> \n> ---\n> \n> Reply to this email directly or view it on GitHub:\n> https://github.com/joyent/http-parser/pull/76#issuecomment-3599344\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3599436/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3892956", "body": "Wow, I see a lot of changes in the past 9 months:\n- Significant API changes  (API CHANGE: Remove path, query, fragment CBs. )\n- New error handling facility.\n- Parser pause capability.\n- Tons of bug fixes and security improvements.\n\nThe API change alone typically warrants a new major version number.\n(Well, at least according to the folks over at http://semver.org/).\nBut my question was more around if there was a plan to hit a certain\nmilestone and tag that, or just continue to do incremental dev?  If\nthe latter, I believe there is value in tagging with a new version\nnumber at shorter milestones.  It implies that the code has stabilized\nand has been vetted, and is appropriate for inclusion in another\nproject.  As a user of a third party library, I much prefer to wait\nfor a stable tag to pick up the latest version rather than the tip.\nOne is never quite sure what state the tip of the develop tree is in\nunless paying very close attention.\n\nThanks,\nSean\n\nOn Thu, Feb 9, 2012 at 10:31 AM, Ben Noordhuis\nreply@reply.github.com\nwrote:\n\n> I suppose I could tag it v1.1 or v2.0 but what does it mean? There's been steady on-going development. I don't know of a key commit that would warrant a version bump.\n> \n> ---\n> \n> Reply to this email directly or view it on GitHub:\n> https://github.com/joyent/http-parser/issues/85#issuecomment-3889212\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3892956/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4257751", "body": "Hey Ben,\n\nHere's your reminder.  Lots of activity on the project: clearing\nissues out for a tag?\n\nThanks,\nSean\n\nOn Thu, Feb 9, 2012 at 4:57 PM, Ben Noordhuis\nreply@reply.github.com\nwrote:\n\n> Fair point about the API changes. I'll tag v2.0 in a week or two, remind me if I forget.\n> \n> For now, use 2498961 if you want a newer-but-stable commit to work with, it's what node.js ships with.\n> \n> ---\n> \n> Reply to this email directly or view it on GitHub:\n> https://github.com/joyent/http-parser/issues/85#issuecomment-3896554\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4257751/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}], "commit_comments": [], "review_comments": []}, "a2800276": {"issues": [], "commits": [{"url": "https://api.github.com/repos/nodejs/http-parser/commits/9656fd73de16585164bf14a67dc006aff2c7d80a", "message": "moved unecessary lookup"}], "pull_requests": [], "issue_comments": [{"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/484464", "body": "D'oh! I should really think before I click...\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/484464/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}], "commit_comments": [], "review_comments": []}, "tmm1": {"issues": [], "commits": [{"url": "https://api.github.com/repos/nodejs/http-parser/commits/cae8a96c1639f8a1e6335c46b48721b3e76578c8", "message": "Fix build issues using mingw32 on windows"}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "ewencp": {"issues": [], "commits": [{"url": "https://api.github.com/repos/nodejs/http-parser/commits/24be793f64c82b4c8d38c2d048c43ec78c82e5d8", "message": "Provide typedefs instead of using stdint.h on Windows."}, {"url": "https://api.github.com/repos/nodejs/http-parser/commits/4afe80a44e33efe7d424e16d3a54cbb759ddf7e9", "message": "Add definitions and typedefs to support compilation in Visual Studio under C++ mode."}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "jterrace": {"issues": [], "commits": [{"url": "https://api.github.com/repos/nodejs/http-parser/commits/d0dfc987732a25ee1f2236526e2801f06678cda4", "message": "Initialize method member to avoid falsely upgrading connections. Fixed Issue #7"}], "pull_requests": [], "issue_comments": [{"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/335092", "body": "Fixed in d0dfc987732a25ee1f2236526e2801f06678cda4\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/335092/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}], "commit_comments": [{"url": "https://api.github.com/repos/nodejs/http-parser/comments/131402", "body": "Why did you change nread back to 32-bit? Isn't it possible for a response to be > 4GB? I realize it's rare, but still possible?\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/comments/131402/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}], "review_comments": []}, "syngenio": {"issues": [], "commits": [{"url": "https://api.github.com/repos/nodejs/http-parser/commits/8c3101cbe2b1794d8744026b7dc2cfdb428329ef", "message": "redundant upgrade flag check"}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "sgala": {"issues": [], "commits": [{"url": "https://api.github.com/repos/nodejs/http-parser/commits/0264a0aefcd119e179a3bc730ac517efbbccd4bb", "message": "Upgrade on CONNECT method"}], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": []}, "DCjanus": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/nodejs/http-parser/pulls/388", "title": "fix typo", "body": "from 'futher' to 'further'\r\n\r\n-----------------\r\n\r\nI'm not a native English speaker, maybe there is a word 'futher', but I can't find it by Google.\r\nIf I'm Wrong, forget me\r\n\r\n", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "nibaozhu": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/nodejs/http-parser/pulls/379", "title": "install `package'", "body": "", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "simsong": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/nodejs/http-parser/pulls/378", "title": "add .deps and .dirstamp to .gitignore", "body": "I use http-parser in another project as a submodule. When I run autotools configure, it creates in the http-parser sub directory a directory and a file:\r\n\r\n```\r\n[user@localhost http-parser]$ git status\r\nHEAD detached from 8d9e5db\r\nUntracked files:\r\n  (use \"git add <file>...\" to include in what will be committed)\r\n\r\n\t.deps/\r\n\t.dirstamp\r\n\r\nnothing added to commit but untracked files present (use \"git add\" to track)\r\n[user@localhost http-parser]$\r\n```\r\n\r\nIt would be super-nice to have `git status` **not** warn me about these two files generated by autotools.", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "izaid": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/nodejs/http-parser/pulls/377", "title": "[WIP] CMake Support", "body": "CMake support has been requested a few times, and there has been at least one PR about it. This is a new attempt at it -- I think it is relatively simple. Happy to build it out more if that is what is needed.", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "flandr": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/nodejs/http-parser/pulls/374", "title": "Add basic CMake support", "body": "Only supports building the main library target (static and dynamic).\r\n\r\nRefs #257", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "alperakcan": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/nodejs/http-parser/pulls/369", "title": "ignore headers transfer_encoding_chunked and content_length to work with http assemblers.", "body": "added ignore_header_transfer_encodig_chunked and ignore_header_content_length to settings.\r\n\r\nignore_header_content_length:\r\n  useful if body length and content length does not match. happens with owa servers. or working with pre http assemblers that unzips compressed content without changing content-length.\r\n\r\nignore_header_transfer_encodig_chunked:\r\n  useful when working with pre-http assemblers which assembles chunked content into one http packet without changing transfer-encoding field.\r\n\r\nmay be useful for someone.", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "kunalspathak": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/nodejs/http-parser/pulls/352", "title": "http header parsing", "body": "http_parser along with other http request information supplies header\r\nfields to the consumer. In `node` case, it creates a new `JSString`\r\nof these header fields which involves memory allocation. If parser\r\nkeeps track of headers while parsing and return a unique id to `node`\r\nthat help distinguish the known header name, `node` don't have to\r\nallocate for known headers and it can use the pre-created `JSString`\r\nfor the header fields. See discussion in https://github.com/nodejs/node/issues/10930\r\n\r\nThe approach I have taken is while scanning the request, keep track\r\nof known headers and update the `header_state` accordingly. `node` or\r\nany consumer can consume the `header_state` information and decide\r\nto use cached http header field instead of creating new string. I try to\r\nmatch traditional cases http header. e.g. In Content-Type 'C' and 'T' has\r\nto be upper case for the header to qualify for traditional cased header.\r\nI use `traditional_case_http_headers` to track this information.\r\n\r\nPerformance is flat for node's http benchmark except bench-parse where\r\nsometimes I noticed 5% regression. I am not sure if it was due to noise.", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": [{"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/102633430", "body": "Ok, will change it back. But curious, you didn't like the name of macro or you feel macro is too much for this statement?", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/102633430/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/102634579", "body": "Changed it.", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/102634579/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/102634938", "body": "`sizeof(string) - 2` means that we have just read the last character (and that matched the expected character from `string[parser->index] == c` inside if above). So we are good to save the `header_state`. This is how headers are [matched today](https://github.com/nodejs/http-parser/blob/master/http_parser.c#L1368) and I used same logic to match other headers.", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/102634938/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}]}, "akatrevorjay": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/nodejs/http-parser/pulls/351", "title": "Cython bindings -- Interested?", "body": "Hi, a long time ago I wrote Cython bindings for this. If I clean it up are you interested in merging?\r\n\r\n(notably the build process and add some docs)\r\n\r\nTy,\r\nTrevor", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "roman-neuhauser": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/nodejs/http-parser/pulls/348", "title": "Unbreak `make install` in BSDs", "body": "I've only tested this in freebsd-12.0 where the changes get me from syntax errors in the Makefile to passing `port test` with flying colors.", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "shindo": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/nodejs/http-parser/pulls/347", "title": "parser: fix handling of newlines before HTTP responses", "body": "This diff fixes ignoring of CR and LF chars received before HTTP response's start line the same way as they are handled with HTTP_REQUEST and HTTP_BOTH parser types.", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "AdamMajer": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/nodejs/http-parser/pulls/346", "title": "makefile: Flexible install fixes", "body": "Fixing three Makefile related things,\r\n\r\n1. LIBDIR should be configurable. INCLUDEDIR as well\r\n2. fix SONAME so it represents actual ABI compatibility\r\n3. symlinks should not have absolute paths\r\n", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "shekhei": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/nodejs/http-parser/pulls/342", "title": "Various optimizations", "body": "Hi, basically I was just messing around and did some benchmarking, found some interesting things, so I made some changes. Mostly to do with removing some of the branches and created a SIMD version of finding CRLF that doesn't need to walk the whole payload twice(worst case)\n\nBelow are the benchmark results\n### OSX (el capitan, mbp 13\" early 2015, 3.1 GHz Intel Core i7)\n#### Clang\n\n| time(master) | req/s(master) | time(new) | req/s(new) | percent |\n| --- | --- | --- | --- | --- |\n| 5.761632 | 867809.687500 | 5.104409 | 979545.312500 | 11.4069 |\n| 5.769115 | 866684.062500 | 5.104001 | 979623.625000 | 11.5289 |\n| 5.803461 | 861554.875000 | 5.086198 | 983052.625000 | 12.3592 |\n| 5.779534 | 865121.687500 | 5.082990 | 983672.937500 | 12.0519 |\n| 5.762670 | 867653.375000 | 5.092542 | 981827.875000 | 11.6288 |\n#### GCC 4.9\n\n| time(master) | req/s(master) | time(new) | req/s(new) | percent |\n| --- | --- | --- | --- | --- |\n| 4.297466 | 1163476.375000 | 3.787979 | 1319965.000000 | 11.8555 |\n| 4.159397 | 1202097.250000 | 3.774015 | 1324849.000000 | 9.26533 |\n| 4.230322 | 1181943.125000 | 3.788900 | 1319644.250000 | 10.4347 |\n| 4.214539 | 1186369.375000 | 3.772407 | 1325413.750000 | 10.4906 |\n| 4.162938 | 1201074.750000 | 3.763118 | 1328685.375000 | 9.6042 |\n### ubuntu 14.04 ( Intel Core i7-6700 @ 3.40GHz )\n\n| time(master) | req/s(master) | time(new) | req/s(new) | percent |\n| --- | --- | --- | --- | --- |\n| 3.186016 | 1569358.000000 | 2.815905 | 1775628.000000 | 11.6167 |\n| 3.186449 | 1569144.875000 | 2.846761 | 1756382.125000 | 10.6604 |\n| 3.190864 | 1566973.625000 | 2.877822 | 1737425.125000 | 9.81057 |\n| 3.183230 | 1570731.625000 | 2.813425 | 1777193.250000 | 11.6173 |\n| 3.190520 | 1567142.625000 | 2.849443 | 1754728.875000 | 10.6903 |\n", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": [{"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/93997407", "body": "parens in terms of removing this parens?\r\n```\r\nresult = _mm_movemask_epi8(v2) << 16 | result\r\n```", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/93997407/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/93997908", "body": "hmm... wrapping it around with a while loop while keeping the break is rather tricky, any good tricks for this?", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/93997908/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/93999821", "body": "is it ok to use a if (1) { } else instead?", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/93999821/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/94000231", "body": "Using if(1) {} else instead because of the break within this macro", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/94000231/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/94000249", "body": "This is within 80col", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/94000249/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/139313159", "body": "Thanks for the comments! i made most of the changes and tested, they are all working, as for the inline function, I am not quite sure if that works on every platform's compiler's c dialect though", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/139313159/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/139377230", "body": "nope, I have yet to push the change, will be doing that tonight( asia time, working hours :P )\r\n\r\nOh what I kinda worry about is that whether the other compilable platforms has the dialect turned on, cause this is my first contribution I am not quite sure, if you are sure about it, let me make that change too!", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/139377230/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/139377800", "body": "Or perhaps anybody else who might be able to shed a light on whether this is safe to use, or should I write a macro instead?", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/139377800/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/139578814", "body": "Yup, I just did some test and compiled them last night too, most of them seem to inline it automatically anyways.", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/139578814/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/140632921", "body": "done", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/140632921/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/140632933", "body": "done, i hope this is what you guys are looking for :P", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/140632933/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/140647191", "body": "Actually unless there are some safety or memory concerns, then no, the logic is as such\r\n\r\n## case1\r\ndata: \\r\\nGET /\\r\\n\\r\\n\r\np: data+2\r\nlen: 9\r\nand imagine if alignment is off by 1\r\n\r\n* get alignment offset\r\n* p -= 1, which is data+1\r\n* checks next 32 bytes\r\n* result will be that looks something like 1000 0011 1100 1010 1010 1010 1010 1010(it should be right to left, i wrote it left to write)\r\n** anything beyond the 10th bit is for some data that's beyond the range\r\n* shift right and left by alignment offset, so it will end up being 0000 0011 1100 1010 1010 1010 1010 1010\r\n* and so the first bit found would be the first \\r from data+2\r\n\r\n## case2\r\n\r\ndata: \\r\\nGET /\\r\\n\\r\\n\r\np: data+2\r\nlen: 4\r\nand imagine if alignment is off by 1\r\n\r\n* exactly the same as before\r\n* but the position of the first found \\r after removing alignment false positives will be beyond \"lastp\"\r\n** lastp is either data+len or max header size + p\r\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/140647191/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/140647229", "body": "ah yes, fixed", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/140647229/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/140793492", "body": "It was modified to this to allow overridable defines, as requested by @mscdex earlier", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/140793492/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/140796426", "body": "Hmm... any recommendations on how would you prefer this to be done for the alignment part? The alignment is ensured in find_crlf and it is done just once before the loop. Should I document it or write it in some comments or do you prefer if I move the alignment code in here? I guess that would incur some unnecessary alignment operations though", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/140796426/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/140797265", "body": "ah, then I should include the #if inside and #define again inside the #ifndef, cool", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/140797265/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/140815581", "body": "Ah, yes it does, this pr's been so long, i think i've lost myself somewhere. Let me get that fixed, it should be changed to matching one by one till aligned and then matching remaining one by one", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/140815581/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/140823760", "body": "Made a change to the logic\r\n```\r\nwhile misaligned and not last char\r\n  checks char one by one\r\n  returns if found\r\nif remaining is less than 32:\r\n  while not last char\r\n    checks char one by one\r\n    return if found\r\n  return not found\r\nSIMD match till there are at least 32 left, return if found\r\nif not found and not ended yet\r\n  find char one by one and return if found\r\nreturn if not found\r\n```\r\nthis change will also ensure that we will not be offsetting the pointer to a possibly bogus address, nor will we read beyond the input anymore.\r\n  ", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/140823760/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/141341410", "body": "I have changed the current version to looping unaligned bytes and anything less than 32 one by one, maybe you guys can also review the new commit instead? anyways _mm_lddqu_si128 is unfortunately sse3, right now i think we are just using sse2 for baseline", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/141341410/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/141343105", "body": "@zbjornson I did try it out and loaded the sse3 headers, such a trivial change actually gave me a consistent 4% improvement. Unfortunately I think we might be rather out of luck though.", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/141343105/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/141396448", "body": "@mscdex I am not sure what is the \"baseline\" for the supported architectures, I decided to try making use of sse2 instruction sets only because v8 requires sse2, so I suppose that was the baseline, if we are actually cool with supporting higher versions of vector instructions then great, I will change it immediately! :)", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/141396448/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/141410568", "body": "@zbjornson I was rather surprised too, such a simple operation. Actually with what I have modified, so we dont end up reading out of bounds, is basically the same as how memchr is implemented with sse2, but i guess its good enough.\r\n\r\nI actually tried a avx2 version, with ymm registers and the performance improvements wasnt great, rather surprising. I tested it on a mid 2014 mbp 15\" with haswell family i7, maybe things gets faster on the newer ones, not too sure.", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/141410568/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/141411312", "body": "@zbjornson by the way I think headers can get rather large, think about cookies, i read somewhere typical http headers are between 200bytes to 2kb nowadays.\r\n\r\nleft out the last part :P, it is on average about 700 to 800 bytes, not sure if this is accurate, but looking at the http request header for google.com, i think that is quite possible", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/141411312/reactions", "total_count": 1, "+1": 1, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/141500805", "body": "so do you mean that we create another header file or do you just mean moving it to http_parser.h?\r\n\r\nOr could we perhaps have a non-static function that is conditionally included based on some flags that calls this static function? if not this kinda gets exposed unnecessarily.", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/141500805/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/141506500", "body": "ok, got it, let me do that in a while.", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/141506500/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/141780690", "body": "@zbjornson yup the branches is a huge bottleneck, the function is just so large.\r\n\r\nSome of the stuff I've added that shaved off about 5%(not the SIMD part) was actually reverse engineered from clang's compiled version, and then converted back to c, gcc(i didnt look at the asm from the latest gcc though, was using gcc6 i think) seems to be rather weak when it comes to optimizing certain branches.\r\n\r\nBut definitely did a much better job at optimizing the large function as a whole compared to clang(cant remember the version either)\r\n\r\nI actually wrote one more version, just to test it out using PCMPESTRI, it was significantly slower, god knows why :P\r\n\r\nmaybe it only improves if we have a lot of tokens we want to match.", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/141780690/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/145695733", "body": "nothing significant, just a badly done copy and paste :P", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/145695733/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/145872352", "body": "hmm... any recommendations on how this could be improved to be more legal?", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/145872352/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}]}, "jlesk": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/nodejs/http-parser/pulls/334", "title": "build: vms and os400 support", "body": "", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "bc-lee": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/nodejs/http-parser/pulls/296", "title": "Fix: suppress warning C4244 on MSVC", "body": "MSVC 2015 gives some warnings on http_parser.c with \n\n> warning C4244: '=' : conversion from 'int' to 'uint16_t', possible loss of data\n> It will supress this warning.\n", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "claudix": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/nodejs/http-parser/pulls/294", "title": "Added support for compiling on MinGW platform", "body": "Added rules to compile on MinGW platforms (Microsoft Windows environments):\n- Use 'gcc' as compiler.\n- Generate DLL file when compiling the library.\n- Disable -fPIC when compiling the library (on MinGW platforms all code is already position independent and setting this flag issues an error).\n", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "RandoMan70": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/nodejs/http-parser/pulls/285", "title": "Introduce raw data callbacks", "body": "These callbacks can be used when developing transparent HTTP traffic analysis and filtering. \nThe main goal of it is to handle transmitted data as-is, but having ability to distinguish data between headers, bodies and different requests.\n", "author_association": "NONE"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/258", "title": "Implement on_header_raw and on_body_raw callbacks", "body": "This patch adds on_header_raw and on_body_raw callbacks. \nWhen parser finish processing of new portion of data (or when it switches between header/body state) it run these callbacks, attaching exact stream data.\nThese callbacks called after usual header and body callbacks.\n\nPatch contains bug: after parsing error detected it still can call raw callback, so we need to check error status of a parser inside raw callbacks.\n\nPatch based at old revision, so we need to dig into parser logic again.\nBase revision: 959f4cb12748ea3aa2c4ec3183ff4acbf0fd222f\n", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "staticfloat": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/nodejs/http-parser/pulls/264", "title": "Make library symlinks relative", "body": "This allows distributions to be more easily relocatable, such as when bottling this library in Homebrew.\n", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "erikjohnston": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/nodejs/http-parser/pulls/243", "title": "Allow repeatable calls to 'make install'.", "body": "Currently if `make install` is invoked multiple times it fails due to it trying to recreate the `libhttp_parser.so` symlink. \n\nAdding the `-f` flag to the `ln` invocations fixes this, but will change the default http-parser used to the newly installed version if there are multiple versions installed. I _think_ this is what we want to do anyway since we are clobbering any existing `http-parser.h` during install, so not repointing the symlink would result in a mismatch between the default library and header versions.\n\nThe alternative would be to version `http-parser.h` and add a symlink for it, while trying to ensure we always update both symlinks atomically.\n", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "ThisIsMissEm": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/nodejs/http-parser/pulls/214", "title": "Added support for SOURCE", "body": "As per tweets: https://twitter.com/indutny/status/557499042243289088\n\nIt seems new handling for upgrade was added at some point, which makes the tests break. Unfortunately I don't have time to work out how to make the tests pass again.\n\nSOURCE should essentially be handled like Upgrade, I believe, and switched to data/tcp mode after parsing headers.\n\n/cc @indutny @bnoordhuis \n", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "jacquesg": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/nodejs/http-parser/pulls/184", "title": "Solaris doesn't necessarily have stdint.h, use inttypes.h", "body": "Solaris doesn't necessarily have `stdint.h`, it's more portable to use `sys/inttypes.h`.\n\nSee:\nhttp://wiki.opencsw.org/porting-faq#toc1\n", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "vincentbernat": {"issues": [], "commits": [], "pull_requests": [{"url": "https://api.github.com/repos/nodejs/http-parser/pulls/159", "title": "Add two hooks to be executed when a chunk is downloaded.", "body": "One hook is executed right before receiving a new chunk. The second\none is executed just after. parsertrace.c is updated to use those\nhooks for display.\n\nI am using this for experimentation with rendering. This is more reliable than looking at timestamps to know where chunks start and end.\n", "author_association": "NONE"}], "issue_comments": [], "commit_comments": [], "review_comments": []}, "suhoparov": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [{"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/154504", "body": "And in what sense not to call message_complete ?\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/154504/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/155150", "body": "int message_complete_cb(http_parser \\* p) {\n    puts(**FUNCTION**);\n    return 0;\n}\n\n```\nconst char * response = \n    \"HTTP/1.1 200 OK\\r\\n\"\n    \"Date: Fri, 31 Dec 1999 23:59:59 GMT\\r\\n\"\n    \"Content-Type: text/plain\\r\\n\"\n    \"Transfer-Encoding: chunked\\r\\n\"\n    \"\\r\\n\"\n    \"1a\\r\\n\"\n    \"abcdefghijklmnopqrstuvwxyz\\r\\n\"\n    \"10\\r\\n\"\n    \"1234567890abcdef\\r\\n\"\n    \"0\\r\\n\";\n```\n\nmain() ...\n    http_parser parser;\n    http_parser_init(&parser, HTTP_RESPONSE);\n\n```\nhttp_parser_settings settings;\nsettings.on_body = data_cb;\nsettings.on_message_begin = message_cb;\nsettings.on_header_field = header_field_cb;\nsettings.on_header_value = header_value_cb;\nsettings.on_headers_complete = headers_complete_cb;\nsettings.on_message_complete = message_complete_cb;\n\nhttp_parser_execute(&parser, settings, response, strlen(response));\n```\n\noutput: calls all callback unless \"message_complete_cb\".\ncode is master branch on VC++ 7.1\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/155150/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/155456", "body": "the same, message_complete_callback doesn't call\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/155456/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/156180", "body": "Sorry, yes it invalid response, with CRLF good works. No in real-life, this my design)\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/156180/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/156183", "body": "closed\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/156183/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commit_comments": [], "review_comments": []}, "jonashaag": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [{"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/221353", "body": "wtf, that was fast. Doesn't `http_parser_execute` return the number of bytes parsed?\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/221353/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/221390", "body": "hrm, I'd like to use the return values for indicating the reason why I made http-parser exit; for example after I got the request URL and figured out I want to answer with HTTP 404, it would be comfortable to simply return `404`.\n\nIf I manually break parsing, I've got a reason to and I most probably want to communicate that reason back to the code that called `http_parser_execute` so that code can decide what steps to take next.\n\nSo please add this feature. :-)\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/221390/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1143605", "body": "Could we get this pull request done soon?\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1143605/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1144988", "body": "Tried Ubuntu with an AMD 64 CPU and Arch Linux with an Intel 64.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1144988/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1148210", "body": "The problem is that Python compiles with `-fPIC` by default and there's no way to disable that. Furthermore, on Ubuntu, IIRC the Standard Library is compiled with `-fPIC` too, so it's impossible to link with non-`-fPIC` code.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1148210/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1149469", "body": "Ah yes. Makes perfect sense. Thanks for clarifying this!\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1149469/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1227005", "body": "+1\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1227005/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1587756", "body": "Needs docs. I don't want to guess how to update my apps to get back path, query and fragment notifications/markers.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1587756/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1618379", "body": "docs! where are the docs!\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1618379/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commit_comments": [], "review_comments": []}, "ptlomholt": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [{"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/244507", "body": "A sample request from http://muffin.doit.org/docs/rfc/tunneling_ssl.html:\n\nCONNECT home.netscape.com:443 HTTP/1.0\nUser-agent: Mozilla/1.1N\nProxy-authorization: basic aGVsbG86d29ybGQ=\n\nI can get a dump, but from the sample it is pretty obvious what the problem is...\n\nThe parser fails when it encounters the first period in the hostname as it assumes it is parsing the schema, not the hostname!\nI guess an easy fix would be to skip directly to _s_req_host state_ instead of _s_req_schema_ iff the request is a CONNECT...\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/244507/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commit_comments": [], "review_comments": []}, "arhrodriguez": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [{"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/350174", "body": "ok\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/350174/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commit_comments": [], "review_comments": []}, "mnot": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [{"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/451895", "body": "Just FYI, HTTPbis is discouraging the use of multi-line headers; from http://tools.ietf.org/html/draft-ietf-httpbis-p1-messaging-11#section-3.2 : \n\n   Historically, HTTP header field values could be extended over\n   multiple lines by preceding each extra line with at least one space\n   or horizontal tab character (line folding).  This specification\n   deprecates such line folding except within the message/http media\n   type (Section 10.3.1).  HTTP/1.1 senders MUST NOT produce messages\n   that include line folding (i.e., that contain any field-content that\n   matches the obs-fold rule) unless the message is intended for\n   packaging within the message/http media type.  HTTP/1.1 recipients\n   SHOULD accept line folding and replace any embedded obs-fold\n   whitespace with a single SP prior to interpreting the field value or\n   forwarding the message downstream.\n\nI.e., the parser still SHOULD be able to handle them, but the spec now admits they're not widely supported.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/451895/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/451909", "body": "This appears to be caused by this:\n          if (c < 'a' || 'z' < c) goto error;\n\nwhich rejects non-alphabetic first characters. The BNF for the field name in HTTP is 'token' which accepts a much broader range of characters (see http://tools.ietf.org/html/draft-ietf-httpbis-p1-messaging-11#section-1.2.2).\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/451909/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/519240", "body": "That message is delimited by EOF, as is \"301 no response phrase\". Both should have message_complete_on_eof = TRUE.\n\nOnce they're fixed, however, test_multiple3 falls down with \n  **\\* Parser didn't see 3 messages only 2 ***\n\nThe tests here are pretty intertwined, so I'm not sure how to address that; I'm guessing that they're written assuming that those responses (or similar ones) can be kept alive.\n\nAlso, the semantics of http_should_keep_alive are a bit out of whack, because you can't really keep alive a response that's delimited by EOF. Not sure if it's worth fixing, though, because AFAICT that case is never reached in the current code.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/519240/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/536700", "body": "32 (space), 34 (dquote), 49 (forward slash), 125 (right curly brace) are all specials / separators. \n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/536700/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1144847", "body": "I don't have a big problem with doing this in http_parser, I guess, but I'd be concerned if node's client started sending requests with non-ascii URLs; as you point out, some servers (including proxies) don't support them.\n\nTo me, making this kind of change is only making things better for people who are doing things wrong, and postponing (a bit) their realisation of that. I.e., they're going to have interop problems with servers / intermediaries that don't support this anyway, so they shouldn't be doing it -- what's the use case for supporting it?\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1144847/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1213338", "body": "Sounds reasonable. One of the things I'd really like to see out of the parser is more fine-grained information, rather than all-or-nothing failures.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1213338/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1226149", "body": "Trying to page this back in; is it just the test cases that's holding it up?\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1226149/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1226160", "body": "+1 from an HTTP angle.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1226160/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1299912", "body": "There are a couple of recoverable HTTP parsing errors; e.g., the header line without a colon (that's not a continuation), as discussed recently on-list.\n\nI agree, however, that they're pretty rare, and in the 99% case you can determine a single behaviour that's good for everyone. The exception is if someone wants to build a validator or HTTP traffic inspector using the parser; in that case you really need that deep information, and you need to be able to recover (so that one error doesn't stop inspection).\n\nHowever, this is a _very_ specialised use case (obviously) that it'd be easy to say is just out of scope.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1299912/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/2046676", "body": "ry, where'd you see that response with the space in it? \n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/2046676/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commit_comments": [], "review_comments": []}, "somemetricprefix": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [{"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/484382", "body": "The tables are indexed by a character and if this character isn't valid ascii a table with only 128 characters would lead to an undefined result. If we define the tables with a size of 256 the rest is just filled with zeros.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/484382/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commit_comments": [], "review_comments": []}, "creationix": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [{"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/521170", "body": "I also have hit a bug where the parser is being too strict. Here are some headers seen in the wild:\n\n```\nHTTP/1.1 200 OK \nDate: Tue, 28 Sep 2010 01:14:13 GMT \nServer: Apache \nCache-Control: no-cache, must-revalidate \nExpires: Mon, 26 Jul 1997 05:00:00 GMT \nSet-Cookie: PlaxoCS=1274804622353690521; path=/; domain=.plaxo.com \nVary: Accept-Encoding \n_eep-Alive: timeout=45 \n_onnection: Keep-Alive \nTransfer-Encoding: chunked \nContent-Type: text/html \nConnection: close \n```\n\nNote the headers containing an underscore.\n\nFrom the spec:\n\n> The  field-name must be composed of printable ASCII characters\n> (i.e., characters that  have  values  between  33.  and  126.,\n> decimal, except colon).  The field-body may be composed of any\n> ASCII characters, except CR or LF.\n\nhttp://tools.ietf.org/html/rfc2616.html#section-4.2\nhttp://tools.ietf.org/html/rfc822#section-3.1.2\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/521170/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commit_comments": [], "review_comments": []}, "kingst": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [{"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/536912", "body": "I have also seen hostnames with a '-' in them, which caused similar problems.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/536912/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commit_comments": [], "review_comments": []}, "caeies": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [{"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/973462", "body": "Im my case, when I have an upgrade request, I consume myself this bytes to purge the request and to be sure that the body is really where it should be ...\n\nNot sure of the sides effects of consuming the LF bytes in case it's not given (poor browser implementation).\n\nBest regards\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/973462/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1387075", "body": "Hi,\nLe 11/06/2011 18:31, pgriess a \u00e9crit :\n\n> I believe the CONNECT parsing issue was fixed by 3bd18a779e880d996fda3cf4c35ef4dc4f6a24e1.\n> \n> Let me know if this isn't working for you.\n> Yes, it looks like. I have merge your stuff in my repository, thank you.\n> But I'm not sure to understand why you are checking that we are in\n> CONNECT mode ...\n\nAnyway, thanks.\n\nCaeies.\n\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1387075/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1388266", "body": "Ok got it.\n\nThanks.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1388266/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commit_comments": [], "review_comments": []}, "shimondoodkin": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [{"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1558832", "body": "@bnoordhuis looks like you have made some changes to code but you have not opened a pull request\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1558832/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commit_comments": [], "review_comments": []}, "errzey": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [{"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1588986", "body": "Why would you remove the path/query cbs? I use these.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1588986/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1595379", "body": "There are actually many situations where your callback can be called twice. I attempted to fix this exact issue in another project which used a small stack to store information that would normally trigger 2 calls. \n\nThe issue I have with getting rid of path/query was I was hoping one day to get true schema/url callbacks (which is also why the other project was created). \n\n@pgriess yeah, I am using https://github.com/ellzey/libhtparse which actually has a few more features, but for work it's been this project until I get around to doing full regression testing.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1595379/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1595569", "body": "@pgriess I don't use it just for the uri parsing. So using two different libs for one feature seems a bit odd. Could we introduce a flag/ifdef to enable or disable these features for backwards-compatibility?\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1595569/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1595862", "body": "I think I don't really care about this change - I am probably just griping about another issue as a whole, which semi-relates to what this is attempting to fix. That issue is the fact http-parser is not a true streaming parser. If you were to send a non-blocking byte-by-byte request your callbacks get invoked many times\n\nTake the following request for example:\nGET /foo/bar HTTP/1.0\nHost: hith\n\nIf you send it byte-by-byte you end up with:\n\n/home/mthomas/libevhtp/evhtp.c[310] htp_start_cb: enter\n/home/mthomas/libevhtp/evhtp.c[1848] htp_request_new: enter\n/home/mthomas/libevhtp/evhtp.c[482] htp_path_cb: enter\n/home/mthomas/libevhtp/evhtp.c[346] htp_uri_cb: enter\n/home/mthomas/libevhtp/evhtp.c[482] htp_path_cb: enter\n/home/mthomas/libevhtp/evhtp.c[346] htp_uri_cb: enter\n/home/mthomas/libevhtp/evhtp.c[482] htp_path_cb: enter\n/home/mthomas/libevhtp/evhtp.c[346] htp_uri_cb: enter\n/home/mthomas/libevhtp/evhtp.c[482] htp_path_cb: enter\n/home/mthomas/libevhtp/evhtp.c[346] htp_uri_cb: enter\n/home/mthomas/libevhtp/evhtp.c[482] htp_path_cb: enter\n/home/mthomas/libevhtp/evhtp.c[346] htp_uri_cb: enter\n/home/mthomas/libevhtp/evhtp.c[482] htp_path_cb: enter\n/home/mthomas/libevhtp/evhtp.c[346] htp_uri_cb: enter\n/home/mthomas/libevhtp/evhtp.c[482] htp_path_cb: enter\n/home/mthomas/libevhtp/evhtp.c[346] htp_uri_cb: enter\n/home/mthomas/libevhtp/evhtp.c[346] htp_uri_cb: enter\n/home/mthomas/libevhtp/evhtp.c[482] htp_path_cb: enter\n/home/mthomas/libevhtp/evhtp.c[391] htp_header_key_cb: len = 1\n/home/mthomas/libevhtp/evhtp.c[391] htp_header_key_cb: len = 1\n/home/mthomas/libevhtp/evhtp.c[391] htp_header_key_cb: len = 1\n/home/mthomas/libevhtp/evhtp.c[391] htp_header_key_cb: len = 1\n/home/mthomas/libevhtp/evhtp.c[391] htp_header_key_cb: len = 0\n/home/mthomas/libevhtp/evhtp.c[420] htp_header_val_cb: len = 1\n/home/mthomas/libevhtp/evhtp.c[420] htp_header_val_cb: len = 1\n/home/mthomas/libevhtp/evhtp.c[420] htp_header_val_cb: len = 1\n/home/mthomas/libevhtp/evhtp.c[420] htp_header_val_cb: len = 1\n/home/mthomas/libevhtp/evhtp.c[420] htp_header_val_cb: len = 0\n\nWhile it seems like a separate issue - it is along these lines. I honestly suggest that a small stack is maintained for these types of situations (that is until the next state is reached)\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1595862/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1602242", "body": "@AndreLouisCaron I actually deal with this quite transparently with little overhead here: https://github.com/ellzey/libhtparse/blob/master/htparse.c#L256\n\nThe parser struct includes a small stack variable 1024 bytes in length, and is only used for things between two states (e.g., in a reading_header_key state but with the first pass hasn't transitioned to reading_header_val). p->buf, and p->buf_idx are the variables within that code are key. My implementation is much less complex, more hooks,and no goto insanity. Much like http-parser this has roots in based on nginx parser, but a more up-to-date and performance tweaked variant. The complexity is reduced partly on the fact it only processes http requests, not the responses. This was the only requirement for my needs.\n\nIt is quite trivial, security, and implementation wise to do this. And if requested I can take some time to make this a feature of http-parser.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1602242/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1602415", "body": "@AndreLouisCaron yeah I quickly realized I was getting off-topic a few replies ago; was just responding to the responses :). And to this, I will write some proposed patches and discuss there.\n\nOn-topic: I relooked at the patch, and I fully support getting rid of the fragment cb, it always annoyed me anyway. \n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1602415/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commit_comments": [], "review_comments": []}, "tj": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [{"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1619601", "body": "+.5 for @clifffrey's suggestion, or alternatively you could maybe have all the associated callbacks and remove url instead and stitch if needed instead of parsing if needed, doesn't really matter to me, scanning for the chars is pretty simple im not sure we would need anything else\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1619601/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commit_comments": [{"url": "https://api.github.com/repos/nodejs/http-parser/comments/487456", "body": "so it's just request_url now? I'm using the others and wouldn't mind them staying so I dont have to re-parse them in c land, but it's not a show stopper I guess, pretty simple to delimit\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/comments/487456/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/nodejs/http-parser/comments/487563", "body": "nah it's a none-node related C project, thanks I'll check it out!\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/comments/487563/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "review_comments": []}, "yhager": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [{"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1667875", "body": "Haven't reviewed the code, but this is exactly what I asked in #56, so consider this an upvote.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1667875/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commit_comments": [], "review_comments": []}, "coreyfarrell": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [{"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1677569", "body": "I like 'Stop using shadow parser state in execute().'  In addition to your end goal, this would ensure http_parser\\* is valid after all error's.  This makes it possible to handle an unsupported or custom (invalid) fragment, update parser state, and resume normal parsing after the fragment.  I haven't had a chance to review the other commits yet but wanted to comment on the first.\n\nOne issue is an underscore followed by capitol letter is reserved: http://gcc.gnu.org/onlinedocs/cpp/System_002dspecific-Predefined-Macros.html.  Maybe rename _CALLBACK_NOTIFY and _CALLBACK_DATA to CALLBACK_NOTIFY_ and CALLBACK_DATA_?\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1677569/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commit_comments": [], "review_comments": []}, "toffaletti": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [{"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1821766", "body": "For some reason I can't update this pull request to include more commits. I made 2 commits, but this is only showing 1 of them.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1821766/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1831566", "body": "I've updated the tests to include the reason string, which helped me fix a bug. I also looked back through old issues to find people who might be using http-parser in a proxy server and sent them messages asking for feedback on the change.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1831566/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commit_comments": [], "review_comments": []}, "cfis": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [{"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1993864", "body": "Hi ry,\n\nSorry on the ruby/config.h, I was actually using http-parser.rb which pulls http-parser as git module and didn't realize http-parser wasn't ruby related.  Anyway, the issue still remains there that MSVC 2010 does have stdint.h (that is new as of VC 2010) and that conflicts with the code in http_parser.h because the same types get defined twice and you end up with things like typedef int8_t int8_t which isn't allowed.  The top of that header looks like this:\n\n/\\* stdint.h standard header */\n#pragma once\n#ifndef _STDINT\n#define _STDINT\n\nSo what I should have done is add a check for defined?(_STDINT) - sorry for the mistake there.\n\nAs far as compiling, I'm suprised it works for you.  MSVC follows the C rule that you have to declare a variable at the top of a block.  Its a gcc extension to not allow that, which I believe is turned off by using the -pedantic flag.\n\nReading here:\n\nhttp://stackoverflow.com/questions/6754126/msvc-vs-gcc-variable-declaration-in-function\n\nIt looks like you can tell MSVC to compile C files as CPP files, but that could lead to other issues.\n\nSo - I'm curious how you are getting this to compile on MSVC.  Are you using that flag or some other approach?  Because by default it doesn't.\n\nThanks - Charlie\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1993864/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1996786", "body": "Hi Ry, \n\nNo - its being pulled in via http_parser.rb and then being built via nmake.  I'll try generating the MSVC project file from the .gyp file and see what it does differently.\n\nNote the stdint.h issue only comes into play if somewhere else in your code you require it...so in general you would not see it.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/1996786/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/2036171", "body": "Yup, that explains that.  So by default VC assumes a \".c\" file is c an enforces C89 rules.  /TP tells VC to compile all files as C++, which solves the variable issue.  \n\nDon't know if that introduces other isssues or not.  One thing I can think of off the top of my head is if someone includes the file in their library and builds a dll, the names will then have C++ mangling.   You can of course work around that, but is an extra thing to worry about.\n\nNote that gcc won't work either if you use the --pedantic flag.\n\nAnyway, thanks for looking at this.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/2036171/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commit_comments": [], "review_comments": []}, "entity64": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [{"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/2027584", "body": "> It looks like you can tell MSVC to compile C files as CPP files, but that could lead to other issues.\n\nThe flag you mean is /TP and using it, MSVC 2010 compiles http_parser.c without any warning or error\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/2027584/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commit_comments": [], "review_comments": []}, "vmg": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [{"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/2230229", "body": "Non-integer bit fields are not in the C99 standard. Any compiler that supports them does so through an (unofficial) extension. Now: I've got no special interest on having full standards compatibility -- after all, this is one of the few extensions that MSVC does support, so we could very well drop the commit and forget about this. On the other hand, some embedded programmers that have to resort to non-GCC compilers would surely appreciate being able to _compile_ the library at the expense of 4 extra bytes.\n\nUp to @ry.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/2230229/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3693000", "body": "@carlosmn: can you open a new PR, please? Might as well backport the new http-parser changes to libgit2.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3693000/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commit_comments": [], "review_comments": []}, "carlosmn": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [{"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/2230825", "body": "Bitfield changes dropped\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/2230825/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3696424", "body": "I thought the issues had been solved by other PRs. I'll dust off my copy of the repo\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3696424/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commit_comments": [], "review_comments": []}, "juhovh": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [{"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/2995931", "body": "Yeah, I really need IPv6 support as well in this otherwise great library. Guess I should try writing a patch myself.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/2995931/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/2996502", "body": "I noticed this was fixed in nginx version 5 days ago, I tried backporting the patch in my tree https://github.com/juhovh/http-parser. You can see if that one helps.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/2996502/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commit_comments": [], "review_comments": []}, "rrizun": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [{"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3546424", "body": "should path/query/fragment from HTTP_ERRNO_MAP also be removed?\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3546424/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3974080", "body": "yup, already did, but I'll do it again =)\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3974080/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commit_comments": [], "review_comments": []}, "gwik": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [{"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3632067", "body": "I'm not talking about HEAD requests.\nA response to a GET, POST,... can be without a body. If there is no content-length nor transfer-encoding and no connection: close headers then response has no body and the parser should consider should be done (message_complete) after the headers and should not try to read a body until EOF.\n\nhttp://tools.ietf.org/html/rfc2616#section-4.4 5.\n\nIf you think about it's pretty consistent because the client shouldn't close the connection (and the server don't expect the client to) if there is no connection: close header.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3632067/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3632442", "body": "What I suggested was in complement to that, but reading other parts of the RFC, I realize it doesn't matter. The scenario I was describing shouldn't happen if the server follows the RFC. I just need to change my test cases.\n\nSorry to have bothered you about it and thank you for this great parser.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3632442/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commit_comments": [], "review_comments": []}, "udp": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [{"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3669272", "body": "Doh. Never mind!  ;-)\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3669272/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}], "commit_comments": [], "review_comments": []}, "novln": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [{"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3938872", "body": "CLA signed. \n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3938872/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commit_comments": [], "review_comments": []}, "indexzero": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [{"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3943603", "body": "@pgriess Nice of you to join us. \n\nIt's not about faster proxying, it's about better proxying. The websocket proxying code in node-http-proxy is terrible because it has to be written on top of an `http.Server`. This change allows us to greatly simplify the proxy logic as well as remove a lot of unnecessary logic used through `http.IncomingMessage` where the parser integration is. \n\nThe logic is simple: \n\n[Adapted from here. We'll be updating this once this pull-request lands.](https://github.com/nodejitsu/node-http-proxy/blob/experimental/lib/balancing-proxy.js#L255-268)\n\n``` js\n  var parsed = false;\n  var buffer = [];\n  socket.ondata = function (chunk) {\n    var ret = parser.execute(d, start, end - start);\n\n    if (parser.boundary && !parsed) {\n      parsed = true;\n      buffer.push(chunk.slice(0, parser.boundary);\n\n      heyUserModifyTheHeadersIfYouWant(parser._headers, function (_, newHeaders) {\n        //\n        // Serialize the headers back to the outgoing socket e.g.\n        // https://github.com/joyent/node/blob/master/lib/http.js#L471-562\n        //\n        ready = true;\n\n        //\n        // Flush any buffered chunks\n        //\n        for (var i = 0; i < buffer.length; i++) {\n          // Write to outgoing socket.\n        }\n\n        buffer.length = 0;\n      })\n    }\n    else if (parser.boundary && parsed && !ready) {\n      buffer.push(chunk);\n    }\n    else {\n      //\n      // Just write to the outgoing socket.\n      //\n    }\n  };\n```\n\nOh, and (unrelated) users frequently bother me about why still use a vendored version of `node-websocket-client`. Can you find some cycles to merge this? https://github.com/pgriess/node-websocket-client/pull/9\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3943603/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3946225", "body": "After speaking @pgriess I'm actually inclined to agree with him. I did not know that the parser.onBody would actually be called for each chunk of the body. I had assumed it would be called with the entirety of the body. \n\nWith this in mind here's the new logic:\n\n``` js\n  var buffer = [];\n  var parsed = false;\n  var ready = false;\n  var HTTPParser = process.binding('http_parser').HTTPParser;\n\n  parser = new HTTPParser(HTTPParser.REQUEST);\n  parser._headers = [];\n  parser._url = '';\n  parser.socket = socket;\n\n  parser.onBody(function (b) {\n    if (ready) {\n      //\n      // If there is any buffer length write it out first\n      //\n      if (buffer.length) {\n        for (var i = 0; i < buffer.length; i++) {\n          // Write buffer to socket\n        }\n\n        buffer.length = 0;\n      }\n\n      //\n      // Write the current body chunk, b, out to the socket\n      //\n      return;\n    }\n\n    buffer.push(b);\n  });\n\n  socket.ondata = function (chunk) {\n    var ret = parser.execute(d, start, end - start);\n\n    if (parser._headers && !parsed) {\n      parsed = true;\n      heyUserModifyTheHeadersIfYouWant(parser._headers, function (_, newHeaders) {\n        //\n        // Serialize the headers back to the outgoing socket e.g.\n        // https://github.com/joyent/node/blob/master/lib/http.js#L471-562\n        //\n        ready = true;\n      });\n    }\n  };\n```\n\nI'm still +1 on this though. 4 bytes per request additional doesn't seem like killer overhead to me.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3946225/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3946321", "body": "The reason I'm still +1 on this is that the approach using `parser.boundary` suggests to be more performant because it only invokes a single function on every chunk: `ondata` instead of both `onbody` and `ondata`.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3946321/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3994205", "body": "So after digging around in `http.js` in node.js internals I realized that this behavior (of calling both `socket.ondata` and `parser.onBody` for every chunk) is already in use. \n\nIn most cases (except for `Upgrade`) both of these functions will be invoked:\n\nhttps://github.com/joyent/node/blob/master/lib/http.js#L1229-1271\nhttps://github.com/joyent/node/blob/master/lib/http.js#L121-129\n\nThis won't help parsing scenarios do any better than node.js core already does so might as well scrap it. :(\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3994205/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "MEMBER"}], "commit_comments": [], "review_comments": []}, "jiefoxi": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [{"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3979686", "body": "Sorry, I won't sign it cause it requires too much personal information to provide. :)\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3979686/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commit_comments": [], "review_comments": []}, "janl": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [{"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3979814", "body": "This is sad. A one line patch does not require a CLA.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3979814/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commit_comments": [], "review_comments": []}, "ckruse": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [{"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3979935", "body": "I hope this is a joke?\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3979935/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commit_comments": [], "review_comments": []}, "trodrigues": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [{"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3980347", "body": "Can't he just declare it's in the public domain and the joyent guys can merge it? I think I remember dojo guys saying they could do that.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3980347/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commit_comments": [], "review_comments": []}, "Seldaek": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [{"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3980513", "body": "@bnoordhuis a type cast isn't even a line, it's not code, it's nothing. It's not like the CLA is of much use anyway, but when it blocks such PRs it's really getting absurd.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/3980513/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commit_comments": [], "review_comments": []}, "romanbsd": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [{"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4045977", "body": "It's interesting, I cannot reproduce it when I'm reading it from a locally saved file, but it reproduces every time when I get it from network. I'll investigate this more and report back. I'll also try git bisect in order to find which commit changed the behavior.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4045977/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4046100", "body": "Sorry. My bad. My callback function was returning the number of bytes processed, while the http_parser was halting if anything other than 0 was returned, as far as I understand.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4046100/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commit_comments": [], "review_comments": []}, "pezcode": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [{"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4199436", "body": "Is node (or any other library) relying on http-parser not executing `on_message_complete` after pausing from inside `on_headers_complete`?\nIf not, I think the easiest 'fix' would be to implement pause as \"don't consume any more bytes (but call whatever callbacks are necessary)\" instead of \"stop doing _anything_\". That was what I thought it did when I read the prototype of `http_parser_pause` anyway.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4199436/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commit_comments": [], "review_comments": []}, "jduell": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [{"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4249763", "body": "You might also want to make your parser/server reply with a HTTP error if parsing goes wrong?  FF simply saw no reply and had to eventually time out the connection.\n\ncheers,\n\nJason Duell\nMozilla\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4249763/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4279737", "body": "@bnoordhuis:  \n\n> I can't get http://www.twimbow.com/dashboard.php to send me any WS upgrade headers.\n\nThe browser sends the upgrade header (from JS: you have to wait a minute).  Here's a wireshark capture of the resulting HTTP request from the websocket creation:\n\n```\nGET /rand/1789415e9e8fb74eed55c90adb7622bd4ac33773b09ce457c4794ae03246d5a3dfcd2484f4ba4be321fde546d3710cb63f6ed865545c8afa2e913db25f58be2d57b806b65e8ae2771e2719559c73dae3188f48e896b8d29e1c287180aae14ae726bd20888eda1e3188c869bf8628130b7665f4af52c4789d06/433e8a1da527942f2c781ff904ae07b9/twimbow HTTP/1.1\nHost: twimbow.com:8125\nUser-Agent: Mozilla/5.0 (X11; Linux x86_64; rv:13.0) Gecko/20120228 Firefox/13.0a1\nAccept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\nAccept-Language: en-us,en;q=0.5\nAccept-Encoding: gzip, deflate\nConnection: keep-alive, Upgrade\nSec-WebSocket-Version: 13\nOrigin: http://www.twimbow.com\nSec-WebSocket-Key: kWYBHLg2fBw3KuYTBYFJ2A==\nCookie: __utma=9462832.1788180937.1330419635.1330419635.1330479818.2; __utmz=9462832.1330419635.1.1.utmcsr=(direct)|utmccn=(direct)|utmcmd=(none); __utmb=9462832.1.10.1330479818; __utmc=9462832\nPragma: no-cache\nCache-Control: no-cache\nUpgrade: websocket\n```\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4279737/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4279746", "body": "And no, that's not a carriage return after GET and the resource, just a space :)\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4279746/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4280134", "body": "> >   I can't get http://www.twimbow.com/dashboard.php to send me any WS upgrade headers.\n> \n> The browser sends the upgrade header (from JS: you have to wait a minute)\n\nYou also have to be logged in\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4280134/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commit_comments": [], "review_comments": []}, "einaros": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [{"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4255724", "body": "Firefox' WebSockets work just fine with node. Tested with:\n- node 0.6.11\n- Firefox 10.0.2\n- [ws](http://github.com/einaros/ws) 0.4.8\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4255724/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4259218", "body": "@pgriess, this isn't actually a http-parser bug. It parses Connection: keep-alive, upgrade just fine, and passes it on to node's parser.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4259218/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4268660", "body": "@pgriess, I wrote a patch for that earlier today. Unsure if that's fit for the parser, though.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4268660/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4281377", "body": "@jduell, any luck finding out which version and library they use?\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4281377/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4287356", "body": "Will that pullreq handle Connection: foo, ,bar?\n\nI'd check, but I'm barely able to comment on this windows phone I'm currently on.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4287356/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4287884", "body": "Cool. My http-rfc fu is a little rusty; what's the priority in case of something daft such as connection: close, keep-alive?\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4287884/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4287905", "body": "Oh, and what about lws & multi-header? Is the latter allowed for connection?\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/issues/comments/4287905/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "commit_comments": [], "review_comments": []}, "temoto": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [{"url": "https://api.github.com/repos/nodejs/http-parser/comments/25796", "body": "I think that 'ascii*'\nallows matching\nHTTP/1.1 301 \\r\\n\\r\\n  (space between 301 and CRLF)\neither. And if i understand correctly, it would trigger response phrase callback with empty phrase.\n\nIs that proper?\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/comments/25796/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/comments/26180", "body": "How to read reason phrase then?\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/comments/26180/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}, {"url": "https://api.github.com/repos/nodejs/http-parser/comments/36133", "body": "And new parser will not support custom methods?\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/comments/36133/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}], "review_comments": []}, "erichocean": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [{"url": "https://api.github.com/repos/nodejs/http-parser/comments/35944", "body": "Happy to see you going by hand, but the Ragel parser had the advantage of the graphical Dot state machine output. Are you maintaing a similar FSM for this version, and if so, would you please copy the .Dot file into the repository? Thanks! \n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/comments/35944/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "review_comments": []}, "cmlenz": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [{"url": "https://api.github.com/repos/nodejs/http-parser/comments/37594", "body": "Afaik, TRACE and OPTIONS aren't WebDAV methods, but defined by the HTTP/1.1 spec.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/comments/37594/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "review_comments": []}, "lericson": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [{"url": "https://api.github.com/repos/nodejs/http-parser/comments/121707", "body": "Heh, funny how it's the exact same modifications though - one huge coincidence right there ;-) I mean especially what with the `CC?=gcc` part, that's not even necessary as `CC` is set by default in a Makefile.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/comments/121707/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "review_comments": []}, "ignacio": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [{"url": "https://api.github.com/repos/nodejs/http-parser/comments/189521", "body": "These typedefs don't work with Mingw. #ifdef _WIN32 should check for mingw and/or cygwin\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/comments/189521/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "review_comments": []}, "dhruvbird": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [{"url": "https://api.github.com/repos/nodejs/http-parser/comments/2133565", "body": "Thanks!\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/comments/2133565/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "review_comments": []}, "felix-halim": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [{"url": "https://api.github.com/repos/nodejs/http-parser/comments/2912367", "body": "Adding the status_complete on the header and c files breaks my program.\nIt doesn't parse the HTTP_RESPONSE header correctly.\nHowever this only breaks when I compiled it on my Debian server.\nIt works fine on my mac and ubuntu.\n\nWhat is the status_complete is for?\nany thoughts on what side effects it introduces?\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/comments/2912367/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/nodejs/http-parser/comments/2917013", "body": "I forgot to mention that I run this inside node addons.\nIs there some quirks on running http-parser inside addons?\nHere is the steps to reproduce:\n\nhttps://github.com/felix-halim/http-parser-bug\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/comments/2917013/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/nodejs/http-parser/comments/2917062", "body": "If I run it without addons, it works fine.\nI'm wondering whether it is the bug inside addons?\nOr maybe a combination of addons + http-parser bug.\nSee https://github.com/felix-halim/http-parser-bug for the code without addons ( standalone.cc )\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/comments/2917062/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/nodejs/http-parser/comments/2920505", "body": "I see, that is why I encountered weird things like: I edit http_parser.c, the node-gyp did compile what I edited, but it does NOT use it :(. So yes I am guessing it links to the \"old\" internal node.js http_parser.\n\nOk, how to statically link my add-on to the newest version that I cloned?\nWhat should I write in the binding.gyp? Definitely my current binding.gyp is not correct?:\n\nhttps://github.com/felix-halim/http-parser-bug\n\nThanks!\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/comments/2920505/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "review_comments": []}, "claudiusaiz": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [{"url": "https://api.github.com/repos/nodejs/http-parser/comments/3047145", "body": "Hello,\n\nI noticed that lines 771-781 in http_parser.c allow an HTTP header to contain only the field name, without the ':'.\nFor example, we could have a header like this:\n\n\"Accept-Encoding\\r\\n\"\n\nBut, section 4.2 of HTTP RFC 2616 specifies that an HTTP header is defined like this:\n\nmessage-header = field-name \":\" [ field-value ]\n\n, having the ':' character compulsory.\n\nI am having some problems with this, and I was thinking of commenting out lines 771-781. Does anyone happen to know if this would have negative effects on the rest of the parser's functionality?\n\nThanks,\nClaudiu\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/comments/3047145/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "review_comments": []}, "pzhxl823": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [{"url": "https://api.github.com/repos/nodejs/http-parser/comments/8773546", "body": "whatis the fuck?\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/comments/8773546/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "review_comments": []}, "jpinner": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [{"url": "https://api.github.com/repos/nodejs/http-parser/comments/9824730", "body": "unnecessary trailing '\\'\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/comments/9824730/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}], "review_comments": []}, "AaronCAlbers": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [{"url": "https://api.github.com/repos/nodejs/http-parser/comments/19479824", "body": "Perhaps this function should be added as well?\n\n``` c\nconst char *\nhttp_status_str (enum http_status s)\n{\n  switch (s) {\n#define XX(num, name, string) case num : return #string;\n      HTTP_STATUS_MAP(XX)\n#undef XX\n  }\n  return \"<unknown>\";\n}\n```\n\nIt compliments the http_method_str() function and I find it most useful.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/comments/19479824/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/nodejs/http-parser/comments/19566034", "body": "@npmccallum, the same could be said about http_method_str(). Where do we draw the line? I think a default implementation makes the library balanced. As you said all the tools are readily available (as long as you know how to use them) to build your own if the consumer needs a custom method.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/comments/19566034/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/nodejs/http-parser/comments/19567282", "body": "@npmccallum, If we were to choose we would want to make it consistent with http_method_str() which currently returns `\"<unknown>\"` when an unknown `enum http_method` is encountered.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/comments/19567282/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}], "review_comments": []}, "postmodern": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": [{"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/1039630", "body": "Correct. This could be a function, but I choose a constant variable since accessing them via FFI is cheaper than function calls.\n\nIn http-parser 2.0, `HTTP_PARSER_DEBUG` can dramatically change the layout of `http_parser`, so I need to check if debug was enabled when defining my own [FFI Struct](https://github.com/postmodern/ffi-http-parser/blob/master/lib/ffi/http/parser/instance.rb#L11-33).\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/1039630/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}]}, "bpaquet": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": [{"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/1230578", "body": "I try to remove it, but I have to modify\nhttps://github.com/bpaquet/http-parser/blob/master/http_parser.c#L2022.\nI think the code is much cleaner with this state.\n\nIf you have a proper solution, I'm ok to implement.\n\nOn Tue, Jul 24, 2012 at 7:13 PM, Peter Griess <\nreply@reply.github.com\n\n> wrote:\n> \n> > @@ -1938,6 +1911,144 @@ const char \\* http_method_str (enum http_method m)\n> >    return http_strerror_tab[err].description;\n> >  }\n> > \n> > +static enum http_host_state\n> > +http_parse_host_char(enum http_host_state s, const char ch) {\n> > -  switch(s) {\n> > -    case s_http_userinfo:\n> > -    case s_http_userinfo_start:\n> > -      if (ch == '@') {\n> \n> Why do we need the `s_http_userinfo_start` state at all? It sees to behave\n> the same as `s_http_userinfo`.\n> \n> ---\n> \n> Reply to this email directly or view it on GitHub:\n> https://github.com/joyent/http-parser/pull/118/files#r1227343\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/1230578/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "CONTRIBUTOR"}]}, "juanper": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": [{"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/1850290", "body": "This is necessary because I'm using MSVS 2005 yet in production code. My company don't want move yours production code to MSVS 2010/12 yet but I need this parser to extend old code. And I don't want install other compiler only to build this code. I tested in my home computer using both MSVS 2005 and MSVS 2010 and works fine.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/1850290/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}]}, "leakim": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": [{"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/18948923", "body": "It was only a demonstration of how to compile/test for 32bit. It's not really needed.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/18948923/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}]}, "simpkins": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": [{"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/28905723", "body": "The previous code didn't call the chunk_complete at this location at all.  Setting the state to s_message_done before calling the chunk_complete callback is necessary for correctness in case the chunk_complete pauses the parser before returning.  This ensures that the state will be s_message_done on the next execution even if CALLBACK_NOTIFY_NOADVANCE(chunk_complete) ends up returning.  This makes sure that the message_complete callback will still be called correctly after the chunk_complete callback.\n\nIf you are asking for the overall motivation for adding these chunking callback, this helps implement proxies more efficiently.  Even though the chunk bounadaries shouldn't have semantic meaning, it is more efficient for the proxy to retransmit the message using the exact same chunk boundaries as originally used in the message.  Otherwise it is pessimistically forced to rechunk with smaller chunk boundaries in some cases, resulting in more data transmitted on the wire (due to more chunk headers).\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/28905723/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}]}, "craig65535": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": [{"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/34730343", "body": "might want to remove the space between Web and Socket, as above.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/34730343/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/52661609", "body": "Does this comparison work for values >= 128? `ch` is a signed char so those values would be interpreted as -128..-1 and not valid.\n\nAlso, in https://www.w3.org/Protocols/rfc2616/rfc2616-sec2.html#sec2.2 :\n\n> ```\n>        CHAR           = <any US-ASCII character (octets 0 - 127)>\n> [...]\n>        CTL            = <any US-ASCII control character\n>                         (octets 0 - 31) and DEL (127)>\n> [...]\n>        SP             = <US-ASCII SP, space (32)>\n>        HT             = <US-ASCII HT, horizontal-tab (9)>\n> [...]\n> ```\n> \n> HTTP/1.1 defines the sequence CR LF as the end-of-line marker for all protocol elements except the entity-body (see appendix 19.3 for tolerant applications). The end-of-line marker within an entity-body is defined by its associated media type, as described in section 3.7.\n> \n> ```\n>        CRLF           = CR LF\n> ```\n> \n> HTTP/1.1 header field values can be folded onto multiple lines if the continuation line begins with a space or horizontal tab. All linear white space, including folding, has the same semantics as SP. A recipient MAY replace any linear white space with a single SP before interpreting the field value or forwarding the message downstream.\n> \n> ```\n>        LWS            = [CRLF] 1*( SP | HT )\n> ```\n> \n> The TEXT rule is only used for descriptive field contents and values that are not intended to be interpreted by the message parser. Words of *TEXT MAY contain characters from character sets other than ISO- 8859-1 [22] only when encoded according to the rules of RFC 2047 [14].\n> \n> ```\n>        TEXT           = <any OCTET except CTLs,\n>                         but including LWS>\n> ```\n> \n> A CRLF is allowed in the definition of TEXT only as part of a header field continuation. It is expected that the folding LWS will be replaced with a single SP before interpretation of the TEXT value.\n\nMy reading is that if a CR or LF char is present, it must be in a pair (CRLF) and then must be followed by either a SP or a HT.\n\nBut overall this does over the set of valid characters, so maybe that doesn't matter. Although I would consider adding a definition for HT instead of 9.\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/52661609/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/52946399", "body": "Looks like this was addressed in #283, which is good, but... does nobody read these pull request comments? Should I have made my own PR instead?\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/52946399/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/79027862", "body": "You may want to move this comment\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/79027862/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/79027907", "body": "Seems this comment is no longer valid\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/79027907/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}]}, "eli-schwartz": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": [{"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/144731636", "body": "This is incredibly wrong and utterly violates the fundamental aspect of DESTDIR. See https://www.gnu.org/prep/standards/html_node/DESTDIR.html\r\n\r\nAlso see #264 #272 #321 and #346 which all try to fix this and thereby allow the Makefile to actually work with DESTDIR, all of which are busy being ignored.\r\n\r\n", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/144731636/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}]}, "zbjornson": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": [{"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/139292911", "body": "Nice work with this PR!\r\n\r\nIt's trivial to make this work on Windows also, just change these two lines to:\r\n\r\n```cpp\r\n#if defined(_MSC_VER) // SSE2 is baseline\r\n#include <intrin.h>\r\n#define __builtin_ctz _tzcnt_u32\r\n#elif defined(__SSE2__) && defined(__GNUC__) \r\n#include <emmintrin.h>\r\n#endif\r\n\r\n#if defined(_MSC_VER) || (defined(__SSE2__) && defined(__GNUC__))\r\n```", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/139292911/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/139293308", "body": "`_mm_set1_epi32(0x0a0a0a0a)` does the same thing and is shorter if you're concerned about 80col. Or even `_mm_set1_epi8(0x0a)`.", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/139293308/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/139293314", "body": "These four/five lines are repeated four times; you could add a little `inline static int get_crlf_mask(const char*)` method maybe and save ~16 lines.", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/139293314/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/139313791", "body": "Awesome! Thanks. (Did you push the changes up?)\r\n\r\nAs for `inline static`, I saw the line below saying it's a C99 project, which means it's in the standard. GCC has supported it since 4.2. Obviously unnecessary, just nice cleanup.\r\nhttps://github.com/nodejs/http-parser/blob/master/http_parser.gyp#L65", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/139313791/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/139516073", "body": "> whether the other compilable platforms has the dialect turned on\r\n\r\nGCC and Clang default to gnu11, which supports `inline`. MSVC is set to compile this package as C++. Since you're testing for `__GNUC__`, I think that means it would be safe. But... in any case, I just tested GCC 4.4.7, 5.1, 6.1 and 7.2, and LLVM Clang 4.0.0 and 5.0.0, and they all automatically inline the static helper function without the `inline` keyword in this case.", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/139516073/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/140600178", "body": "Using `-mno-sse2` (regardless of `-march` or `-mtune`) would achieve this, perhaps less explicitly than you're aiming for though.", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/140600178/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/140820680", "body": "(GCC defines the vector types with `__may_alias__`, making this safe. If you're worried about memory alignment you could use `_mm_lddqu_si128` explicitly.)", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/140820680/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/141404504", "body": "I forgot that `lddqu` is SSE3. Sticking to SSE2 is nice because it's baseline on all platforms, and there's not much else you can do to get a perf bump here until you get to 256-bit registers (AVX) or get `pshufb` (SSSE3).\r\n\r\nAs far as improving node's performance specifically, node's build would have to be tweaked to emit for that instruction set. None of the oldest [currently supported x86/64 platforms](https://github.com/nodejs/node/blob/master/BUILDING.md#supported-platforms-1) require more than SSE2 AFAIK. It would be nice if node.js was open to requiring minimum CPU features (especially ones older than 8-10 years); there's a lot that could be done to improve performance if that were to happen.\r\n\r\nI'm a bit surprised that `lddqu` is that much faster, that should only be the case if you're routinely loading across a CL, and I wouldn't expect this code to be memory-bound overall. (The benchmark I think always uses the same payload, so I guess not surprising.) I'll look in more detail today ... I'm also wondering if doing alignment is beneficial overall given that headers tend to be short.", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/141404504/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}, {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/141778204", "body": "As you have it now, I'm not seeing a difference between `lddqu` and `movdqa` (I don't think `lddqu` is \"supposed\" to be faster than `movdqa` in the case of CL splits with 16B-alignment).\r\n\r\nAs for AVX2, I get a 7-8% speedup over the current SSE2 version, and appears to be bottlenecking on branches. (`find_crlf` is down to <5% of the total instructions retired though. `parse_url_char` is the next heaviest hitter, which is also unsurprisingly bottlenecked on branches. There's maybe some stuff to be done with LUTs or `pshufb` in that function, for another time.)", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/141778204/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}]}, "2underscores-vic": {"issues": [], "commits": [], "pull_requests": [], "issue_comments": [], "commit_comments": [], "review_comments": [{"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/139381251", "body": "Why don't you make it a regular function? Will it be a big overhead?", "reactions": {"url": "https://api.github.com/repos/nodejs/http-parser/pulls/comments/139381251/reactions", "total_count": 0, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0}, "author_association": "NONE"}]}}}}